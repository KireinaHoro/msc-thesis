
@article{noauthor_vivado_2022,
	title = {Vivado {Design} {Suite} {Tutorial}: {Programming} and {Debugging}},
	language = {en},
	year = {2022},
}

@misc{noauthor_kondi_nodate,
	title = {Kondi {\textbar} {ASVZ}},
	url = {https://www.asvz.ch/sport/45675-kondi},
	abstract = {Willkommen beim Klassiker unter den ASVZ-Sportarten! Hier werden zu motivierender Musik Kraft, Ausdauer und Beweglichkeit trainiert, wobei sich der Fokus je nach Kondiart unterscheidet. Das Angebot ist mit über 50 Wochenlektionen riesig. Let's move!},
	language = {de},
	urldate = {2023-09-10},
}

@inproceedings{hoefler_implementation_2007,
	address = {Reno Nevada},
	title = {Implementation and performance analysis of non-blocking collective operations for {MPI}},
	isbn = {978-1-59593-764-3},
	url = {https://dl.acm.org/doi/10.1145/1362622.1362692},
	doi = {10.1145/1362622.1362692},
	abstract = {Collective operations and non-blocking point-to-point operations have always been part of MPI. Although non-blocking collective operations are an obvious extension to MPI, there have been no comprehensive studies of this functionality. In this paper we present LibNBC, a portable high-performance library for implementing non-blocking collective MPI communication operations. LibNBC provides non-blocking versions of all MPI collective operations, is layered on top of MPI-1, and is portable to nearly all parallel architectures. To measure the performance characteristics of our implementation, we also present a microbenchmark for measuring both latency and overlap of computation and communication. Experimental results demonstrate that the blocking performance of the collective operations in our library is comparable to that of collective operations in other highperformance MPI implementations. Our library introduces a very low overhead between the application and the underlying MPI and thus, in conjunction with the potential to overlap communication with computation, oﬀers the potential for optimizing real-world applications.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 2007 {ACM}/{IEEE} conference on {Supercomputing}},
	publisher = {ACM},
	author = {Hoefler, Torsten and Lumsdaine, Andrew and Rehm, Wolfgang},
	month = nov,
	year = {2007},
	pages = {1--10},
}

@article{noauthor_ieee_2020,
	title = {{IEEE} {Standard} for a {Precision} {Clock} {Synchronization} {Protocol} for {Networked} {Measurement} and {Control} {Systems}},
	doi = {10.1109/IEEESTD.2020.9120376},
	abstract = {In this standard, a protocol is defined that provides precise synchronization of clocks in packet-based networked systems. Synchronization of clocks can be achieved in heterogeneous systems that include clocks of different inherent precision, resolution, and stability. The protocol supports synchronization accuracy and precision in the sub-microsecond range with minimal network and local computing resources. Customization is supported by means of profiles. The protocol includes default profiles that permit simple systems to be installed and operated without the need for user management. Sub-nanosecond time transfer accuracy can be achieved in a properly designed network.},
	journal = {IEEE Std 1588-2019 (Revision ofIEEE Std 1588-2008)},
	month = jun,
	year = {2020},
	note = {Conference Name: IEEE Std 1588-2019 (Revision ofIEEE Std 1588-2008)},
	keywords = {Boundary Clock, Clocks, Grandmaster Clock, IEEE 1588, IEEE Standards, Ordinary Clock, Security, Synchronization, Transparent Clock, clock, management, security, synchronization},
	pages = {1--499},
}

@article{barrett_portals_nodate,
	title = {The {Portals} 4.3 {Network} {Programming} {Interface}},
	language = {en},
	author = {Barrett, Brian W and Brightwell, Ron and Grant, Ryan E and Schonbein, Whit and Hemmert, Scott and Pedretti, Kevin and Underwood, Keith and Riesen, Rolf and Hoeﬂer, Torsten and Barbe, Mathieu and Filho, Luiz H Suraty and Ratchov, Alexandre and Maccabe, Arthur B},
}

@techreport{j_user_1980,
	type = {Request for {Comments}},
	title = {User {Datagram} {Protocol}},
	url = {https://datatracker.ietf.org/doc/rfc768},
	number = {RFC 768},
	urldate = {2023-09-06},
	institution = {Internet Engineering Task Force},
	author = {J., Postel},
	month = aug,
	year = {1980},
	doi = {10.17487/RFC0768},
	note = {Num Pages: 3},
}

@techreport{eddy_transmission_2022,
	type = {Request for {Comments}},
	title = {Transmission {Control} {Protocol} ({TCP})},
	url = {https://datatracker.ietf.org/doc/rfc9293},
	abstract = {This document specifies the Transmission Control Protocol (TCP). TCP is an important transport-layer protocol in the Internet protocol stack, and it has continuously evolved over decades of use and growth of the Internet. Over this time, a number of changes have been made to TCP as it was specified in RFC 793, though these have only been documented in a piecemeal fashion. This document collects and brings those changes together with the protocol specification from RFC 793. This document obsoletes RFC 793, as well as RFCs 879, 2873, 6093, 6429, 6528, and 6691 that updated parts of RFC 793. It updates RFCs 1011 and 1122, and it should be considered as a replacement for the portions of those documents dealing with TCP requirements. It also updates RFC 5961 by adding a small clarification in reset handling while in the SYN-RECEIVED state. The TCP header control bits from RFC 793 have also been updated based on RFC 3168.},
	number = {RFC 9293},
	urldate = {2023-09-06},
	institution = {Internet Engineering Task Force},
	author = {Eddy, Wesley},
	month = aug,
	year = {2022},
	doi = {10.17487/RFC9293},
	note = {Num Pages: 98},
}

@techreport{iyengar_quic_2021,
	type = {Request for {Comments}},
	title = {{QUIC}: {A} {UDP}-{Based} {Multiplexed} and {Secure} {Transport}},
	shorttitle = {{QUIC}},
	url = {https://datatracker.ietf.org/doc/rfc9000},
	abstract = {This document defines the core of the QUIC transport protocol. QUIC provides applications with flow-controlled streams for structured communication, low-latency connection establishment, and network path migration. QUIC includes security measures that ensure confidentiality, integrity, and availability in a range of deployment circumstances. Accompanying documents describe the integration of TLS for key negotiation, loss detection, and an exemplary congestion control algorithm.},
	number = {RFC 9000},
	urldate = {2023-09-06},
	institution = {Internet Engineering Task Force},
	author = {Iyengar, Jana and Thomson, Martin},
	month = may,
	year = {2021},
	doi = {10.17487/RFC9000},
	note = {Num Pages: 151},
}

@techreport{floyd_datagram_2006,
	type = {Request for {Comments}},
	title = {Datagram {Congestion} {Control} {Protocol} ({DCCP})},
	url = {https://datatracker.ietf.org/doc/rfc4340},
	abstract = {The Datagram Congestion Control Protocol (DCCP) is a transport protocol that provides bidirectional unicast connections of congestion-controlled unreliable datagrams. DCCP is suitable for applications that transfer fairly large amounts of data and that can benefit from control over the tradeoff between timeliness and reliability. [STANDARDS-TRACK]},
	number = {RFC 4340},
	urldate = {2023-09-06},
	institution = {Internet Engineering Task Force},
	author = {Floyd, Sally and Handley, Mark J. and Kohler, Eddie},
	month = mar,
	year = {2006},
	doi = {10.17487/RFC4340},
	note = {Num Pages: 129},
}

@techreport{stewart_stream_2007,
	type = {Request for {Comments}},
	title = {Stream {Control} {Transmission} {Protocol}},
	url = {https://datatracker.ietf.org/doc/rfc4960},
	abstract = {This document obsoletes RFC 2960 and RFC 3309. It describes the Stream Control Transmission Protocol (SCTP). SCTP is designed to transport Public Switched Telephone Network (PSTN) signaling messages over IP networks, but is capable of broader applications. SCTP is a reliable transport protocol operating on top of a connectionless packet network such as IP. It offers the following services to its users: – acknowledged error-free non-duplicated transfer of user data, – data fragmentation to conform to discovered path MTU size, – sequenced delivery of user messages within multiple streams, with an option for order-of-arrival delivery of individual user messages, – optional bundling of multiple user messages into a single SCTP packet, and – network-level fault tolerance through supporting of multi-homing at either or both ends of an association. The design of SCTP includes appropriate congestion avoidance behavior and resistance to flooding and masquerade attacks. [STANDARDS-TRACK]},
	number = {RFC 4960},
	urldate = {2023-09-06},
	institution = {Internet Engineering Task Force},
	author = {Stewart, Randall R.},
	month = sep,
	year = {2007},
	doi = {10.17487/RFC4960},
	note = {Num Pages: 152},
}

@inproceedings{xianyi_model-driven_2012,
	title = {Model-driven {Level} 3 {BLAS} {Performance} {Optimization} on {Loongson} {3A} {Processor}},
	doi = {10.1109/ICPADS.2012.97},
	abstract = {Every mainstream processor vendor provides an optimized BLAS implementation for its CPU, as BLAS is a fundamental math library in scientific computing. The Loongson 3A CPU is a general-purpose 64-bit MIPS64 quad-core processor, developed by the Institute of Computing Technology, Chinese Academy of Sciences. To date, there has not been a sufficiently optimized BLAS on the Loongson 3A CPU. The purpose of this research is to optimize level 3 BLAS performance on the Loongson 3A CPU. We analyzed the Loongson 3A architecture and built a performance model to highlight the key point, L1 data cache misses, which is different from level 3 BLAS optimization on the mainstream x86 CPU. Therefore, we employed a variety of methods to avoid L1 cache misses in single thread optimization, including cache and register blocking, the Loongson 3A 128-bit memory accessing extension instructions, software prefetching, and single precision floating-point SIMD instructions. Furthermore, we improved parallel performance by reducing bank conflicts among multiple threads in the shared L2 cache. We created an open source BLAS project, OpenBLAS, to demonstrate the performance improvement on the Loongson 3A quad-core processor.},
	booktitle = {2012 {IEEE} 18th {International} {Conference} on {Parallel} and {Distributed} {Systems}},
	author = {Xianyi, Zhang and Qian, Wang and Yunquan, Zhang},
	month = dec,
	year = {2012},
	note = {ISSN: 1521-9097},
	keywords = {BLAS, Kernel, Loongson 3A, MIPS64, Multi-core, Optimization, Pipelines, Prefetching, Registers},
	pages = {684--691},
}

@misc{katherine_stpingdgping_2023,
	title = {stping/dgping: {TCP} and {UDP} ping},
	copyright = {BSD-2-Clause},
	shorttitle = {stping/dgping},
	url = {https://github.com/katef/stping},
	abstract = {TCP and UDP client/server ping},
	urldate = {2023-08-31},
	author = {Katherine, Flavel},
	month = aug,
	year = {2023},
	note = {original-date: 2020-03-30T02:25:36Z},
	keywords = {healthcheck, keepalive, monitoring-tool, networking, ping, ping-server, tcp, udp},
}

@misc{noauthor_iputilsiputils_2023,
	title = {iputils/iputils},
	url = {https://github.com/iputils/iputils},
	abstract = {The iputils package is set of small useful utilities for Linux networking.},
	urldate = {2023-08-31},
	publisher = {iputils},
	month = aug,
	year = {2023},
	note = {original-date: 2014-04-18T12:14:53Z},
}

@article{diciccio_bootstrap_1996,
	title = {Bootstrap confidence intervals},
	volume = {11},
	issn = {0883-4237, 2168-8745},
	url = {https://projecteuclid.org/journals/statistical-science/volume-11/issue-3/Bootstrap-confidence-intervals/10.1214/ss/1032280214.full},
	doi = {10.1214/ss/1032280214},
	abstract = {This article surveys bootstrap methods for producing good approximate confidence intervals. The goal is to improve by an order of magnitude upon the accuracy of the standard intervals \${\textbackslash}hat\{{\textbackslash}theta\} {\textbackslash}pm z{\textasciicircum}\{({\textbackslash}alpha)\} {\textbackslash}hat\{{\textbackslash}sigma\}\$, in a way that allows routine application even to very complicated problems. Both theory and examples are used to show how this is done. The first seven sections provide a heuristic overview of four bootstrap confidence interval procedures: \$BC\_a\$, bootstrap-t , ABC and calibration. Sections 8 and 9 describe the theory behind these methods, and their close connection with the likelihood-based confidence interval theory developed by Barndorff-Nielsen, Cox and Reid and others.},
	number = {3},
	urldate = {2023-08-31},
	journal = {Statistical Science},
	author = {DiCiccio, Thomas J. and Efron, Bradley},
	month = sep,
	year = {1996},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {\$BC\_a\$ and ABC methods, Bootstrap-\$t\$, Calibration, second-order accuracy},
	pages = {189--228},
}

@article{forzan_statistical_2009,
	title = {Statistical static timing analysis: {A} survey},
	volume = {42},
	issn = {01679260},
	shorttitle = {Statistical static timing analysis},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167926008000564},
	doi = {10.1016/j.vlsi.2008.10.002},
	abstract = {As the device and interconnect physical dimensions decrease steadily in modern nanometer silicon technologies, the ability to control the process and environmental variations is becoming more and more difﬁcult. As a consequence, variability is a dominant factor in the design of complex system-onchip (SoC) circuits. A solution to the problem of accurately evaluating the design performance with variability is statistical static timing analysis (SSTA). Starting from the probability distributions of the process parameters, SSTA allows to accurately estimating the probability distribution of the circuit performance in a single timing analysis run. An excellent survey on SSTA was recently published [D. Blaauw, K. Chopra, A. Srivastava, L. Scheffer, Statistical timing analysis: from basic principles to state of the art, IEEE Trans. Computer-Aided Design 27 (2008) 589–607], where the authors presented a general overview of the subject and provided a comprehensive list of references.},
	language = {en},
	number = {3},
	urldate = {2023-08-29},
	journal = {Integration},
	author = {Forzan, Cristiano and Pandini, Davide},
	month = jun,
	year = {2009},
	pages = {409--435},
}

@misc{nazarewicz_deep_nodate,
	title = {A deep dive into {CMA} [{LWN}.net]},
	url = {https://lwn.net/Articles/486301/},
	urldate = {2023-08-28},
	author = {Nazarewicz, Michal},
}

@misc{noauthor_risc-v_2023,
	title = {{RISC}-{V} {GNU} {Compiler} {Toolchain}},
	url = {https://github.com/pulp-platform/pulp-riscv-gnu-toolchain},
	urldate = {2023-08-28},
	publisher = {pulp-platform},
	month = aug,
	year = {2023},
	note = {original-date: 2018-02-05T21:16:30Z},
}

@misc{noauthor_incremental_nodate,
	title = {Incremental {Implementation} • {Vivado} {Design} {Suite} {User} {Guide}: {Implementation} ({UG904}) • {Reader} • {AMD} {Adaptive} {Computing} {Documentation} {Portal}},
	url = {https://docs.xilinx.com/r/2021.1-English/ug904-vivado-implementation/Incremental-Implementation},
	urldate = {2023-08-28},
}

@misc{noauthor_jinja_nodate,
	title = {Jinja — {Jinja} {Documentation} (3.1.x)},
	url = {https://jinja.palletsprojects.com/en/3.1.x/},
	urldate = {2023-08-22},
}

@article{corsetti_controlling_2004,
	title = {Controlling hardware with ioctls},
	volume = {2004},
	issn = {1075-3583},
	abstract = {Control all the little stuff thatisn't in the UNIX programming books.},
	number = {117},
	journal = {Linux Journal},
	author = {Corsetti, Lisa},
	month = jan,
	year = {2004},
	pages = {1},
}

@article{noauthor_ieee_2018,
	title = {{IEEE} {Standard} for {Information} {Technology}–{Portable} {Operating} {System} {Interface} ({POSIX}({TM})) {Base} {Specifications}, {Issue} 7},
	doi = {10.1109/IEEESTD.2018.8277153},
	abstract = {POSIX.1-2017 is simultaneously IEEE Std 1003.1-2017 and The Open Group Standard Base Specifications, Issue 7. POSIX.1-2017 defines a standard operating system interface and environment, including a command interpreter (or “shell”), and common utility programs to support applications portability at the source code level. POSIX.1-2017 is intended to be used by both application developers and system implementors and comprises four major components (each in an associated volume): • General terms, concepts, and interfaces common to all volumes of this standard, including utility conventions and C-language header definitions, are included in the Base Definitions volume. • Definitions for system service functions and subroutines, language-specific system services for the C programming language, function issues, including portability, error handling, and error recovery, are included in the System Interfaces volume. • Definitions for a standard source code-level interface to command interpretation services (a “shell”) and common utility programs for application programs are included in the Shell and Utilities volume. • Extended rationale that did not fit well into the rest of the document structure, which contains historical information concerning the contents of POSIX.1-201x and why features were included or discarded by the standard developers, is included in the Rationale (Informative) volume. The following areas are outside the scope of POSIX.1-201x: • Graphics interfaces • Database management system interfaces • Record I/O considerations • Object or binary code portability • System configuration and resource availability POSIX.1-2017 describes the external characteristics and facilities that are of importance to application developers, rather than the internal construction techniques employed to achieve these capabilities. Special emphasis is placed on those functions and facilities that are needed in a wide variety of commercial applications.},
	journal = {IEEE Std 1003.1-2017 (Revision of IEEE Std 1003.1-2008)},
	month = jan,
	year = {2018},
	note = {Conference Name: IEEE Std 1003.1-2017 (Revision of IEEE Std 1003.1-2008)},
	keywords = {Access control, Application programming interfaces, Batch production systems, CPU, FIFO, IEEE 1003.1, IEEE Standards, Information technology, Operating systems, Synchronization, Utility programs, X/Open System Interface (XSI), application program interface (API), argument, asynchronous, basic regular expression (BRE), batch job, batch system, built-in utility, byte, child, command language interpreter, extended regular expression (ERE), file access control mechanism, input/output (I/O), job control, network, parent, portable operating system interface (POSIX), shell, stream, string, synchronous, system, thread},
	pages = {1--3951},
}

@misc{mochel_sysfs_2011,
	title = {sysfs - {The} filesystem for exporting kernel objects},
	url = {https://www.kernel.org/doc/Documentation/filesystems/sysfs.txt},
	urldate = {2023-08-21},
	author = {Mochel, Patrick and Murphy, Mike},
	month = aug,
	year = {2011},
}

@misc{noauthor_auxiliary_nodate,
	title = {Auxiliary {Bus} — {The} {Linux} {Kernel} documentation},
	url = {https://www.kernel.org/doc/html/next/driver-api/auxiliary_bus.html},
	urldate = {2023-08-18},
}

@misc{ichiro_u-dma-bufuser_2023,
	title = {u-dma-buf({User} space mappable {DMA} {Buffer})},
	copyright = {BSD-2-Clause},
	url = {https://github.com/ikwzm/udmabuf},
	abstract = {User space mappable dma buffer device driver for Linux.},
	urldate = {2023-08-18},
	author = {Ichiro, KAWAZOME},
	month = aug,
	year = {2023},
	note = {original-date: 2015-07-13T09:17:35Z},
	keywords = {device-driver, dma-buffer, fpga-soc-linux, linux-drivers},
}

@article{arm_limited_amba_2003,
	title = {{AMBA}® {AXI} {Protocol} {Specification}},
	language = {en},
	author = {ARM Limited},
	year = {2003},
}

@article{arm_limited_amba_2010,
	title = {{AMBA} {AXI}-{Stream} {Protocol} {Specification}},
	language = {en},
	author = {ARM Limited},
	year = {2010},
}

@book{brown_field-programmable_1992,
	title = {Field-{Programmable} {Gate} {Arrays}},
	isbn = {978-0-7923-9248-4},
	abstract = {Field-Programmable Gate Arrays (FPGAs) have emerged as an attractive means of implementing logic circuits, providing instant manufacturing turnaround and negligible prototype costs. They hold the promise of replacing much of the VLSI market now held by mask-programmed gate arrays. FPGAs offer an affordable solution for customized VLSI, over a wide variety of applications, and have also opened up new possibilities in designing reconfigurable digital systems.  Field-Programmable Gate Arrays discusses the most important aspects of FPGAs in a textbook manner. It provides the reader with a focused view of the key issues, using a consistent notation and style of presentation. It provides detailed descriptions of commercially available FPGAs and an in-depth treatment of the FPGA architecture and CAD issues that are the subjects of current research.  The material presented is of interest to a variety of readers, including those who are not familiar with FPGA technology, but wish to be introduced to it, as well as those who already have an understanding of FPGAs, but who are interested in learning about the research directions that are of current interest.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Brown, Stephen D. and Francis, Robert J. and Rose, Jonathan and Vranesic, Zvonko G.},
	month = jun,
	year = {1992},
	keywords = {Computers / CAD-CAM, Computers / Computer Science, Computers / Information Technology, Technology \& Engineering / Electrical},
}

@inproceedings{lin_panic_2020,
	title = {\{{PANIC}\}: {A} \{{High}-{Performance}\} {Programmable} \{{NIC}\} for {Multi}-tenant {Networks}},
	isbn = {978-1-939133-19-9},
	shorttitle = {\{{PANIC}\}},
	url = {https://www.usenix.org/conference/osdi20/presentation/lin},
	language = {en},
	urldate = {2023-08-15},
	author = {Lin, Jiaxin and Patel, Kiran and Stephens, Brent E. and Sivaraman, Anirudh and Akella, Aditya},
	year = {2020},
	pages = {243--259},
}

@misc{t-head_t-head_nodate,
	title = {T-{Head} {XuanTie} {C910} {High} performance {RV64} compatible processor},
	url = {https://img.102.alibaba.com/1627958419409/49652c9412c41cb6f39b36fed1244e6e.pdf},
	urldate = {2023-08-15},
	author = {T-HEAD},
}

@misc{sifive_sifive_2022,
	title = {{SiFive} {Performance}™ {P650}/{P670}},
	url = {https://www.sifive.com/},
	abstract = {The latest generation SiFive Performance P600-Series processors are the highest performance commercially licensable RISC-V processors.},
	language = {en-us},
	urldate = {2023-08-15},
	journal = {SiFive},
	author = {SiFive},
	year = {2022},
}

@article{zhao_sonicboom_2020,
	title = {{SonicBOOM}: {The} 3rd {Generation} {Berkeley} {Out}-of-{Order} {Machine}},
	language = {en},
	journal = {Fourth Workshop on Computer Architecture Research with RISC-V},
	author = {Zhao, Jerry and Korpan, Ben and Gonzalez, Abraham and Asanovic, Krste},
	month = may,
	year = {2020},
}

@article{asanovic_rocket_2016,
	title = {The {Rocket} {Chip} {Generator}},
	abstract = {Rocket Chip is an open-source Sysem-on-Chip design generator that emits synthesizable RTL. It leverages the Chisel hardware construction language to compose a library of sophisticated generators for cores, caches, and interconnects into an integrated SoC. Rocket Chip generates general-purpose processor cores that use the open RISC-V ISA, and provides both an in-order core generator (Rocket) and an out-of-order core generator (BOOM). For SoC designers interested in utilizing heterogeneous specialization for added eﬃciency gains, Rocket Chip supports the integration of custom accelerators in the form of instruction set extensions, coprocessors, or fully independent novel cores. Rocket Chip has been taped out (manufactured) eleven times, and yielded functional silicon prototypes capable of booting Linux.},
	language = {en},
	author = {Asanovic, Krste and Aviˇzienis, Rimas and Bachrach, Jonathan and Beamer, Scott and Biancolin, David and Celio, Christopher and Cook, Henry and Dabbelt, Palmer and Hauser, John and Izraelevitz, Adam and Karandikar, Sagar and Keller, Benjamin and Kim, Donggyu and Koenig, John and Lee, Yunsup and Love, Eric and Maas, Martin and Magyar, Albert and Mao, Howard and Moreto, Miquel and Ou, Albert and Patterson, David and Richards, Brian and Schmidt, Colin and Twigg, Stephen and Vo, Huy and Waterman, Andrew},
	month = apr,
	year = {2016},
	pages = {11},
}

@article{waterman_risc-v_2019,
	title = {The {RISC}-{V} {Instruction} {Set} {Manual}, {Volume} {I}: {Unprivileged} {ISA}},
	language = {en},
	author = {Waterman, Andrew and Asanovic, Krste},
	month = dec,
	year = {2019},
}

@misc{asanovic_instruction_2014,
	title = {Instruction {Sets} {Should} {Be} {Free}: {The} {Case} {For} {RISC}-{V}},
	url = {https://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-146.pdf},
	urldate = {2023-08-14},
	author = {Asanović, Krste and Patterson, David A.},
	month = jun,
	year = {2014},
}

@article{vieira_fast_2021,
	title = {Fast {Packet} {Processing} with {eBPF} and {XDP}: {Concepts}, {Code}, {Challenges}, and {Applications}},
	volume = {53},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Fast {Packet} {Processing} with {eBPF} and {XDP}},
	url = {https://dl.acm.org/doi/10.1145/3371038},
	doi = {10.1145/3371038},
	abstract = {Extended Berkeley Packet Filter (eBPF) is an instruction set and an execution environment inside the Linux kernel. It enables modification, interaction, and kernel programmability at runtime. eBPF can be used to program the eXpress Data Path (XDP), a kernel network layer that processes packets closer to the NIC for fast packet processing. Developers can write programs in C or P4 languages and then compile to eBPF instructions, which can be processed by the kernel or by programmable devices (e.g., SmartNICs). Since its introduction in 2014, eBPF has been rapidly adopted by major companies such as Facebook, Cloudflare, and Netronome. Use cases include network monitoring, network traffic manipulation, load balancing, and system profiling. This work aims to present eBPF to an inexpert audience, covering the main theoretical and fundamental aspects of eBPF and XDP, as well as introducing the reader to simple examples to give insight into the general operation and use of both technologies.},
	language = {en},
	number = {1},
	urldate = {2023-08-14},
	journal = {ACM Computing Surveys},
	author = {Vieira, Marcos A. M. and Castanho, Matheus S. and Pacífico, Racyus D. G. and Santos, Elerson R. S. and Júnior, Eduardo P. M. Câmara and Vieira, Luiz F. M.},
	month = jan,
	year = {2021},
	pages = {1--36},
}

@article{bosshart_p4_2014,
	title = {P4: programming protocol-independent packet processors},
	volume = {44},
	issn = {0146-4833},
	shorttitle = {P4},
	url = {https://dl.acm.org/doi/10.1145/2656877.2656890},
	doi = {10.1145/2656877.2656890},
	abstract = {P4 is a high-level language for programming protocol-independent packet processors. P4 works in conjunction with SDN control protocols like OpenFlow. In its current form, OpenFlow explicitly speciﬁes protocol headers on which it operates. This set has grown from 12 to 41 ﬁelds in a few years, increasing the complexity of the speciﬁcation while still not providing the ﬂexibility to add new headers. In this paper we propose P4 as a strawman proposal for how OpenFlow should evolve in the future. We have three goals: (1) Reconﬁgurability in the ﬁeld: Programmers should be able to change the way switches process packets once they are deployed. (2) Protocol independence: Switches should not be tied to any speciﬁc network protocols. (3) Target independence: Programmers should be able to describe packetprocessing functionality independently of the speciﬁcs of the underlying hardware. As an example, we describe how to use P4 to conﬁgure a switch to add a new hierarchical label.},
	language = {en},
	number = {3},
	urldate = {2023-08-14},
	journal = {ACM SIGCOMM Computer Communication Review},
	author = {Bosshart, Pat and Daly, Dan and Gibb, Glen and Izzard, Martin and McKeown, Nick and Rexford, Jennifer and Schlesinger, Cole and Talayco, Dan and Vahdat, Amin and Varghese, George and Walker, David},
	month = jul,
	year = {2014},
	pages = {87--95},
}

@inproceedings{firestone_azure_2018,
	title = {Azure {Accelerated} {Networking}: \{{SmartNICs}\} in the {Public} {Cloud}},
	isbn = {978-1-939133-01-4},
	shorttitle = {Azure {Accelerated} {Networking}},
	url = {https://www.usenix.org/conference/nsdi18/presentation/firestone},
	language = {en},
	urldate = {2023-08-14},
	author = {Firestone, Daniel and Putnam, Andrew and Mundkur, Sambhrama and Chiou, Derek and Dabagh, Alireza and Andrewartha, Mike and Angepat, Hari and Bhanu, Vivek and Caulfield, Adrian and Chung, Eric and Chandrappa, Harish Kumar and Chaturmohta, Somesh and Humphrey, Matt and Lavier, Jack and Lam, Norman and Liu, Fengfen and Ovtcharov, Kalin and Padhye, Jitu and Popuri, Gautham and Raindel, Shachar and Sapre, Tejas and Shaw, Mark and Silva, Gabriel and Sivakumar, Madhan and Srivastava, Nisheeth and Verma, Anshuman and Zuhair, Qasim and Bansal, Deepak and Burger, Doug and Vaid, Kushagra and Maltz, David A. and Greenberg, Albert},
	year = {2018},
	pages = {51--66},
}

@misc{xilinx_alveo_2020,
	title = {Alveo {U25} 2x10/{25Gb} {Ethernet} {PCIe} {SmartNIC}},
	url = {https://www.xilinx.com/content/dam/xilinx/publications/product-briefs/alveo-u25-product-brief.pdf},
	urldate = {2023-08-14},
	author = {Xilinx},
	year = {2020},
}

@misc{intel_intel_nodate,
	title = {Intel {SmartNICs} for {Telecommunications} at the {Broadband} {Edge}},
	url = {https://www.intel.com/content/www/us/en/products/programmable/smart-nics-fpga-for-broadband-edge.html},
	abstract = {Intel SmartNICs for telecommunications can help optimize the efficiency and performance of your converged wireless-wireline network.},
	language = {en},
	urldate = {2023-08-14},
	journal = {Intel},
	author = {Intel},
}

@article{xilinx_alveo_2022,
	title = {Alveo {SN1000} {SmartNICs} {Data} {Sheet}},
	abstract = {The Xilinx® Alveo™ SN1000 SmartNICs bring true convergence of network, compute, and storage acceleration to a single platform. As shown in the following figure, the Alveo SN1000 SmartNICs are offered in a single slot, half-length, full height form factor. The card consists of an XCU26 FPGA (XCU26-L2VSVA1365E) and an NXP Layerscape LX2162A processor featuring 16 Arm® v8 Cortex®-A72 cores. The card is passively-cooled, and has two QSFP28 network connections and a x16 PCI Express® Gen 3/Gen 4 x8 interface connected to the XCU26. The card currently supports a 1×100GbE network configuration via Port 1 only. The card has a maximum electrical power limit of 75W. The SN1000 SmartNICs integrate the XCU26 FPGA with the LX2162A processor, enabling hardware accelerated networking, compute, and storage applications to process data with maximum efficiency while avoiding unnecessary data movements and CPU processing. The SN1000 SmartNICs enable cloud service providers to maximize CPU savings by offloading infrastructure workloads to the SmartNIC and enabling deployment of bare-metal services.},
	language = {en},
	author = {Xilinx},
	year = {2022},
}

@misc{nvidia_corporation_nvidia_2021,
	title = {{NVIDIA} {BlueField}-2 {DPU} - {Data} {Center} {Infrastructure} on a {Chip}},
	url = {https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/documents/datasheet-nvidia-bluefield-2-dpu.pdf},
	urldate = {2023-08-14},
	author = {NVIDIA Corporation},
	year = {2021},
}

@inproceedings{guo_framework_2022,
	title = {A {Framework} for {Neural} {Network} {Inference} on {FPGA}-{Centric} {SmartNICs}},
	doi = {10.1109/FPL57034.2022.00071},
	abstract = {FPGA-based SmartNICs offer great potential to significantly improve the performance of high-performance computing and warehouse data processing by tightly coupling support for reconfigurable data-intensive computation with cross-node communication thereby mitigating the von Neumann bottleneck. Existing work however has generally been limited in that it assumes an accelerator model where kernels are offloaded to SmartNICs with most control tasks left to the CPUs. This leads to frequent waiting reduced performance and scaling challenges. In this work we propose a new distributive data-centric computing framework named FCsN for reconfigurable SmartNIC-based systems. Through a lightweight task circulation execution model and its implementation architecture FCsN allows the complete detaching of NN kernel execution control logic system scheduling and network communication to the SmartNICs. This boosts performance by (i) avoiding control dependency with CPUs and (ii) supporting streaming NN kernel execution and network communication at line rate and in a very fine-grained manner. We demonstrate the efficiency and flexibility of FCsN using various types of neural network kernels and applications including deep neural networks (DNN) and graph neural networks (GNN) as these last are both irregular and data intensive they offer an especially robust demonstration. Evaluations using commonly-used neural network models and graph datasets show that a system with FCsN can achieve 10 × speedups over the MPI-based standard CPU baselines},
	booktitle = {2022 32nd {International} {Conference} on {Field}-{Programmable} {Logic} and {Applications} ({FPL})},
	author = {Guo, Anqi and Geng, Tong and Zhang, Yongan and Haghi, Pouya and Wu, Chunshu and Tan, Cheng and Lin, Yingyan and Li, Ang and Herbordt, Martin},
	month = aug,
	year = {2022},
	note = {ISSN: 1946-1488},
	keywords = {Artificial neural networks, Computational modeling, High performance computing, Neural networks, Processor scheduling, Programming, Runtime},
	pages = {01--08},
}

@article{noauthor_marvell_nodate,
	title = {Marvell {LiquidIO} {III}},
	language = {en},
}

@misc{noauthor_agilio_nodate,
	title = {Agilio {CX} {SmartNICs} - {Netronome}},
	url = {https://www.netronome.com/products/agilio-cx/},
	abstract = {Netronome Agilio CX 10GbE, 25GbE and 40GbE standard low-profile PCIe SmartNICs are designed for general-purpose x86 commercial off-the-shelf (COTS) rack servers, fitting needed power and form factor requirements.},
	language = {en},
	urldate = {2023-08-14},
}

@inproceedings{schuh_xenic_2021,
	address = {Virtual Event Germany},
	title = {Xenic: {SmartNIC}-{Accelerated} {Distributed} {Transactions}},
	isbn = {978-1-4503-8709-5},
	shorttitle = {Xenic},
	url = {https://dl.acm.org/doi/10.1145/3477132.3483555},
	doi = {10.1145/3477132.3483555},
	abstract = {High-performance distributed transactions require efficient remote operations on database memory and protocol metadata. The high communication cost of this workload calls for hardware acceleration. Recent research has applied RDMA to this end, leveraging the network controller to manipulate host memory without consuming CPU cycles on the target server. However, the basic read/write RDMA primitives demand trade-offs in data structure and protocol design, limiting their benefits. SmartNICs are a flexible alternative for fast distributed transactions, adding programmable compute cores and on-board memory to the network interface. Applying measured performance characteristics, we design Xenic, a SmartNIC-optimized transaction processing system. Xenic applies an asynchronous, aggregated execution model to maximize network and core efficiency. Xenic’s codesigned data store achieves low-overhead remote object accesses. Additionally, Xenic uses flexible, point-to-point communication patterns between SmartNICs to minimize transaction commit latency. We compare Xenic against prior RDMA- and RPC-based transaction systems with the TPCC, Retwis, and Smallbank benchmarks. Our results for the three benchmarks show 2.42×, 2.07×, and 2.21× throughput improvement, 59\%, 42\%, and 22\% latency reduction, while saving 2.3, 8.1, and 10.1 threads per server.},
	language = {en},
	urldate = {2023-08-14},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 28th {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Schuh, Henry N. and Liang, Weihao and Liu, Ming and Nelson, Jacob and Krishnamurthy, Arvind},
	month = oct,
	year = {2021},
	pages = {740--755},
}

@inproceedings{wang_fpganic_2022,
	title = {\{{FpgaNIC}\}: {An} \{{FPGA}-based\} {Versatile} {100Gb} \{{SmartNIC}\} for \{{GPUs}\}},
	shorttitle = {\{{FpgaNIC}\}},
	url = {https://www.usenix.org/conference/atc22/presentation/wang-zeke},
	language = {en},
	urldate = {2023-08-13},
	author = {Wang, Zeke and Huang, Hongjing and Zhang, Jie and Wu, Fei and Alonso, Gustavo},
	year = {2022},
	pages = {967--986},
}

@inproceedings{wei_characterizing_2023,
	title = {Characterizing {Off}-path \{{SmartNIC}\} for {Accelerating} {Distributed} {Systems}},
	isbn = {978-1-939133-34-2},
	url = {https://www.usenix.org/conference/osdi23/presentation/wei-smartnic},
	language = {en},
	urldate = {2023-08-13},
	author = {Wei, Xingda and Cheng, Rongxin and Yang, Yuhan and Chen, Rong and Chen, Haibo},
	year = {2023},
	pages = {987--1004},
}

@misc{miller_pursuit_nodate,
	title = {In {Pursuit} of 1.{6T} {Data} {Center} {Network} {Speeds} {\textbar} {Network} {Computing}},
	url = {https://www.networkcomputing.com/data-centers/pursuit-16t-data-center-network-speeds},
	abstract = {Today’s 400G data centers are not fast enough for many emerging applications. The networking industry is looking toward 1.6T network speeds.},
	language = {en},
	urldate = {2023-08-08},
	author = {Miller, Ben},
}

@inproceedings{cao_accelerating_2022,
	address = {Dallas, TX, USA},
	title = {Accelerating {Data} {Serialization}/{Deserialization} {Protocols} with {In}-{Network} {Compute}},
	isbn = {978-1-66546-341-6},
	url = {https://ieeexplore.ieee.org/document/10027020/},
	doi = {10.1109/ExaMPI56604.2022.00008},
	abstract = {Efficient data communication is a major goal for scalable and cost-effective use of datacenter and HPC system resources. To let applications communicate efficiently, exchanged data must be serialized at the source and deserialized at the destination. The serialization/deserialization process enables exchanging data in a language- and machine-independent format. However, serialization/deserialization overheads can negatively impact application performance. For example, a server within a microservice framework must deserialize all incoming requests before invoking the respective microservices. We show how data deserialization can be offloaded to fully programmable SmartNICs and performed on the data path, on a per-packet basis. This solution avoids intermediate memory copies, enabling on-the-fly deserialization. We showcase our approach by offloading Google Protocol Buffers, a widely used framework to serialize/deserialize data. Our evaluation demonstrates that, by offloading data deserialization to the NIC, we can achieve up to 4.8x higher throughput than a single AMD Ryzen 7 CPU. We then show through microservice throughput modeling how we can improve the overall throughput by pipelining the deserialization and actual application activities with PsPIN.},
	language = {en},
	urldate = {2023-08-09},
	booktitle = {2022 {IEEE}/{ACM} {International} {Workshop} on {Exascale} {MPI} ({ExaMPI})},
	publisher = {IEEE},
	author = {Cao, Shiyi and Di Girolamo, Salvatore and Hoefler, Torsten},
	month = nov,
	year = {2022},
	pages = {22--30},
}

@inproceedings{di_girolamo_building_2022,
	address = {Dallas, TX, USA},
	title = {Building {Blocks} for {Network}-{Accelerated} {Distributed} {File} {Systems}},
	isbn = {978-1-66545-444-5},
	url = {https://ieeexplore.ieee.org/document/10046100/},
	doi = {10.1109/SC41404.2022.00015},
	abstract = {High-performance clusters and datacenters pose increasingly demanding requirements on storage systems. If these systems do not operate at scale, applications are doomed to become I/O bound and waste compute cycles. To accelerate the data path to remote storage nodes, remote direct memory access (RDMA) has been embraced by storage systems to let data ﬂow from the network to storage targets, reducing overall latency and CPU utilization. Yet, this approach still involves CPUs on the data path to enforce storage policies such as authentication, replication, and erasure coding. We show how storage policies can be ofﬂoaded to fully programmable SmartNICs, without involving host CPUs. By using PsPIN, an open-hardware SmartNIC, we show latency improvements for writes (up to 2x), data replication (up to 2x), and erasure coding (up to 2x), when compared to respective CPU- and RDMA-based alternatives.},
	language = {en},
	urldate = {2023-08-09},
	booktitle = {{SC22}: {International} {Conference} for {High} {Performance} {Computing}, {Networking}, {Storage} and {Analysis}},
	publisher = {IEEE},
	author = {Di Girolamo, Salvatore and De Sensi, Daniele and Taranov, Konstantin and Malesevic, Milos and Besta, Maciej and Schneider, Timo and Kistler, Severin and Hoefler, Torsten},
	month = nov,
	year = {2022},
	pages = {1--14},
}

@inproceedings{rossi_pulp_2015,
	title = {{PULP}: {A} parallel ultra low power platform for next generation {IoT} applications},
	shorttitle = {{PULP}},
	doi = {10.1109/HOTCHIPS.2015.7477325},
	abstract = {This article consists of a collection of slides from the authors' conference presentation.},
	booktitle = {2015 {IEEE} {Hot} {Chips} 27 {Symposium} ({HCS})},
	author = {Rossi, Davide and Conti, Francesco and Marongiu, Andrea and Pullini, Antonio and Loi, Igor and Gautschi, Michael and Tagliavini, Giuseppe and Capotondi, Alessandro and Flatresse, Philippe and Benini, Luca},
	month = aug,
	year = {2015},
	keywords = {Internet of things, Low-power electronics, Memory architecture, Microcontrollers, Parallel processing, Reduced instruction set computing},
	pages = {1--39},
}

@misc{noauthor_verilog_nodate,
	title = {Verilog {Hierarchical} {Reference} {Scope}},
	url = {https://www.chipverify.com/verilog/verilog-hierarchical-reference-scope},
	abstract = {Learn Verilog, SystemVerilog, UVM with code examples, quizzes, interview questions and more !},
	language = {en-GB},
	urldate = {2023-08-04},
	journal = {ChipVerify},
}

@misc{forencich_verilog_2023,
	title = {Verilog {PCI} {Express} {Components} {Readme}},
	copyright = {MIT},
	url = {https://github.com/alexforencich/verilog-pcie},
	abstract = {Verilog PCI express components},
	urldate = {2023-08-04},
	author = {Forencich, Alex},
	month = aug,
	year = {2023},
	note = {original-date: 2019-01-08T05:28:51Z},
}

@inproceedings{john_analysis_2007,
	address = {San Diego California USA},
	title = {Analysis of internet backbone traffic and header anomalies observed},
	isbn = {978-1-59593-908-1},
	url = {https://dl.acm.org/doi/10.1145/1298306.1298321},
	doi = {10.1145/1298306.1298321},
	language = {en},
	urldate = {2023-08-04},
	booktitle = {Proceedings of the 7th {ACM} {SIGCOMM} conference on {Internet} measurement},
	publisher = {ACM},
	author = {John, Wolfgang and Tafvelin, Sven},
	month = oct,
	year = {2007},
	pages = {111--116},
}

@inproceedings{benson_understanding_2009,
	address = {Barcelona Spain},
	title = {Understanding data center traffic characteristics},
	isbn = {978-1-60558-443-0},
	url = {https://dl.acm.org/doi/10.1145/1592681.1592692},
	doi = {10.1145/1592681.1592692},
	abstract = {As data centers become more and more central in Internet communications, both research and operations communities have begun to explore how to better design and manage them. In this paper, we present a preliminary empirical study of end-to-end traﬃc patterns in data center networks that can inform and help evaluate research and operational approaches. We analyze SNMP logs collected at 19 data centers to examine temporal and spatial variations in link loads and losses. We ﬁnd that while links in the core are heavily utilized the ones closer to the edge observe a greater degree of loss. We then study packet traces collected at a small number of switches in one data center and ﬁnd evidence of ON-OFF traﬃc behavior. Finally, we develop a framework that derives ON-OFF traﬃc parameters for data center trafﬁc sources that best explain the SNMP data collected for the data center. We show that the framework can be used to evaluate data center traﬃc engineering approaches. We are also applying the framework to design network-level traﬃc generators for data centers.},
	language = {en},
	urldate = {2023-08-04},
	booktitle = {Proceedings of the 1st {ACM} workshop on {Research} on enterprise networking},
	publisher = {ACM},
	author = {Benson, Theophilus and Anand, Ashok and Akella, Aditya and Zhang, Ming},
	month = aug,
	year = {2009},
	pages = {65--72},
}

@misc{cohen_iptables_nodate,
	title = {{IPTables} {U32} {Match} {Tutorial}},
	url = {http://www.stearns.org/doc/iptables-u32.current.html},
	urldate = {2023-08-04},
	author = {Cohen, Don and Stearns, William},
}

@inproceedings{firoozshahian_mtia_2023,
	address = {Orlando FL USA},
	title = {{MTIA}: {First} {Generation} {Silicon} {Targeting} {Meta}'s {Recommendation} {Systems}},
	isbn = {9798400700958},
	shorttitle = {{MTIA}},
	url = {https://dl.acm.org/doi/10.1145/3579371.3589348},
	doi = {10.1145/3579371.3589348},
	language = {en},
	urldate = {2023-07-20},
	booktitle = {Proceedings of the 50th {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {ACM},
	author = {Firoozshahian, Amin and Coburn, Joel and Levenstein, Roman and Nattoji, Rakesh and Kamath, Ashwin and Wu, Olivia and Grewal, Gurdeepak and Aepala, Harish and Jakka, Bhasker and Dreyer, Bob and Hutchin, Adam and Diril, Utku and Nair, Krishnakumar and Aredestani, Ehsan K. and Schatz, Martin and Hao, Yuchen and Komuravelli, Rakesh and Ho, Kunming and Abu Asal, Sameer and Shajrawi, Joe and Quinn, Kevin and Sreedhara, Nagesh and Kansal, Pankaj and Wei, Willie and Jayaraman, Dheepak and Cheng, Linda and Chopda, Pritam and Wang, Eric and Bikumandla, Ajay and Karthik Sengottuvel, Arun and Thottempudi, Krishna and Narasimha, Ashwin and Dodds, Brian and Gao, Cao and Zhang, Jiyuan and Al-Sanabani, Mohammed and Zehtabioskuie, Ana and Fix, Jordan and Yu, Hangchen and Li, Richard and Gondkar, Kaustubh and Montgomery, Jack and Tsai, Mike and Dwarakapuram, Saritha and Desai, Sanjay and Avidan, Nili and Ramani, Poorvaja and Narayanan, Karthik and Mathews, Ajit and Gopal, Sethu and Naumov, Maxim and Rao, Vijay and Noru, Krishna and Reddy, Harikrishna and Venkatapuram, Prahlad and Bjorlin, Alexis},
	month = jun,
	year = {2023},
	pages = {1--13},
}

@inproceedings{schneider_mpi_2013,
	address = {Madrid Spain},
	title = {{MPI} datatype processing using runtime compilation},
	isbn = {978-1-4503-1903-4},
	url = {https://dl.acm.org/doi/10.1145/2488551.2488552},
	doi = {10.1145/2488551.2488552},
	abstract = {Data packing before and after communication can make up as much as 90\% of the communication time on modern computers. Despite MPI’s well-deﬁned datatype interface for non-contiguous data access, many codes use manual pack loops for performance reasons. Programmers write accesspattern speciﬁc pack loops (e.g., do manual unrolling) for which compilers emit optimized code. In contrast, MPI implementations in use today interpret datatypes at pack time, resulting in high overheads. In this work we explore the effectiveness of using runtime compilation techniques to generate eﬃcient and optimized pack code for MPI datatypes at commit time. Thus, none of the overhead of datatype interpretation is incurred at pack time and pack setup is as fast as calling a function pointer. We have implemented a library called libpack that can be used to compile and (un)pack MPI datatypes. The library optimizes the datatype representation and uses the LLVM framework to produce vectorized machine code for each datatype at commit time. We show several examples of how MPI datatype pack functions beneﬁt from runtime compilation and analyze the performance of compiled pack functions for the data access patterns in many applications. We show that the pack/unpack functions generated by our packing library are seven times faster than those of prevalent MPI implementations for 73\% of the datatypes used in a scientiﬁc application and in many cases outperform manual pack loops.},
	language = {en},
	urldate = {2023-07-12},
	booktitle = {Proceedings of the 20th {European} {MPI} {Users}' {Group} {Meeting}},
	publisher = {ACM},
	author = {Schneider, Timo and Kjolstad, Fredrik and Hoefler, Torsten},
	month = sep,
	year = {2013},
	pages = {19--24},
}

@article{mai_honeycomb_nodate,
	title = {Honeycomb: {Secure} and {Efficient} {GPU} {Executions} via {Static} {Validation}},
	abstract = {Graphics Processing Units (GPUs) unlock emerging use cases like large language models and autonomous driving. They process a large amount of sensitive data, where security is of critical importance. GPU Trusted Execution Environments (TEEs) generally provide security to GPU applications with modest overheads. Recent proposals for GPU TEEs are promising, but many of them require hardware changes that have a long lead time to deploy in production environments. This paper presents Honeycomb, a software-based, secure and efficient TEE for GPU applications. The key idea of Honeycomb is to leverage static analysis to validate the security of GPU applications at load time. Co-designing with the CPU TEE, as well as adding OS and driver support, Honeycomb is able to remove both the OS and the driver from the trusted computing base (TCB). Validation also ensures that all applications inside the system are secure, enabling a concise and secure approach to exchange data in plaintext via shared device memory on the GPU.},
	language = {en},
	author = {Mai, Haohui and Zhao, Jiacheng and Zheng, Hongren and Zhao, Yiyang and Liu, Zibin and Gao, Mingyu and Wang, Cong and Cui, Huimin and Feng, Xiaobing and Kozyrakis, Christos},
}

@incollection{ropo_processing_2009,
	address = {Berlin, Heidelberg},
	title = {Processing {MPI} {Datatypes} {Outside} {MPI}},
	volume = {5759},
	isbn = {978-3-642-03769-6 978-3-642-03770-2},
	url = {http://link.springer.com/10.1007/978-3-642-03770-2_11},
	abstract = {The MPI datatype functionality provides a powerful tool for describing structured memory and ﬁle regions in parallel applications, enabling noncontiguous data to be operated on by MPI communication and I/O routines. However, no facilities are provided by the MPI standard to allow users to eﬃciently manipulate MPI datatypes in their own codes.},
	language = {en},
	urldate = {2023-07-11},
	booktitle = {Recent {Advances} in {Parallel} {Virtual} {Machine} and {Message} {Passing} {Interface}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ross, Robert and Latham, Robert and Gropp, William and Lusk, Ewing and Thakur, Rajeev},
	editor = {Ropo, Matti and Westerholm, Jan and Dongarra, Jack},
	year = {2009},
	doi = {10.1007/978-3-642-03770-2_11},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {42--53},
}

@inproceedings{khazraee_rosebud_2023,
	address = {Vancouver BC Canada},
	title = {Rosebud: {Making} {FPGA}-{Accelerated} {Middlebox} {Development} {More} {Pleasant}},
	isbn = {978-1-4503-9918-0},
	shorttitle = {Rosebud},
	url = {https://dl.acm.org/doi/10.1145/3582016.3582067},
	doi = {10.1145/3582016.3582067},
	language = {en},
	urldate = {2023-06-05},
	booktitle = {Proceedings of the 28th {ACM} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}, {Volume} 3},
	publisher = {ACM},
	author = {Khazraee, Moein and Forencich, Alex and Papen, George C. and Snoeren, Alex C. and Schulman, Aaron},
	month = mar,
	year = {2023},
	pages = {586--605},
}

@misc{cho_case_2023,
	title = {A {Case} for {CXL}-{Centric} {Server} {Processors}},
	url = {http://arxiv.org/abs/2305.05033},
	abstract = {The memory system is a major performance determinant for server processors. Ever-growing core counts and datasets demand higher bandwidth and capacity as well as lower latency from the memory system. To keep up with growing demands, DDR--the dominant processor interface to memory over the past two decades--has offered higher bandwidth with every generation. However, because each parallel DDR interface requires a large number of on-chip pins, the processor's memory bandwidth is ultimately restrained by its pin-count, which is a scarce resource. With limited bandwidth, multiple memory requests typically contend for each memory channel, resulting in significant queuing delays that often overshadow DRAM's service time and degrade performance. We present CoaXiaL, a server design that overcomes memory bandwidth limitations by replacing {\textbackslash}textit\{all\} DDR interfaces to the processor with the more pin-efficient CXL interface. The widespread adoption and industrial momentum of CXL makes such a transition possible, offering \$4{\textbackslash}times\$ higher bandwidth per pin compared to DDR at a modest latency overhead. We demonstrate that, for a broad range of workloads, CXL's latency premium is more than offset by its higher bandwidth. As CoaXiaL distributes memory requests across more channels, it drastically reduces queuing delays and thereby both the average value and variance of memory access latency. Our evaluation with a variety of workloads shows that CoaXiaL improves the performance of manycore throughput-oriented servers by \$1.52{\textbackslash}times\$ on average and by up to \$3{\textbackslash}times\$.},
	urldate = {2023-05-30},
	publisher = {arXiv},
	author = {Cho, Albert and Saxena, Anish and Qureshi, Moinuddin and Daglis, Alexandros},
	month = may,
	year = {2023},
	note = {arXiv:2305.05033 [cs]},
	keywords = {Computer Science - Hardware Architecture},
}

@article{kaffes_shinjuku_nodate,
	title = {Shinjuku: {Preemptive} {Scheduling} for µsecond-scale {Tail} {Latency}},
	abstract = {The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores. For the many realworld scenarios where request service times follow distributions with high dispersion or a heavy tail, they allow short requests to be blocked behind long requests, which leads to poor tail latency.},
	language = {en},
	author = {Kaffes, Kostis and Belay, Adam and Chong, Timothy and Mazieres, David and Humphries, Jack Tigar and Kozyrakis, Christos},
}

@misc{ibanez_nanopu_2020,
	title = {The {nanoPU}: {Redesigning} the {CPU}-{Network} {Interface} to {Minimize} {RPC} {Tail} {Latency}},
	shorttitle = {The {nanoPU}},
	url = {http://arxiv.org/abs/2010.12114},
	abstract = {The nanoPU is a new networking-optimized CPU designed to minimize tail latency for RPCs. By bypassing the cache and memory hierarchy, the nanoPU directly places arriving messages into the CPU register file. The wire-to-wire latency through the application is just 65ns, about 13x faster than the current state-of-the-art. The nanoPU moves key functions from software to hardware: reliable network transport, congestion control, core selection, and thread scheduling. It also supports a unique feature to bound the tail latency experienced by high-priority applications. Our prototype nanoPU is based on a modified RISC-V CPU; we evaluate its performance using cycle-accurate simulations of 324 cores on AWS FPGAs, including real applications (MICA and chain replication).},
	urldate = {2023-05-26},
	publisher = {arXiv},
	author = {Ibanez, Stephen and Mallery, Alex and Arslan, Serhat and Jepsen, Theo and Shahbaz, Muhammad and McKeown, Nick and Kim, Changhoon},
	month = oct,
	year = {2020},
	note = {arXiv:2010.12114 [cs]},
	keywords = {C.1.1, C.2.1, Computer Science - Hardware Architecture, Computer Science - Networking and Internet Architecture},
}

@article{cutler_benets_nodate,
	title = {The beneﬁts and costs of writing a {POSIX} kernel in a high-level language},
	abstract = {This paper presents an evaluation of the use of a high-level language (HLL) with garbage collection to implement a monolithic POSIX-style kernel. The goal is to explore if it is reasonable to use an HLL instead of C for such kernels, by examining performance costs, implementation challenges, and programmability and safety beneﬁts.},
	language = {en},
	author = {Cutler, Cody and Kaashoek, M Frans and Morris, Robert T},
}

@misc{schuldt_backdoors_nodate,
	title = {Backdoors in {Pseudorandom} {Number} {Generators}: {Possibility} and {Impossibility} {Results}},
	shorttitle = {Backdoors in {Pseudorandom} {Number} {Generators}},
	url = {https://eprint.iacr.org/undefined/undefined},
	abstract = {Inspired by the Dual EC DBRG incident, Dodis et al. (Eurocrypt 2015) initiated the formal study of backdoored PRGs, showing that backdoored PRGs are equivalent to public key encryption schemes, giving constructions for backdoored PRGs (BPRGs), and showing how BPRGs can be ``immunised'' by careful post-processing of their outputs. In this paper, we continue the foundational line of work initiated by Dodis et al., providing both positive and negative results. We first revisit the backdoored PRG setting of Dodis et al., showing that PRGs can be more strongly backdoored than was previously envisaged. Specifically, we give efficient constructions of BPRGs for which, given a single generator output, Big Brother can recover the initial state and, therefore, all outputs of the BPRG. Moreover, our constructions are forward-secure in the traditional sense for a PRG, resolving an open question of Dodis et al. in the negative. We then turn to the question of the effectiveness of backdoors in robust PRNGs with input (c.f. Dodis et al., ACM-CCS 2013): generators in which the state can be regularly refreshed using an entropy source, and in which, provided sufficient entropy has been made available since the last refresh, the outputs will appear pseudorandom. The presence of a refresh procedure might suggest that Big Brother could be defeated, since he would not be able to predict the values of the PRNG state backwards or forwards through the high-entropy refreshes. Unfortunately, we show that this intuition is not correct: we are also able to construct robust PRNGs with input that are backdoored in a backwards sense. Namely, given a single output, Big Brother is able to rewind through a number of refresh operations to earlier ``phases'', and recover all the generator's outputs in those earlier phases. Finally, and ending on a positive note, we give an impossibility result: we provide a bound on the number of previous phases that Big Brother can compromise as a function of the state-size of the generator: smaller states provide more limited backdooring opportunities for Big Brother.},
	urldate = {2022-10-21},
	author = {Schuldt, Kenneth G. Paterson, Jacob C. N., Jean Paul Degabriele and Woodage, Joanne},
	keywords = {Backdoor, Dual EC, PRG, PRNG with input, Subversion, Surveillance},
}

@incollection{hutchison_fpga-based_2011,
	address = {Berlin, Heidelberg},
	title = {{FPGA}-{Based} {True} {Random} {Number} {Generation} {Using} {Circuit} {Metastability} with {Adaptive} {Feedback} {Control}},
	volume = {6917},
	isbn = {978-3-642-23950-2 978-3-642-23951-9},
	url = {http://link.springer.com/10.1007/978-3-642-23951-9_2},
	abstract = {The paper presents a novel and efﬁcient method to generate true random numbers on FPGAs by inducing metastability in bi-stable circuit elements, e.g. ﬂip-ﬂops. Metastability is achieved by using precise programmable delay lines (PDL) that accurately equalize the signal arrival times to ﬂip-ﬂops. The PDLs are capable of adjusting signal propagation delays with resolutions higher than fractions of a pico second. In addition, a real time monitoring system is utilized to assure a high degree of randomness in the generated output bits, resilience against ﬂuctuations in environmental conditions, as well as robustness against active adversarial attacks. The monitoring system employs a feedback loop that actively monitors the probability of output bits; as soon as any bias is observed in probabilities, it adjusts the delay through PDLs to return to the metastable operation region. Implementation on Xilinx Virtex 5 FPGAs and results of NIST randomness tests show the effectiveness of our approach.},
	language = {en},
	urldate = {2022-10-21},
	booktitle = {Cryptographic {Hardware} and {Embedded} {Systems} – {CHES} 2011},
	publisher = {Springer Berlin Heidelberg},
	author = {Majzoobi, Mehrdad and Koushanfar, Farinaz and Devadas, Srinivas},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Preneel, Bart and Takagi, Tsuyoshi},
	year = {2011},
	doi = {10.1007/978-3-642-23951-9_2},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {17--32},
}

@misc{schuldt_backdoors_nodate-1,
	title = {Backdoors in {Pseudorandom} {Number} {Generators}: {Possibility} and {Impossibility} {Results}},
	shorttitle = {Backdoors in {Pseudorandom} {Number} {Generators}},
	url = {https://eprint.iacr.org/undefined/undefined},
	abstract = {Inspired by the Dual EC DBRG incident, Dodis et al. (Eurocrypt 2015) initiated the formal study of backdoored PRGs, showing that backdoored PRGs are equivalent to public key encryption schemes, giving constructions for backdoored PRGs (BPRGs), and showing how BPRGs can be ``immunised'' by careful post-processing of their outputs. In this paper, we continue the foundational line of work initiated by Dodis et al., providing both positive and negative results. We first revisit the backdoored PRG setting of Dodis et al., showing that PRGs can be more strongly backdoored than was previously envisaged. Specifically, we give efficient constructions of BPRGs for which, given a single generator output, Big Brother can recover the initial state and, therefore, all outputs of the BPRG. Moreover, our constructions are forward-secure in the traditional sense for a PRG, resolving an open question of Dodis et al. in the negative. We then turn to the question of the effectiveness of backdoors in robust PRNGs with input (c.f. Dodis et al., ACM-CCS 2013): generators in which the state can be regularly refreshed using an entropy source, and in which, provided sufficient entropy has been made available since the last refresh, the outputs will appear pseudorandom. The presence of a refresh procedure might suggest that Big Brother could be defeated, since he would not be able to predict the values of the PRNG state backwards or forwards through the high-entropy refreshes. Unfortunately, we show that this intuition is not correct: we are also able to construct robust PRNGs with input that are backdoored in a backwards sense. Namely, given a single output, Big Brother is able to rewind through a number of refresh operations to earlier ``phases'', and recover all the generator's outputs in those earlier phases. Finally, and ending on a positive note, we give an impossibility result: we provide a bound on the number of previous phases that Big Brother can compromise as a function of the state-size of the generator: smaller states provide more limited backdooring opportunities for Big Brother.},
	urldate = {2022-10-21},
	author = {Schuldt, Kenneth G. Paterson, Jacob C. N., Jean Paul Degabriele and Woodage, Joanne},
	keywords = {Backdoor, Dual EC, PRG, PRNG with input, Subversion, Surveillance},
}

@inproceedings{cock_enzian_2022,
	address = {Lausanne Switzerland},
	title = {Enzian: an open, general, {CPU}/{FPGA} platform for systems software research},
	isbn = {978-1-4503-9205-1},
	shorttitle = {Enzian},
	url = {https://dl.acm.org/doi/10.1145/3503222.3507742},
	doi = {10.1145/3503222.3507742},
	abstract = {Hybrid computing platforms, comprising CPU cores and FPGA logic, are increasingly used for accelerating data-intensive workloads in cloud deployments, and are a growing topic of interest in systems research. However, from a research perspective, existing hardware platforms are limited: they are often optimized for concrete, narrow use-cases and, therefore lack the flexibility needed to explore other applications and configurations. We show that a research group can design and build a more general, open, and affordable hardware platform for hybrid systems research. The platform, Enzian, is capable of duplicating the functionality of existing CPU/FPGA systems with comparable performance but in an open, flexible system. It couples a large FPGA with a server-class CPU in an asymmetric cache-coherent NUMA system. Enzian also enables research not possible with existing hybrid platforms, through explicit access to coherence messages, extensive thermal and power instrumentation, and an open, programmable baseboard management processor.},
	language = {en},
	urldate = {2022-09-27},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Cock, David and Ramdas, Abishek and Schwyn, Daniel and Giardino, Michael and Turowski, Adam and He, Zhenhao and Hossle, Nora and Korolija, Dario and Licciardello, Melissa and Martsenko, Kristina and Achermann, Reto and Alonso, Gustavo and Roscoe, Timothy},
	month = feb,
	year = {2022},
	pages = {434--451},
}

@techreport{maruf_tpp_2022,
	title = {{TPP}: {Transparent} {Page} {Placement} for {CXL}-{Enabled} {Tiered} {Memory}},
	shorttitle = {{TPP}},
	url = {http://arxiv.org/abs/2206.02878},
	abstract = {With increasing memory demands for datacenter applications and the emergence of coherent interfaces like CXL that enable main memory expansion, we are about to observe a wide adoption of tiered-memory subsystems in hyperscalers. In such systems, main memory can constitute different memory technologies with varied performance characteristics. In this paper, we characterize the memory usage of a wide range of datacenter applications across the server fleet of a hyperscaler (Meta) to get insights into an application's memory access patterns and performance on a tiered memory system. Our characterizations show that datacenter applications can benefit from tiered memory systems as there exist opportunities for offloading colder pages to slower memory tiers. Without efficient memory management, however, such systems can significantly degrade performance. We propose a novel OS-level application-transparent page placement mechanism (TPP) for efficient memory management. TPP employs a lightweight mechanism to identify and place hot and cold pages to appropriate memory tiers. It enables page allocation to work independently from page reclamation logic that is, otherwise, tightly coupled in today's Linux kernel. As a result, the local memory tier has memory headroom for new allocations. At the same time, TPP can promptly promote performance-critical hot pages trapped in the slow memory tiers to the fast tier node. Both promotion and demotion mechanisms work transparently without any prior knowledge of an application's memory access behavior. We evaluate TPP with diverse workloads that consume significant portions of DRAM on Meta's server fleet and are sensitive to memory subsystem performance. TPP's efficient page placement improves Linux's performance by up to 18\%. TPP outperforms NUMA balancing and AutoTiering, state-of-the-art solutions for tiered memory, by 10-17\%.},
	number = {arXiv:2206.02878},
	urldate = {2022-09-27},
	institution = {arXiv},
	author = {Maruf, Hasan Al and Wang, Hao and Dhanotia, Abhishek and Weiner, Johannes and Agarwal, Niket and Bhattacharya, Pallab and Petersen, Chris and Chowdhury, Mosharaf and Kanaujia, Shobhit and Chauhan, Prakash},
	month = jun,
	year = {2022},
	note = {arXiv:2206.02878 [cs]
type: article},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Operating Systems},
}

@inproceedings{chen_caching_2008,
	title = {Caching for bursts ({C}-{Burst}): let hard disks sleep well and work energetically},
	shorttitle = {Caching for bursts ({C}-{Burst})},
	doi = {10.1145/1393921.1393961},
	abstract = {High energy consumption has become a critical challenge in all kinds of computer systems. Hardware-supported Dynamic Power Management (DPM) provides a mechanism to save disk energy by transitioning an idle disk to a low-power mode. However, the achievable disk energy saving is mainly dependent on the pattern of I/O requests received at the disk. In particular, for a given number of requests, a bursty disk access pattern serves as a foundation for energy optimization. Aggressive prefetching has been used to increase disk access burstiness and extend disk idle intervals, while caching, a critical component in buffer cache management, has not been paid a specific attention. In the absence of cooperation from caching, the attempt to create bursty disk accesses would often be disturbed due to improper replacement decision made by energy unaware caching policies. In this paper, we present the design of a set of comprehensive energy-aware caching schemes, called C-Burst, and its implementation in Linux kernel 2.6.21. Our caching schemes leverage the 'filtering' effect of buffer cache to effectively reshape the disk access stream to a bursty pattern for energy saving. The experiments under various scenarios show that C-Burst schemes can achieve up to 35\% disk energy saving with minimal performance loss.},
	booktitle = {Proceeding of the 13th international symposium on {Low} power electronics and design ({ISLPED} '08)},
	author = {Chen, Feng and Zhang, Xiaodong},
	month = aug,
	year = {2008},
	keywords = {Energy consumption, Energy management, Filtering, Hard disks, Kernel, Linux, Performance loss, Power system management, Prefetching, Sleep, buffer caches, energy saving, hard disk, power management},
	pages = {141--146},
}

@inproceedings{kurth_hero_2018,
	address = {Limassol, Cyprus},
	title = {{HERO}: an open-source research platform for {HW}/{SW} exploration of heterogeneous manycore systems},
	isbn = {978-1-4503-6591-8},
	shorttitle = {{HERO}},
	url = {http://dl.acm.org/citation.cfm?doid=3295816.3295821},
	doi = {10.1145/3295816.3295821},
	abstract = {Heterogeneous systems on chip (HeSoCs) co-integrate a high-performance multicore host processor with programmable manycore accelerators (PMCAs) to combine “standard platform” software support (e.g. the Linux OS) with energy-efficient, domain-specific, highly parallel processing capabilities.},
	language = {en},
	urldate = {2022-07-21},
	booktitle = {Proceedings of the 2nd {Workshop} on {AutotuniNg} and {aDaptivity} {AppRoaches} for {Energy} efficient {HPC} {Systems} - {ANDARE} '18},
	publisher = {ACM Press},
	author = {Kurth, Andreas and Capotondi, Alessandro and Vogel, Pirmin and Benini, Luca and Marongiu, Andrea},
	year = {2018},
	pages = {1--6},
}

@article{noauthor_memo_nodate,
	title = {Memo {Research} in {Computer} {Science}},
	language = {en},
	pages = {1},
}

@article{noauthor_memo_nodate-1,
	title = {Memo {Practical} {Work}},
	language = {en},
	pages = {2},
}

@misc{httpwwwsoftcomwrocpl_select_nodate,
	title = {Select seats},
	url = {https://butik.teatrwielki.pl/rezerwacja/numerowane.html?ter_id=1942&ter_idt=7acf1df1184f5415ee2b369d13c42615&extid=4942&wiz_id=313&id_strefy=&zniz=12},
	abstract = {Teatr Wielki Opera Narodowa},
	language = {en},
	urldate = {2022-06-28},
	journal = {Select seats},
	author = {http://www.softcom.wroc.pl, SoftCOM-},
}

@misc{noauthor_xl2tpd_nodate,
	title = {xl2tpd - {Google} {Suche}},
	url = {https://www.google.com/search?q=xl2tpd&rlz=1C5CHFA_enDE933DE933&oq=xl2tpd&aqs=chrome..69i57j0i30l9.200j0j4&sourceid=chrome&ie=UTF-8},
	urldate = {2022-06-13},
}

@article{livinskii_random_2020,
	title = {Random testing for {C} and {C}++ compilers with {YARPGen}},
	volume = {4},
	issn = {2475-1421},
	url = {https://dl.acm.org/doi/10.1145/3428264},
	doi = {10.1145/3428264},
	abstract = {VSEVOLOD LIVINSKII, University of Utah and Intel Corporation, USA DMITRY BABOKIN, Intel Corporation, USA JOHN REGEHR, University of Utah, USA Compilers should not crash and they should not miscompile applications. Random testing is an effective method for finding compiler bugs that have escaped other kinds of testing. This paper presents Yet Another Random Program Generator (YARPGen), a random test-case generator for C and C++ that we used to find and report more than 220 bugs in GCC, LLVM, and the Intel® C++ Compiler. Our research contributions include a method for generating expressive programs that avoid undefined behavior without using dynamic checks, and generation policies, a mechanism for increasing diversity of generated code and for triggering more optimizations. Generation policies decrease the testing time to find hard-to-trigger compiler bugs and, for the kinds of scalar optimizations YARPGen was designed to stress-test, increase the number of times these optimizations are applied by the compiler by an average of 20\% for LLVM and 40\% for GCC. We also created tools for automating most of the common tasks related to compiler fuzzing; these tools are also useful for fuzzers other than ours. CCS Concepts: · Software and its engineering → Software testing and debugging; Source code generation.},
	language = {en},
	number = {OOPSLA},
	urldate = {2022-06-06},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Livinskii, Vsevolod and Babokin, Dmitry and Regehr, John},
	month = nov,
	year = {2020},
	pages = {1--25},
}

@article{xu_zertifikat_nodate,
	title = {Zertifikat für "{Theatrale} {Improvisation} in der {Fremdsprache} {Deutsch}; {B1}-{C1}"},
	language = {de},
	author = {Xu, Pengcheng},
	pages = {1},
}

@inproceedings{eran_flexdriver_2022,
	address = {Lausanne Switzerland},
	title = {{FlexDriver}: a network driver for your accelerator},
	isbn = {978-1-4503-9205-1},
	shorttitle = {{FlexDriver}},
	url = {https://dl.acm.org/doi/10.1145/3503222.3507776},
	doi = {10.1145/3503222.3507776},
	abstract = {We propose a new system design for connecting hardware and FPGA accelerators to the network, allowing the accelerator to directly control commodity Network Interface Cards (NICs) without using the CPU. This enables us to solve the key challenge of leveraging existing NIC hardware offloads such as virtualization, tunneling, and RDMA for accelerator networking. Our approach supports a diverse set of use cases, from direct network access for disaggregated accelerators to inline-acceleration of the network stack, all without the complex networking logic in the accelerator. To demonstrate the feasibility of this approach, we build FlexDriver (FLD), an on-accelerator hardware module that implements a NIC data-plane driver. Our main technical contribution is a mechanism that compresses the NIC control structures by two orders of magnitude, allowing FLD to achieve high networking scalability with low die area cost and no bandwidth interference with the accelerator logic. The prototype for NVIDIA Innova-2 FPGA SmartNICs showcases our design’s utility for three different accelerators: a disaggregated LTE cipher, an IP-defragmentation inline accelerator, and an IoT cryptographic-token authentication offload. These accelerators reach 25 Gbps line rate and leverage the NIC for RDMA processing, VXLAN tunneling, and traffic shaping without CPU involvement.},
	language = {en},
	urldate = {2022-05-05},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Eran, Haggai and Fudim, Maxim and Malka, Gabi and Shalom, Gal and Cohen, Noam and Hermony, Amit and Levi, Dotan and Liss, Liran and Silberstein, Mark},
	month = feb,
	year = {2022},
	pages = {1115--1129},
}

@inproceedings{eran_flexdriver_2022-1,
	address = {Lausanne Switzerland},
	title = {{FlexDriver}: a network driver for your accelerator},
	isbn = {978-1-4503-9205-1},
	shorttitle = {{FlexDriver}},
	url = {https://dl.acm.org/doi/10.1145/3503222.3507776},
	doi = {10.1145/3503222.3507776},
	abstract = {We propose a new system design for connecting hardware and FPGA accelerators to the network, allowing the accelerator to directly control commodity Network Interface Cards (NICs) without using the CPU. This enables us to solve the key challenge of leveraging existing NIC hardware offloads such as virtualization, tunneling, and RDMA for accelerator networking. Our approach supports a diverse set of use cases, from direct network access for disaggregated accelerators to inline-acceleration of the network stack, all without the complex networking logic in the accelerator. To demonstrate the feasibility of this approach, we build FlexDriver (FLD), an on-accelerator hardware module that implements a NIC data-plane driver. Our main technical contribution is a mechanism that compresses the NIC control structures by two orders of magnitude, allowing FLD to achieve high networking scalability with low die area cost and no bandwidth interference with the accelerator logic. The prototype for NVIDIA Innova-2 FPGA SmartNICs showcases our design’s utility for three different accelerators: a disaggregated LTE cipher, an IP-defragmentation inline accelerator, and an IoT cryptographic-token authentication offload. These accelerators reach 25 Gbps line rate and leverage the NIC for RDMA processing, VXLAN tunneling, and traffic shaping without CPU involvement.},
	language = {en},
	urldate = {2022-03-02},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Eran, Haggai and Fudim, Maxim and Malka, Gabi and Shalom, Gal and Cohen, Noam and Hermony, Amit and Levi, Dotan and Liss, Liran and Silberstein, Mark},
	month = feb,
	year = {2022},
	pages = {1115--1129},
}

@article{cibik_niveau_2022,
	title = {Niveau {B1} {Frühlingssemester} 2022 {Claudio} {Consani}},
	language = {de},
	author = {Cibik, Shewin},
	year = {2022},
	pages = {114},
}

@inproceedings{truong_capband_2018,
	address = {Shenzhen China},
	title = {{CapBand}: {Battery}-free {Successive} {Capacitance} {Sensing} {Wristband} for {Hand} {Gesture} {Recognition}},
	isbn = {978-1-4503-5952-8},
	shorttitle = {{CapBand}},
	url = {https://dl.acm.org/doi/10.1145/3274783.3274854},
	doi = {10.1145/3274783.3274854},
	abstract = {We present CapBand, a battery-free hand gesture recognition wearable in the form of a wristband. The key challenges in creating such a system are (1) to sense useful hand gestures at ultra-low power so that the device can be powered by the limited energy harvestable from the surrounding environment and (2) to make the system work reliably without requiring training every time a user puts on the wristband. We present successive capacitance sensing, an ultra-low power sensing technique, to capture small skin deformations due to muscle and tendon movements on the user’s wrist, which corresponds to speci�c groups of wrist muscles representing the gestures being performed. We build a wrist muscles-to-gesture model, based on which we develop a hand gesture classi�cation method using both motion and static features. To eliminate the need for per-usage training, we propose a kernel-based on-wrist localization technique to detect the CapBand’s position on the user’s wrist. We prototype CapBand with a custom-designed capacitance sensor array on two� exible circuits driven by a custom-built electronic board, a heterogeneous material-made, deformable silicone band, and a custom-built energy harvesting and management module. Evaluations on 20 subjects show 95.0\% accuracy of gesture recognition when recognizing 15 di�erent hand gestures and 95.3\% accuracy of on-wrist localization.},
	language = {en},
	urldate = {2022-01-28},
	booktitle = {Proceedings of the 16th {ACM} {Conference} on {Embedded} {Networked} {Sensor} {Systems}},
	publisher = {ACM},
	author = {Truong, Hoang and Zhang, Shuo and Muncuk, Ufuk and Nguyen, Phuc and Bui, Nam and Nguyen, Anh and Lv, Qin and Chowdhury, Kaushik and Dinh, Thang and Vu, Tam},
	month = nov,
	year = {2018},
	pages = {54--67},
}

@article{liu_e3_nodate,
	title = {E3: {Energy}-{Efﬁcient} {Microservices} on {SmartNIC}-{Accelerated} {Servers}},
	abstract = {We investigate the use of SmartNIC-accelerated servers to execute microservice-based applications in the data center. By ofﬂoading suitable microservices to the SmartNIC’s lowpower processor, we can improve server energy-efﬁciency without latency loss. However, as a heterogeneous computing substrate in the data path of the host, SmartNICs bring several challenges to a microservice platform: network trafﬁc routing and load balancing, microservice placement on heterogeneous hardware, and contention on shared SmartNIC resources.},
	language = {en},
	author = {Liu, Ming and Peter, Simon and Phothilimthana, Phitchaya Mangpo and Krishnamurthy, Arvind},
	pages = {17},
}

@article{noauthor_alveo_2019,
	title = {Alveo {U200} and {U250} {Accelerator} {Cards} {User} {Guide}},
	language = {en},
	year = {2019},
	pages = {26},
}

@phdthesis{ibanez_optimizing_2021,
	address = {Ann Arbor, United States},
	type = {Ph.{D}.},
	title = {Optimizing {Remote} {Procedure} {Calls} in {Datacenters} {Using} {Hardware}/{Software} {Co}-{Design}},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	url = {https://www.proquest.com/docview/2570367632/abstract/F1FD66C0239A4283PQ/1},
	abstract = {In this dissertation, we present the nanoPU, a new NIC-CPU co-design that provides ultra low and predictable remote procedure call (RPC) response time and thus accelerates datacenter applications. The nanoPU achieves its goal by providing a fast path between the network and applications. This fast path has the following three characteristics: (1) it moves key resource scheduling decisions from software to hardware (reliable network transport \& congestion control, RPC load balancing across cores, thread scheduling) allowing them to operate much more efficiently, (2) it provides a path directly between the network and applications which bypasses the cache and memory hierarchy placing arriving messages directly into the CPU register file, and (3) it supports a unique thread scheduling feature to bound the tail response time experienced by certain high-priority applications.
We built an FPGA prototype of the nanoPU fast path by modifying an open-source RISC-V CPU, and evaluated its performance using cycle-accurate simulations on AWS FPGAs. The wire-to-wire time for nanoPU to receive an incoming message and initiate transmission of a response (response time) is just 69ns, an order of magnitude quicker than the best-of-breed, low latency, commercial NICs. Our hardware implementation of the NDP transport protocol adds less than 10ns to the wire-to-wire response time. We demonstrate that the hardware thread scheduler is able to lower (and potentially bound) RPC tail response time by about 5x while enabling the system to sustain 20\% higher load, relative to traditional thread scheduling techniques. Furthermore, the nanoPU's core selection policy in hardware is able to efficiently distribute RPCs across cores eliminating hot spots and reducing tail response time. We implement and evaluate a suite of applications on the nanoPU, including MICA, Raft, and set algebra for document retrieval.},
	language = {Englisch},
	urldate = {2022-01-21},
	author = {Ibanez, Stephen Gabriel},
	year = {2021},
	note = {ISBN: 9798505571309},
	keywords = {Bandwidths, Communication, Logic, Response time, Scheduling, Servers, Software},
}

@article{vilanova_one_nodate,
	title = {One {Interface} to {Rule} them {All}: {A} {Hardware}/{Software} {Co}-{Design} for {Disaggregated} {Computing}},
	language = {en},
	author = {Vilanova, Lluís and Etsion, Yoav and Silberstein, Mark},
	pages = {5},
}

@article{de_michell_hardwaresoftware_1997,
	title = {Hardware/software co-design},
	volume = {85},
	issn = {1558-2256},
	doi = {10.1109/5.558708},
	abstract = {Most electronic systems, whether self contained or embedded, have a predominant digital component consisting of a hardware platform which executes software application programs. Hardware/software co-design means meeting system level objectives by exploiting the synergism of hardware and software through their concurrent design. Co-design problems have different flavors according to the application domain, implementation technology and design methodology. Digital hardware design has increasingly more similarities to software design. Hardware circuits are often described using modeling or programming languages, and they are validated and implemented by executing software programs, which are sometimes conceived for the specific hardware design. Current integrated circuits can incorporate one (or more) processor core(s) and memory array(s) on a single substrate. These "systems on silicon" exhibit a sizable amount of embedded software, which provides flexibility for product evolution and differentiation purposes. Thus the design of these systems requires designers to be knowledgeable in both hardware and software domains to make good design tradeoffs. The paper introduces various aspects of co-design. We highlight the commonalities and point out the differences in various co-design problems in some application areas. Co-design issues and their relationship to classical system implementation tasks are discussed to help develop a perspective on modern digital system design that relies on computer aided design (CAD) tools and methods.},
	number = {3},
	journal = {Proceedings of the IEEE},
	author = {De Michell, G. and Gupta, R.K.},
	month = mar,
	year = {1997},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {Application software, Consumer electronics, Control systems, Demand forecasting, Design automation, Digital systems, Hardware, Humans, Integrated circuit technology, Marketing and sales},
	pages = {349--365},
}

@inproceedings{yang_making_2020,
	address = {Virtual Event USA},
	title = {Making {QUIC} {Quicker} {With} {NIC} {Offload}},
	isbn = {978-1-4503-8047-8},
	url = {https://dl.acm.org/doi/10.1145/3405796.3405827},
	doi = {10.1145/3405796.3405827},
	abstract = {This paper aims at defining the right set of primitives a NIC shall expose to efficiently offload the QUIC protocol. Although previous work already partially tackled this problem, it has only considered one specific aspect: the crypto module. We instead dissect different QUIC implementations, and perform an in-depth analysis of the cost associated to many of its components. We find that the kernel to userspace communication, the crypto module and the packet reordering algorithm are CPU hungry and often the cause of application performance degradation. We use those findings to define an architecture for offloading QUIC and discuss the associated challenges.},
	language = {en},
	urldate = {2022-01-20},
	booktitle = {Proceedings of the {Workshop} on the {Evolution}, {Performance}, and {Interoperability} of {QUIC}},
	publisher = {ACM},
	author = {Yang, Xiangrui and Eggert, Lars and Ott, Jörg and Uhlig, Steve and Sun, Zhigang and Antichi, Gianni},
	month = aug,
	year = {2020},
	pages = {21--27},
}

@inproceedings{forencich_corundum_2020,
	address = {Fayetteville, AR, USA},
	title = {Corundum: {An} {Open}-{Source} 100-{Gbps} {Nic}},
	isbn = {978-1-72815-803-7},
	shorttitle = {Corundum},
	url = {https://ieeexplore.ieee.org/document/9114811/},
	doi = {10.1109/FCCM48280.2020.00015},
	abstract = {Corundum is an open-source, FPGA-based prototyping platform for network interface development at up to 100 Gbps and beyond. The Corundum platform includes several core features to enable real-time, high-line-rate operations including: a high-performance datapath, 10G/25G/100G Ethernet MACs, PCI Express gen 3, a custom PCIe DMA engine, and native high-precision IEEE 1588 PTP timestamping. A key feature is extensible queue management that can support over 10,000 queues coupled with extensible transmit schedulers, enabling ﬁne-grained hardware control of packet transmission. In conjunction with multiple network interfaces, multiple ports per interface, and per-port event-driven transmit scheduling, these features enable the development of advanced network interfaces, architectures, and protocols. The software interface to these hardware features is a high-performance driver for the Linux networking stack. The platform also supports scatter/gather DMA, checksum ofﬂoading, receive ﬂow hashing, and receiveside scaling. Development and debugging is facilitated by a comprehensive open-source, Python-based simulation framework that includes the entire system from a simulation model of the driver and PCI express interface to the Ethernet interfaces. The power and ﬂexibility of Corundum is demonstrated by the implementation of a microsecond-precision time-division multiple access (TDMA) hardware scheduler to enforce a TDMA schedule at 100 Gbps line rate with no CPU overhead.},
	language = {en},
	urldate = {2022-01-18},
	booktitle = {2020 {IEEE} 28th {Annual} {International} {Symposium} on {Field}-{Programmable} {Custom} {Computing} {Machines} ({FCCM})},
	publisher = {IEEE},
	author = {Forencich, Alex and Snoeren, Alex C. and Porter, George and Papen, George},
	month = may,
	year = {2020},
	pages = {38--46},
}

@article{istvan_consensus_nodate,
	title = {Consensus in a {Box}: {Inexpensive} {Coordination} in {Hardware}},
	abstract = {Consensus mechanisms for ensuring consistency are some of the most expensive operations in managing large amounts of data. Often, there is a trade off that involves reducing the coordination overhead at the price of accepting possible data loss or inconsistencies. As the demand for more efﬁcient data centers increases, it is important to provide better ways of ensuring consistency without affecting performance.},
	language = {en},
	author = {Istvan, Zsolt and Sidler, David and Alonso, Gustavo and Vukolic, Marko},
	pages = {15},
}

@inproceedings{de_sensi_flare_2021,
	address = {St. Louis Missouri},
	title = {Flare: flexible in-network allreduce},
	isbn = {978-1-4503-8442-1},
	shorttitle = {Flare},
	url = {https://dl.acm.org/doi/10.1145/3458817.3476178},
	doi = {10.1145/3458817.3476178},
	abstract = {The allreduce operation is one of the most commonly used communication routines in distributed applications. To improve its bandwidth and to reduce network traffic, this operation can be accelerated by offloading it to network switches, that aggregate the data received from the hosts, and send them back the aggregated result. However, existing solutions provide limited customization opportunities and might provide suboptimal performance when dealing with custom operators and data types, with sparse data, or when reproducibility of the aggregation is a concern. To deal with these problems, in this work we design a flexible programmable switch by using as a building block PsPIN, a RISC-V architecture implementing the sPIN programming model. We then design, model, and analyze different algorithms for executing the aggregation on this architecture, showing performance improvements compared to state-of-the-art approaches.},
	language = {en},
	urldate = {2022-01-17},
	booktitle = {Proceedings of the {International} {Conference} for {High} {Performance} {Computing}, {Networking}, {Storage} and {Analysis}},
	publisher = {ACM},
	author = {De Sensi, Daniele and Di Girolamo, Salvatore and Ashkboos, Saleh and Li, Shigang and Hoefler, Torsten},
	month = nov,
	year = {2021},
	pages = {1--16},
}

@inproceedings{liu_offloading_2019,
	address = {Beijing China},
	title = {Offloading distributed applications onto {smartNICs} using {iPipe}},
	isbn = {978-1-4503-5956-6},
	url = {https://dl.acm.org/doi/10.1145/3341302.3342079},
	doi = {10.1145/3341302.3342079},
	abstract = {Emerging Multicore SoC SmartNICs, enclosing rich computing resources (e.g., a multicore processor, onboard DRAM, accelerators, programmable DMA engines), hold the potential to offload generic datacenter server tasks. However, it is unclear how to use a SmartNIC efficiently and maximize the offloading benefits, especially for distributed applications. Towards this end, we characterize four commodity SmartNICs and summarize the offloading performance implications from four perspectives: traffic control, computing capability, onboard memory, and host communication. Based on our characterization, we build iPipe, an actor-based framework for offloading distributed applications onto SmartNICs. At the core of iPipe is a hybrid scheduler, combining FCFS and DRRbased processor sharing, which can tolerate tasks with variable execution costs and maximize NIC compute utilization. Using iPipe, we build a real-time data analytics engine, a distributed transaction system, and a replicated key-value store, and evaluate them on commodity SmartNICs. Our evaluations show that when processing 10/25Gbps of application bandwidth, NIC-side offloading can save up to 3.1/2.2 beefy Intel cores and lower application latencies by 23.0/28.0 µs.},
	language = {en},
	urldate = {2022-01-17},
	booktitle = {Proceedings of the {ACM} {Special} {Interest} {Group} on {Data} {Communication}},
	publisher = {ACM},
	author = {Liu, Ming and Cui, Tianyi and Schuh, Henry and Krishnamurthy, Arvind and Peter, Simon and Gupta, Karan},
	month = aug,
	year = {2019},
	pages = {318--333},
}

@article{takruri_flair_nodate,
	title = {{FLAIR}: {Accelerating} {Reads} with {Consistency}-{Aware} {Network} {Routing}},
	abstract = {We present FLAIR, a novel approach for accelerating read operations in leader-based consensus protocols. FLAIR leverages the capabilities of the new generation of programmable switches to serve reads from follower replicas without compromising consistency. The core of the new approach is a packet-processing pipeline that can track client requests and system replies, identify consistent replicas, and at line speed, forward read requests to replicas that can serve the read without sacrificing linearizability. An additional benefit of FLAIR is that it facilitates devising novel consistency-aware load balancing techniques.},
	language = {en},
	author = {Takruri, Hatem and Kettaneh, Ibrahim and Alquraan, Ahmed and Al-Kiswany, Samer},
	pages = {16},
}

@inproceedings{di_girolamo_network-accelerated_2019,
	address = {Denver Colorado},
	title = {Network-accelerated non-contiguous memory transfers},
	isbn = {978-1-4503-6229-0},
	url = {https://dl.acm.org/doi/10.1145/3295500.3356189},
	doi = {10.1145/3295500.3356189},
	abstract = {Applications often communicate data that is non-contiguous in the send- or the receive-buffer, e.g., when exchanging a column of a matrix stored in row-major order. While non-contiguous transfers are well supported in HPC (e.g., MPI derived datatypes), they can still be up to 5x slower than contiguous transfers of the same size. As we enter the era of network acceleration, we need to investigate which tasks to offload to the NIC: In this work we argue that non-contiguous memory transfers can be transparently networkaccelerated, truly achieving zero-copy communications. We implement and extend sPIN, a packet streaming processor, within a Portals 4 NIC SST model, and evaluate strategies for NIC-offloaded processing of MPI datatypes, ranging from datatype-specific handlers to general solutions for any MPI datatype. We demonstrate up to 10x speedup in the unpack throughput of real applications, demonstrating that non-contiguous memory transfers are a first-class candidate for network acceleration.},
	language = {en},
	urldate = {2022-01-16},
	booktitle = {Proceedings of the {International} {Conference} for {High} {Performance} {Computing}, {Networking}, {Storage} and {Analysis}},
	publisher = {ACM},
	author = {Di Girolamo, Salvatore and Taranov, Konstantin and Kurth, Andreas and Schaffner, Michael and Schneider, Timo and Beránek, Jakub and Besta, Maciej and Benini, Luca and Roweth, Duncan and Hoefler, Torsten},
	month = nov,
	year = {2019},
	pages = {1--14},
}

@inproceedings{tork_lynx_2020,
	address = {Lausanne Switzerland},
	title = {Lynx: {A} {SmartNIC}-driven {Accelerator}-centric {Architecture} for {Network} {Servers}},
	isbn = {978-1-4503-7102-5},
	shorttitle = {Lynx},
	url = {https://dl.acm.org/doi/10.1145/3373376.3378528},
	doi = {10.1145/3373376.3378528},
	abstract = {This paper explores new opportunities afforded by the growing deployment of compute and I/O accelerators to improve the performance and efficiency of hardware-accelerated computing services in data centers.},
	language = {en},
	urldate = {2022-01-10},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Tork, Maroun and Maudlej, Lina and Silberstein, Mark},
	month = mar,
	year = {2020},
	pages = {117--131},
}

@article{morgan_-formal_nodate,
	title = {({In}-){Formal} {Methods}: the {Lost} {Art}. . . or},
	language = {en},
	author = {Morgan, Carroll},
	pages = {276},
}

@article{morgan_-formal_nodate-1,
	title = {({In}-){Formal} {Methods}: the {Lost} {Art}. . . or},
	language = {en},
	author = {Morgan, Carroll},
	pages = {276},
}

@book{liu_engineering_2016,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Engineering {Trustworthy} {Software} {Systems}: {First} {International} {School}, {SETSS} 2014, {Chongqing}, {China}, {September} 8-13, 2014. {Tutorial} {Lectures}},
	volume = {9506},
	isbn = {978-3-319-29627-2 978-3-319-29628-9},
	shorttitle = {Engineering {Trustworthy} {Software} {Systems}},
	url = {http://link.springer.com/10.1007/978-3-319-29628-9},
	language = {en},
	urldate = {2021-12-28},
	publisher = {Springer International Publishing},
	editor = {Liu, Zhiming and Zhang, Zili},
	year = {2016},
	doi = {10.1007/978-3-319-29628-9},
}

@article{planeta_migros_nodate,
	title = {{MigrOS}: {Transparent} {Live}-{Migration} {Support} for {Containerised} {RDMA} {Applications}},
	abstract = {RDMA networks ofﬂoad packet processing onto specialised circuitry of the network interface controllers (NICs) and bypass the OS to improve network latency and bandwidth. As a consequence, the OS forfeits control over active RDMA connections and loses the possibility to migrate RDMA applications transparently. This paper presents MigrOS, an OS-level architecture for transparent live migration of containerised RDMA applications. MigrOS shows that a set of minimal changes to the RDMA communication protocol reenables live migration without interposing the critical path operations. Our approach requires no changes to the user applications and maintains backwards compatibility at all levels of the network stack. Overall, MigrOS can achieve up to 33\% lower network latency in comparison to software-only techniques.},
	language = {en},
	author = {Planeta, Maksym and Bierbaum, Jan and Antony, Leo Sahaya Daphne and Härtig, Hermann and Hoeﬂer, Torsten},
	pages = {18},
}

@article{xu_certificate_nodate,
	title = {Certificate of {Achievement} - {BG3}},
	language = {en},
	author = {Xu, Pengcheng},
	pages = {1},
}

@article{huang_dynamic_nodate,
	title = {Dynamic {Inconsistency} in {Risk} {Preferences}},
	abstract = {I conducted an experiment to show that risk preferences are dynamically inconsistent. Preference reversals may happen when individuals make decisions on the same risk choice with diﬀerent uncertainty resolution time, especially when the choice involves payment in the loss domain. The observed inconsistency cannot be explained by the background risk, asymmetric discounting of gain and loss, and most belief-based utility models, but seem consistent with the attention-based anticipatory utility model. The results suggest strongly that the resolution time of uncertainty matters when considering risk preferences.},
	language = {en},
	author = {Huang, Jindi},
	pages = {27},
}

@article{xia_kunpeng_2021,
	title = {Kunpeng 920: {The} {First} 7-nm {Chiplet}-{Based} 64-{Core} {ARM} {SoC} for {Cloud} {Services}},
	volume = {41},
	issn = {1937-4143},
	shorttitle = {Kunpeng 920},
	doi = {10.1109/MM.2021.3085578},
	abstract = {Kunpeng 920 is the second generation server processor designed by HiSilicon based on ARM architecture. Kunpeng 920 is able to achieve cost efficiency for various workloads through using a variety of chiplets and hybrid process technologies. The unique recomposition(s) of these flexible chipsets allows new designs to be created. The Kunpeng series processors combine technology innovations from various levels to improve efficiency, eliminate bottlenecks, and deliver value and performance. Its key features are as follows: The Kunpeng 920 core is specifically designed with superscalar architecture with the support of vector extension to provide leading features for high-performance computing applications; the coherent cache subsystem is created to integrate multicores into single chiplet (e.g., 7-nm process node) with a ring design that is ultralow-latency ({\textless}; 15 ns), nonblocking and bufferless; a dedicated parallel small-IO block is developed to achieve high-bandwidth (e.g., 400 GB/s) interdie connection for 2-D package solutions; IO die is redesigned (e.g., 16-nm process) so that the latest standard interface (e.g., PCI4.0) can be leveraged to scale up the System on a Chip (SoCs) and connect them with other IO devices; two or four Kunpeng 920 can work together as single symmetric multiprocessor system with cache coherent nonuniform memory access fabric.},
	number = {5},
	journal = {IEEE Micro},
	author = {Xia, Jing and Cheng, Chuanning and Zhou, Xiping and Hu, Yuxing and Chun, Peter},
	month = sep,
	year = {2021},
	note = {Conference Name: IEEE Micro},
	keywords = {Cloud computing, Collaboration, Microarchitecture, Microprocessors, Portable document format},
	pages = {67--75},
}

@article{kalia_raising_nodate,
	title = {Raising the {Bar} for {Using} {GPUs} in {Software} {Packet} {Processing}},
	abstract = {Numerous recent research eﬀorts have explored the use of Graphics Processing Units (GPUs) as accelerators for software-based routing and packet handling applications, typically demonstrating throughput several times higher than using legacy code on the CPU alone. In this paper, we explore a new hypothesis about such designs: For many such applications, the beneﬁts arise less from the GPU hardware itself as from the expression of the problem in a language such as CUDA or OpenCL that facilitates memory latency hiding and vectorization through massive concurrency. We demonstrate that in several cases, after applying a similar style of optimization to algorithm implementations, a CPU-only implementation is, in fact, more resource eﬃcient than the version running on the GPU. To “raise the bar” for future uses of GPUs in packet processing applications, we present and evaluate a preliminary language/compiler-based framework called G-Opt that can accelerate CPU-based packet handling programs by automatically hiding memory access latency.},
	language = {en},
	author = {Kalia, Anuj and Zhou, Dong and Kaminsky, Michael and Andersen, David G},
	pages = {15},
}

@article{ioannidis_query_1996,
	title = {Query optimization},
	volume = {28},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/234313.234367},
	doi = {10.1145/234313.234367},
	number = {1},
	urldate = {2021-12-03},
	journal = {ACM Computing Surveys},
	author = {Ioannidis, Yannis E.},
	month = mar,
	year = {1996},
	pages = {121--123},
}

@article{kossmann_state_2000,
	title = {The state of the art in distributed query processing},
	volume = {32},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/371578.371598},
	doi = {10.1145/371578.371598},
	abstract = {Distributed data processing is becoming a reality. Businesses want to do it for many reasons, and they often must do it in order to stay competitive. While much of the infrastructure for distributed data processing is already there (e.g., modern network technology), a number of issues make distributed data processing still a complex undertaking: (1) distributed systems can become very large, involving thousands of heterogeneous sites including PCs and mainframe server machines; (2) the state of a distributed system changes rapidly because the load of sites varies over time and new sites are added to the system; (3) legacy systems need to be integrated—such legacy systems usually have not been designed for distributed data processing and now need to interact with other (modern) systems in a distributed environment. This paper presents the state of the art of query processing for distributed database and information systems.  The paper presents the “textbook” architecture for distributed query processing and a series of techniques that are particularly useful for distributed database systems. These techniques include special join techniques, techniques to exploit intraquery paralleli sm, techniques to reduce communication costs, and techniques to exploit caching and replication of data. Furthermore, the paper discusses different kinds of distributed systems such as client-server, middleware (multitier), and heterogeneous database systems, and shows how query processing works in these systems.},
	language = {en},
	number = {4},
	urldate = {2021-12-03},
	journal = {ACM Computing Surveys},
	author = {Kossmann, Donald},
	month = dec,
	year = {2000},
	pages = {422--469},
}

@article{graefe_sort_1994,
	title = {Sort vs. hash revisited},
	volume = {6},
	issn = {1558-2191},
	doi = {10.1109/69.334883},
	abstract = {Efficient algorithms for processing large volumes of data are very important both for relational and new object-oriented database systems. Many query-processing operations can be implemented using sort- or hash-based algorithms, e.g. intersections, joins, and duplicate elimination. In the early relational database systems, only sort-based algorithms were employed. In the last decade, hash-based algorithms have gained acceptance and popularity, and are often considered generally superior to sort-based algorithms such as merge-join. In this article, we compare the concepts behind sort- and hash-based query-processing algorithms and conclude that (1) many dualities exist between the two types of algorithms, (2) their costs differ mostly by percentages rather than by factors, (3) several special cases exist that favor one or the other choice, and (4) there is a strong reason why both hash- and sort-based algorithms should be available in a query-processing system. Our conclusions are supported by experiments performed using the Volcano query execution engine.{\textless}{\textgreater}},
	number = {6},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Graefe, G. and Linville, A. and Shapiro, L.D.},
	month = dec,
	year = {1994},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	keywords = {Computer science, Costs, Database languages, Database systems, Engines, Partitioning algorithms, Query processing, Relational databases, Sorting, Volcanoes},
	pages = {934--944},
}

@article{mcdonald_its_nodate,
	title = {“{It}’s stressful having all these phones”: {Investigating} {Sex} {Workers}’ {Safety} {Goals}, {Risks}, and {Practices} {Online}},
	abstract = {We investigate how a population of end-users with especially salient security and privacy risks — sex workers —conceptualizes and manages their digital safety. The commercial sex industry is increasingly Internet-mediated. As such, sex workers are facing new challenges in protecting their digital privacy and security and avoiding serious consequences such as stalking, blackmail, and social exclusion. Through interviews (n=29) and a survey (n=65) with sex workers in European countries where sex work is legal and regulated, we ﬁnd that sex workers have well-deﬁned safety goals and clear awareness of the risks to their safety: clients, deﬁcient legal protections, and hostile digital platforms. In response to these risks, our participants developed complex strategies for protecting their safety, but use few tools speciﬁcally designed for security and privacy. Our results suggest that if even highrisk users with clear risk conceptions view existing tools as insufﬁciently effective to merit the cost of use, these tools are not actually addressing their real security needs. Our ﬁndings underscore the importance of more holistic design of security tools to address both online and ofﬂine axes of safety.},
	language = {en},
	author = {McDonald, Allison and Schaub, Florian and Barwulor, Catherine and Mazurek, Michelle L and Redmiles, Elissa M},
	pages = {19},
}

@article{brunella_hxdp_nodate,
	title = {{hXDP}: {Efﬁcient} {Software} {Packet} {Processing} on {FPGA} {NICs}},
	abstract = {FPGA accelerators on the NIC enable the ofﬂoading of expensive packet processing tasks from the CPU. However, FPGAs have limited resources that may need to be shared among diverse applications, and programming them is difﬁcult.},
	language = {en},
	author = {Brunella, Marco Spaziani and Belocchi, Giacomo and Bonola, Marco and Pontarelli, Salvatore and Bianchi, Giuseppe and Cammarano, Aniello and Palumbo, Alessandro and Petrucci, Luca and Bifulco, Roberto},
	pages = {19},
}

@article{eyster_theory_nodate,
	title = {A {Theory} of {Ex} {Post} {Rationalization}},
	abstract = {People rationalize their past choices, even those that were mistakes in hindsight. We propose a formal theory of this behavior. The theory predicts sunk-cost eﬀects, as well as ‘unsunk-beneﬁt’ eﬀects. Its model primitives are identiﬁed by choice behavior and it yields tractable comparative statics.},
	language = {en},
	author = {Eyster, Erik and Li, Shengwu and Ridout, Sarah},
	pages = {55},
}

@book{christ_schweizer_1980,
	address = {Basel},
	title = {Schweizer {Dialekte}},
	isbn = {978-3-0348-6717-7 978-3-0348-6716-0},
	url = {http://link.springer.com/10.1007/978-3-0348-6716-0},
	language = {de},
	urldate = {2021-10-26},
	publisher = {Birkhäuser Basel},
	editor = {Christ, Robert B.},
	year = {1980},
	doi = {10.1007/978-3-0348-6716-0},
}

@misc{foph_coronavirus_nodate,
	title = {Coronavirus: where and how to get a {COVID} certificate and how long it is valid},
	shorttitle = {Coronavirus},
	url = {https://www.bag.admin.ch/bag/en/home/krankheiten/ausbrueche-epidemien-pandemien/aktuelle-ausbrueche-epidemien/novel-cov/covid-zertifikat/covid-zertifikat-erhalt-gueltigkeit.html},
	abstract = {Information on obtaining a COVID certificate and how long it is valid},
	language = {en},
	urldate = {2021-10-23},
	author = {FOPH, Federal Office of Public Health},
}

@incollection{chang_safety_2017,
	address = {Cham},
	title = {Safety and {Liveness} of {MCS} {Lock}—{Layer} by {Layer}},
	volume = {10695},
	isbn = {978-3-319-71236-9 978-3-319-71237-6},
	url = {http://link.springer.com/10.1007/978-3-319-71237-6_14},
	abstract = {The MCS Lock, a small but complex piece of low-level software, is a standard algorithm for providing inter-CPU locks with FIFO ordering guarantee and scalability. It is an interesting target for veriﬁcation—short and subtle, involving both liveness and safety properties. We implemented and veriﬁed the MCS Lock algorithm as part of the CertiKOS kernel [8], showing that the C/assembly implementation contextually reﬁnes atomic speciﬁcations of the acquire and release lock methods. Our development follows the methodology of certiﬁed concurrent abstraction layers [7, 9]. By splitting the proof into layers, we can modularize it into separate parts for the low-level machine model, data abstraction, and reasoning about concurrent interleavings. This separation of concerns makes the layered methodology suitable for veriﬁed programming in the large, and our MCS Lock can be composed with other shared objects in CertiKOS kernel.},
	language = {en},
	urldate = {2021-10-20},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer International Publishing},
	author = {Kim, Jieung and Sjöberg, Vilhelm and Gu, Ronghui and Shao, Zhong},
	editor = {Chang, Bor-Yuh Evan},
	year = {2017},
	doi = {10.1007/978-3-319-71237-6_14},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {273--297},
}

@inproceedings{ruiz_limago_2019,
	title = {Limago: {An} {FPGA}-{Based} {Open}-{Source} 100 {GbE} {TCP}/{IP} {Stack}},
	shorttitle = {Limago},
	doi = {10.1109/FPL.2019.00053},
	abstract = {The realization that the network is becoming an important bottleneck in computing clusters and in the cloud has led in the past years to an increase scrutiny of how networking functionality is deployed. From TCP Offload Engines (TOEs) to Software Defined Networking (SDN), including Smart NICs and In-Network Data Processing, a wide range of approaches are currently being explored to increase the efficiency of networks and tailor its functionality to the actual needs of the application at hand. To address the need for an open and customizable networking stack, in this paper we introduce Limago, an FPGA-based open-source implementation of a TCP/IP stack operating at 100 Gbit/s. To our knowledge, Limago provides the first complete description of an FPGA-based TCP/IP stack at these speeds, thereby illustrating the bottlenecks that must be addressed, proposing several innovative designs to reach the necessary throughput, and showing how to incorporate advanced protocol features into the design. As an example, Limago supports the TCP Window Scale option, addressing the Long Fat Pipe issue. Limago not only enables 100 Gbit/s Ethernet links in an open source package, but also paves the way to programmable and fully customizable NICs based on FPGAs.},
	booktitle = {2019 29th {International} {Conference} on {Field} {Programmable} {Logic} and {Applications} ({FPL})},
	author = {Ruiz, Mario and Sidler, David and Sutter, Gustavo and Alonso, Gustavo and López-Buedo, Sergio},
	month = sep,
	year = {2019},
	note = {ISSN: 1946-1488},
	keywords = {100 GbE FPGA TCP/IP, 100G network stack, Bandwidth, Cloud computing, FPGA Network Stack, FPGA based TCP, Field programmable gate arrays, High level Synthesis (HLS), Microsoft Windows, Open Source TCP, Open source software, TCP/IP, TCPIP, network attached FPGA, scalable TCP/IP stack architecture},
	pages = {286--292},
}

@article{arslan_nanotransport_2021,
	title = {{NanoTransport}: {A} {Low}-{Latency}, {Programmable} {Transport} {Layer} for {NICs}},
	abstract = {Transport protocols can be implemented in NIC (Network Interface Card) hardware to increase throughput, reduce latency and free up CPU cycles. If the ideal transport protocol were known, the optimal implementation would be simple: bake it into fixed-function hardware. But transport layer protocols are still evolving, with innovative new algorithms proposed every year. A recent study proposed Tonic, a Verilog-programmable transport layer in hardware. We build on this work to propose a new programmable hardware transport layer architecture, called nanoTransport, optimized for the extremely low-latency message-based RPCs (Remote Procedure Calls) that dominate large, modern distributed data center applications. NanoTransport is programmed using the P4 language, making it easy to modify existing (or create entirely new) transport protocols in hardware. We identify common events and primitive operations, allowing for a streamlined, modular, programmable pipeline, including packetization, reassembly, timeouts and packet generation, all to be expressed by the programmer.},
	language = {en},
	author = {Arslan, Serhat and Ibanez, Stephen and Mallery, Alex and Kim, Changhoon and McKeown, Nick},
	year = {2021},
	pages = {14},
}

@article{ibanez_nanopu_nodate,
	title = {The {nanoPU}: {A} {Nanosecond} {Network} {Stack} for {Datacenters}},
	abstract = {We present the nanoPU, a new NIC-CPU co-design to accelerate an increasingly pervasive class of datacenter applications: those that utilize many small Remote Procedure Calls (RPCs) with very short (µs-scale) processing times. The novel aspect of the nanoPU is the design of a fast path between the network and applications—bypassing the cache and memory hierarchy, and placing arriving messages directly into the CPU register ﬁle. This fast path contains programmable hardware support for low latency transport and congestion control as well as hardware support for efﬁcient load balancing of RPCs to cores. A hardware-accelerated thread scheduler makes subnanosecond decisions, leading to high CPU utilization and low tail response time for RPCs. We built an FPGA prototype of the nanoPU fast path by modifying an open-source RISC-V CPU, and evaluated its performance using cycle-accurate simulations on AWS FPGAs. The wire-to-wire RPC response time through the nanoPU is just 69ns, an order of magnitude quicker than the best-ofbreed, low latency, commercial NICs. We demonstrate that the hardware thread scheduler is able to lower RPC tail response time by about 5× while enabling the system to sustain 20\% higher load, relative to traditional thread scheduling techniques. We implement and evaluate a suite of applications, including MICA, Raft and Set Algebra for document retrieval; and we demonstrate that the nanoPU can be used as a high performance, programmable alternative for one-sided RDMA operations.},
	language = {en},
	author = {Ibanez, Stephen and Mallery, Alex and Arslan, Serhat and Jepsen, Theo and Shahbaz, Muhammad and Kim, Changhoon and McKeown, Nick},
	pages = {18},
}

@article{graefe_modern_2010,
	title = {Modern {B}-{Tree} {Techniques}},
	volume = {3},
	issn = {1931-7883, 1931-7891},
	url = {http://www.nowpublishers.com/article/Details/DBS-028},
	doi = {10.1561/1900000028},
	abstract = {Invented about 40 years ago and called ubiquitous less than 10 years later, B-tree indexes have been used in a wide variety of computing systems from handheld devices to mainframes and server farms. Over the years, many techniques have been added to the basic design in order to improve eﬃciency or to add functionality. Examples include separation of updates to structure or contents, utility operations such as non-logged yet transactional index creation, and robust query processing such as graceful degradation during index-to-index navigation. This survey reviews the basics of B-trees and of B-tree indexes in databases, transactional techniques and query processing techniques related to B-trees, B-tree utilities essential for database operations, and many optimizations and improvements. It is intended both as a survey and as a reference, enabling researchers to compare index innovations with advanced B-tree techniques and enabling professionals to select features, functions, and tradeoﬀs most appropriate for their data management challenges.},
	language = {en},
	number = {4},
	urldate = {2021-10-19},
	journal = {Foundations and Trends in Databases},
	author = {Graefe, Goetz},
	year = {2010},
	pages = {203--402},
}

@article{abadi_column-oriented_2009,
	title = {Column-oriented database systems},
	volume = {2},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/1687553.1687625},
	doi = {10.14778/1687553.1687625},
	abstract = {Column-oriented database systems (column-stores) have attracted a lot of attention in the past few years. Column-stores, in a nutshell, store each database table column separately, with attribute values belonging to the same column stored contiguously, compressed, and densely packed, as opposed to traditional database systems that store entire records (rows) one after the other. Reading a subset of a table's columns becomes faster, at the potential expense of excessive disk-head seeking from column to column for scattered reads or updates. After several dozens of research papers and at least a dozen of new column-store start-ups, several questions remain. Are these a new breed of systems or simply old wine in new bottles? How easily can a major row-based system achieve column-store performance? Are column-stores the answer to effortlessly support large-scale data-intensive applications? What are the new, exciting system research problems to tackle? What are the new applications that can be potentially enabled by column-stores? In this tutorial, we present an overview of column-oriented database system technology and address these and other related questions.},
	language = {en},
	number = {2},
	urldate = {2021-10-19},
	journal = {Proceedings of the VLDB Endowment},
	author = {Abadi, Daniel J. and Boncz, Peter A. and Harizopoulos, Stavros},
	month = aug,
	year = {2009},
	pages = {1664--1665},
}

@inproceedings{dageville_snowflake_2016,
	address = {San Francisco California USA},
	title = {The {Snowflake} {Elastic} {Data} {Warehouse}},
	isbn = {978-1-4503-3531-7},
	url = {https://dl.acm.org/doi/10.1145/2882903.2903741},
	doi = {10.1145/2882903.2903741},
	abstract = {We live in the golden age of distributed computing. Public cloud platforms now oﬀer virtually unlimited compute and storage resources on demand. At the same time, the Software-as-a-Service (SaaS) model brings enterprise-class systems to users who previously could not aﬀord such systems due to their cost and complexity. Alas, traditional data warehousing systems are struggling to ﬁt into this new environment. For one thing, they have been designed for ﬁxed resources and are thus unable to leverage the cloud’s elasticity. For another thing, their dependence on complex ETL pipelines and physical tuning is at odds with the ﬂexibility and freshness requirements of the cloud’s new types of semi-structured data and rapidly evolving workloads.},
	language = {en},
	urldate = {2021-10-19},
	booktitle = {Proceedings of the 2016 {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Dageville, Benoit and Cruanes, Thierry and Zukowski, Marcin and Antonov, Vadim and Avanes, Artin and Bock, Jon and Claybaugh, Jonathan and Engovatov, Daniel and Hentschel, Martin and Huang, Jiansheng and Lee, Allison W. and Motivala, Ashish and Munir, Abdul Q. and Pelley, Steven and Povinec, Peter and Rahn, Greg and Triantafyllis, Spyridon and Unterbrunner, Philipp},
	month = jun,
	year = {2016},
	pages = {215--226},
}

@article{sherkat_native_2019,
	title = {Native store extension for {SAP} {HANA}},
	volume = {12},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3352063.3352123},
	doi = {10.14778/3352063.3352123},
	abstract = {We present an overview of SAP HANA’s Native Store Extension (NSE). This extension substantially increases database capacity, allowing to scale far beyond available system memory. NSE is based on a hybrid in-memory and paged column store architecture composed from data access primitives. These primitives enable the processing of hybrid columns using the same algorithms optimized for traditional HANA’s in-memory columns. Using only three key primitives, we fabricated byte-compatible counterparts for complex memory resident data structures (e.g. dictionary and hash-index), compressed schemes (e.g. sparse and run-length encoding), and exotic data types (e.g. geo-spatial). We developed a new buﬀer cache which optimizes the management of paged resources by smart strategies sensitive to page type and access patterns. The buﬀer cache integrates with HANA’s new execution engine that issues pipelined prefetch requests to improve disk access patterns. A novel load unit conﬁguration, along with a uniﬁed persistence format, allows the hybrid column store to dynamically switch between inmemory and paged data access to balance performance and storage economy according to application demands while reducing Total Cost of Ownership (TCO). A new partitioning scheme supports load unit speciﬁcation at table, partition, and column level. Finally, a new advisor recommends optimal load unit conﬁgurations. Our experiments illustrate the performance and memory footprint improvements on typical customer scenarios.},
	language = {en},
	number = {12},
	urldate = {2021-10-19},
	journal = {Proceedings of the VLDB Endowment},
	author = {Sherkat, Reza and Florendo, Colin and Andrei, Mihnea and Blanco, Rolando and Dragusanu, Adrian and Pathak, Amit and Khadilkar, Pushkar and Kulkarni, Neeraj and Lemke, Christian and Seifert, Sebastian and Iyer, Sarika and Gottapu, Sasikanth and Schulze, Robert and Gottipati, Chaitanya and Basak, Nirvik and Wang, Yanhong and Kandiyanallur, Vivek and Pendap, Santosh and Gala, Dheren and Almeida, Rajesh and Ghosh, Prasanta},
	month = aug,
	year = {2019},
	pages = {2047--2058},
}

@article{naur_proof_nodate,
	title = {Proof of algorithms by general snapshots},
	abstract = {A constructive approach to the question of proofs of algorithms is to consider proofs that an object resulting from the execution of an algorithm possesses certain static characteristics. It is shown by an elementary example how this possibility may be used to prove the correctness of an algorithm written in ALGOL 60. The stepping stone of the approach is what is called General Snapshots, i.e. expressions of static conditions existing whenever the execution of the algorithm reaches particular points. General Snapshots are further shown to be useful for constructing algorithms.},
	language = {en},
	author = {Naur, Peter},
	pages = {7},
}

@inproceedings{graefe_hybrid_2013,
	address = {Barcelona, Spain},
	title = {A hybrid page layout integrating {PAX} and {NSM}},
	isbn = {978-1-4503-2025-2},
	url = {http://dl.acm.org/citation.cfm?doid=2513591.2513643},
	doi = {10.1145/2513591.2513643},
	abstract = {The paper explores a hybrid page layout (HPL), combining the advantages of NSM and PAX. The design deﬁnes a continuum between NSM and PAX supporting both e cient scans minimizing cache faults and e cient insertions and updates. Our evaluation shows that HPL ﬁlls the PAX-NSM performance gap.},
	language = {en},
	urldate = {2021-10-18},
	booktitle = {Proceedings of the 17th {International} {Database} {Engineering} \& {Applications} {Symposium} on - {IDEAS} '13},
	publisher = {ACM Press},
	author = {Graefe, Goetz and Petrov, Ilia and Ivanov, Todor and Marinov, Veselin},
	year = {2013},
	pages = {86--95},
}

@article{ailamaki_data_2002,
	title = {Data page layouts for relational databases on deep memory hierarchies},
	volume = {11},
	issn = {10668888},
	url = {http://link.springer.com/10.1007/s00778-002-0074-9},
	doi = {10.1007/s00778-002-0074-9},
	abstract = {Relational database systems have traditionally optimized for I/O performance and organized records sequentially on disk pages using the N-ary Storage Model (NSM) (a.k.a., slotted pages). Recent research, however, indicates that cache utilization and performance is becoming increasingly important on modern platforms. In this paper, we ﬁrst demonstrate that in-page data placement is the key to high cache performance and that NSM exhibits low cache utilization on modern platforms. Next, we propose a new data organization model called PAX (Partition Attributes Across), that signiﬁcantly improves cache performance by grouping together all values of each attribute within each page. Because PAX only affects layout inside the pages, it incurs no storage penalty and does not affect I/O behavior. According to our experimental results (which were obtained without using any indices on the participating relations), when compared to NSM: (a) PAX exhibits superior cache and memory bandwidth utilization, saving at least 75\% of NSM’s stall time due to data cache accesses; (b) range selection queries and updates on memory-resident relations execute 17–25\% faster; and (c) TPC-H queries involving I/O execute 11–48\% faster. Finally, we show that PAX performs well across different memory system designs.},
	language = {en},
	number = {3},
	urldate = {2021-10-18},
	journal = {The VLDB Journal The International Journal on Very Large Data Bases},
	author = {Ailamaki, Anastassia and DeWitt, David J. and Hill, Mark D.},
	month = nov,
	year = {2002},
	pages = {198--215},
}

@article{chou_evaluation_1986,
	title = {An evaluation of buffer management strategies for relational database systems},
	volume = {1},
	issn = {0178-4617, 1432-0541},
	url = {http://link.springer.com/10.1007/BF01840450},
	doi = {10.1007/BF01840450},
	abstract = {In this paper we present a new algorithm, DBMIN, for managing the buffer pool of a relational database management system. DBMIN is based on a new model of relational query behavior, the query locality set model (QLSM). Like the hot set model, the QLSM has an advantage over the stochastic models due to its ability to predict future reference behavior. However, the QLSM avoids the potential problems of the hot set model by separating the modeling of reference behavior from any particular buffer management algorithm. After introducing the QLSM and describing the DBMIN algorithm, we present a performance evaluation methodology for evaluating buffer management algorithms in a multiuser environment. This methodology employed a hybrid model that combines features of both trace-driven and distribution-driven simulation models. Using this model, the performance of the DBMIN algorithm in a multiuser environment is compared with that of the hot set algorithm and four more traditional buffer replacement algorithms.},
	language = {en},
	number = {1-4},
	urldate = {2021-10-18},
	journal = {Algorithmica},
	author = {Chou, Hong -Tai and DeWitt, David J.},
	month = nov,
	year = {1986},
	pages = {311--336},
}

@article{chou_evaluation_1986-1,
	title = {An evaluation of buffer management strategies for relational database systems},
	volume = {1},
	issn = {0178-4617, 1432-0541},
	url = {http://link.springer.com/10.1007/BF01840450},
	doi = {10.1007/BF01840450},
	abstract = {In this paper we present a new algorithm, DBMIN, for managing the buffer pool of a relational database management system. DBMIN is based on a new model of relational query behavior, the query locality set model (QLSM). Like the hot set model, the QLSM has an advantage over the stochastic models due to its ability to predict future reference behavior. However, the QLSM avoids the potential problems of the hot set model by separating the modeling of reference behavior from any particular buffer management algorithm. After introducing the QLSM and describing the DBMIN algorithm, we present a performance evaluation methodology for evaluating buffer management algorithms in a multiuser environment. This methodology employed a hybrid model that combines features of both trace-driven and distribution-driven simulation models. Using this model, the performance of the DBMIN algorithm in a multiuser environment is compared with that of the hot set algorithm and four more traditional buffer replacement algorithms.},
	language = {en},
	number = {1-4},
	urldate = {2021-10-03},
	journal = {Algorithmica},
	author = {Chou, Hong -Tai and DeWitt, David J.},
	month = nov,
	year = {1986},
	pages = {311--336},
}

@article{yang_foundations_nodate,
	title = {Foundations of {Cryptography}   – {Digital} {Signature} {Schemes}},
	language = {en},
	author = {Yang, Guang},
	pages = {110},
}

@article{yang_foundations_nodate-1,
	title = {Foundations of {Cryptography}   – {CDH}/{DDH}-based {Encryption} and {RSA} {Encryption}},
	language = {en},
	author = {Yang, Guang},
	pages = {75},
}

@article{yang_foundations_nodate-2,
	title = {Foundations of {Cryptography}   – {Key} {Management} and the {Public}-{Key} {Revolution}},
	language = {en},
	author = {Yang, Guang},
	pages = {82},
}

@article{yang_foundations_nodate-3,
	title = {Foundations of {Cryptography}   – {Number} {Theory} and {Cryptographic} {Hardness} {Assummptions}},
	language = {en},
	author = {Yang, Guang},
	pages = {80},
}

@article{yang_foundations_nodate-4,
	title = {Foundations of {Cryptography}   – {Practical} {Constructions} of {Symmetric}-{Key} {Primitives}},
	language = {en},
	author = {Yang, Guang},
	pages = {60},
}

@article{yang_foundations_nodate-5,
	title = {Foundations of {Cryptography}   – {Theoretical} {Constructions} of {Symmetric}-{Key} {Primitives}},
	language = {en},
	author = {Yang, Guang},
	pages = {49},
}

@article{katz_introduction_nodate,
	title = {Introduction to {Secure} {Computation}, part 3},
	language = {en},
	author = {Katz, Jonathan},
	pages = {49},
}

@article{katz_introduction_nodate-1,
	title = {Introduction to {Secure} {Computation}, part 2},
	language = {en},
	author = {Katz, Jonathan},
	pages = {40},
}

@article{katz_introduction_nodate-2,
	title = {Introduction to {Secure} {Computation}, part},
	language = {en},
	author = {Katz, Jonathan},
	pages = {58},
}

@article{yang_foundations_nodate-6,
	title = {Foundations of {Cryptography}   – {Cryptographic} ({Collision}-{Resistant}) {Hash} {Functions}},
	language = {en},
	author = {Yang, Guang},
	pages = {56},
}

@article{yang_foundations_nodate-7,
	title = {Foundations of {Cryptography}   – {Message} {Authentication} and {Hash} {Functions}},
	language = {en},
	author = {Yang, Guang},
	pages = {77},
}

@article{yang_foundations_nodate-8,
	title = {Foundations of {Cryptography}   – {Private}-{Key} {Encryption}},
	language = {en},
	author = {Yang, Guang},
	pages = {144},
}

@article{yang_foundation_nodate,
	title = {Foundation of {Cryptography}   – {Classical} to {Modern} {Cryptography}},
	language = {en},
	author = {Yang, Guang},
	pages = {74},
}

@article{di_girolamo_pspin_2021,
	title = {{PsPIN}: {A} high-performance low-power architecture for flexible in-network compute},
	shorttitle = {{PsPIN}},
	url = {http://arxiv.org/abs/2010.03536},
	abstract = {The capacity of offloading data and control tasks to the network is becoming increasingly important, especially if we consider the faster growth of network speed when compared to CPU frequencies. In-network compute alleviates the host CPU load by running tasks directly in the network, enabling additional computation/communication overlap and potentially improving overall application performance. However, sustaining bandwidths provided by next-generation networks, e.g., 400 Gbit/s, can become a challenge. sPIN is a programming model for in-NIC compute, where users specify handler functions that are executed on the NIC, for each incoming packet belonging to a given message or flow. It enables a CUDA-like acceleration, where the NIC is equipped with lightweight processing elements that process network packets in parallel. We investigate the architectural specialties that a sPIN NIC should provide to enable high-performance, low-power, and flexible packet processing. We introduce PsPIN, a first open-source sPIN implementation, based on a multi-cluster RISC-V architecture and designed according to the identified architectural specialties. We investigate the performance of PsPIN with cycle-accurate simulations, showing that it can process packets at 400 Gbit/s for several use cases, introducing minimal latencies (26 ns for 64 B packets) and occupying a total area of 18.5 mm 2 (22 nm FDSOI).},
	urldate = {2021-10-01},
	journal = {arXiv:2010.03536 [cs]},
	author = {Di Girolamo, Salvatore and Kurth, Andreas and Calotoiu, Alexandru and Benz, Thomas and Schneider, Timo and Beránek, Jakub and Benini, Luca and Hoefler, Torsten},
	month = jun,
	year = {2021},
	note = {arXiv: 2010.03536},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Networking and Internet Architecture},
}

@article{hellerstein_architecture_2007,
	title = {Architecture of a {Database} {System}},
	volume = {1},
	issn = {1931-7883, 1931-7891},
	url = {http://www.nowpublishers.com/article/Details/DBS-002},
	doi = {10.1561/1900000002},
	abstract = {Database Management Systems (DBMSs) are a ubiquitous and critical component of modern computing, and the result of decades of research and development in both academia and industry. Historically, DBMSs were among the earliest multi-user server systems to be developed, and thus pioneered many systems design techniques for scalability and reliability now in use in many other contexts. While many of the algorithms and abstractions used by a DBMS are textbook material, there has been relatively sparse coverage in the literature of the systems design issues that make a DBMS work. This paper presents an architectural discussion of DBMS design principles, including process models, parallel architecture, storage system design, transaction system implementation, query processor and optimizer architectures, and typical shared components and utilities. Successful commercial and open-source systems are used as points of reference, particularly when multiple alternative designs have been adopted by diﬀerent groups.},
	language = {en},
	number = {2},
	urldate = {2021-09-26},
	journal = {Foundations and Trends® in Databases},
	author = {Hellerstein, Joseph M. and Stonebraker, Michael and Hamilton, James},
	year = {2007},
	pages = {141--259},
}

@article{kwon_maestro_2020,
	title = {{MAESTRO}: {A} {Data}-{Centric} {Approach} to {Understand} {Reuse}, {Performance}, and {Hardware} {Cost} of {DNN} {Mappings}},
	volume = {40},
	issn = {1937-4143},
	shorttitle = {{MAESTRO}},
	doi = {10.1109/MM.2020.2985963},
	abstract = {The efficiency of an accelerator depends on three factors-mapping, deep neural network (DNN) layers, and hardware-constructing extremely complicated design space of DNN accelerators. To demystify such complicated design space and guide the DNN accelerator design for better efficiency, we propose an analytical cost model, MAESTRO. MAESTRO receives DNN model description and hardware resources information as a list, and mapping described in a data-centric representation we propose as inputs. The data-centric representation consists of three directives that enable concise description of mappings in a compiler-friendly form. MAESTRO analyzes various forms of data reuse in an accelerator based on inputs quickly and generates more than 20 statistics including total latency, energy, throughput, etc., as outputs. MAESTRO's fast analysis enables various optimization tools for DNN accelerators such as hardware design exploration tool we present as an example.},
	number = {3},
	journal = {IEEE Micro},
	author = {Kwon, Hyoukjun and Chatarasi, Prasanth and Sarkar, Vivek and Krishna, Tushar and Pellauer, Michael and Parashar, Angshuman},
	month = may,
	year = {2020},
	note = {Conference Name: IEEE Micro},
	keywords = {Analytical models, Buffer storage, Cost modeling, Dataflow, Deep neural networks, Estimation, Neural networks, Single-photon avalanche diodes, Spatial accelerators},
	pages = {20--29},
}

@inproceedings{prabhakar_plasticine_2017,
	address = {Toronto ON Canada},
	title = {Plasticine: {A} {Reconfigurable} {Architecture} {For} {Parallel} {Paterns}},
	isbn = {978-1-4503-4892-8},
	shorttitle = {Plasticine},
	url = {https://dl.acm.org/doi/10.1145/3079856.3080256},
	doi = {10.1145/3079856.3080256},
	abstract = {Reconfigurable architectures have gained popularity in recent years as they allow the design of energy-efficient accelerators. Fine-grain fabrics (e.g. FPGAs) have traditionally suffered from performance and power inefficiencies due to bit-level reconfigurable abstractions. Both fine-grain and coarse-grain architectures (e.g. CGRAs) traditionally require low level programming and suffer from long compilation times. We address both challenges with Plasticine, a new spatially reconfigurable architecture designed to efficiently execute applications composed of parallel patterns. Parallel patterns have emerged from recent research on parallel programming as powerful, high-level abstractions that can elegantly capture data locality, memory access patterns, and parallelism across a wide range of dense and sparse applications. We motivate Plasticine by first observing key application characteristics captured by parallel patterns that are amenable to hardware acceleration, such as hierarchical parallelism, data locality, memory access patterns, and control flow. Based on these observations, we architect Plasticine as a collection of Pattern Compute Units and Pattern Memory Units. Pattern Compute Units are multi-stage pipelines of reconfigurable SIMD functional units that can efficiently execute nested patterns. Data locality is exploited in Pattern Memory Units using banked scratchpad memories and configurable address decoders. Multiple on-chip address generators and scatter-gather engines make efficient use of DRAM bandwidth by supporting a large number of outstanding memory requests, memory coalescing, and burst mode for dense accesses. Plasticine has an area footprint of 113 mm2 in a 28nm process, and consumes a maximum power of 49 W at a 1 GHz clock. Using a cycle-accurate simulator, we demonstrate that Plasticine provides an improvement of up to 76.9× in performance-per-Watt over a conventional FPGA over a wide range of dense and sparse applications.},
	language = {en},
	urldate = {2021-08-03},
	booktitle = {Proceedings of the 44th {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {ACM},
	author = {Prabhakar, Raghu and Zhang, Yaqi and Koeplinger, David and Feldman, Matt and Zhao, Tian and Hadjis, Stefan and Pedram, Ardavan and Kozyrakis, Christos and Olukotun, Kunle},
	month = jun,
	year = {2017},
	pages = {389--402},
}

@article{rucker_capstan_2021,
	title = {Capstan: {A} {Vector} {RDA} for {Sparsity}},
	shorttitle = {Capstan},
	url = {http://arxiv.org/abs/2104.12760},
	abstract = {This paper proposes Capstan: a scalable, parallel-patterns-based, reconfigurable-dataflow accelerator (RDA) for sparse and dense tensor applications. Instead of designing for one application, we start with common sparse data formats, each of which supports multiple applications. Using a declarative programming model, Capstan supports application-independent sparse iteration and memory primitives that can be mapped to vectorized, high-performance hardware. We optimize random-access sparse memories with configurable out-of-order execution to increase SRAM random-access throughput from 32\% to 80\%. For a variety of sparse applications, Capstan with DDR4 memory is 22x faster than a multi-core CPU baseline, while Capstan with HBM2 memory is 17x faster than an Nvidia V100 GPU. For sparse applications that can be mapped to Plasticine, a recent dense RDA, Capstan is 7.6x to 365x faster and only 13\% larger.},
	urldate = {2021-08-03},
	journal = {arXiv:2104.12760 [cs]},
	author = {Rucker, Alexander and Vilim, Matthew and Zhao, Tian and Zhang, Yaqi and Prabhakar, Raghu and Olukotun, Kunle},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.12760},
	keywords = {Computer Science - Hardware Architecture},
}

@article{xiao_hasco_nodate,
	title = {{HASCO}: {Towards} {Agile} {HArdware} and {Software} {CO}-design for {Tensor} {Computation}},
	abstract = {Tensor computations overwhelm traditional generalpurpose computing devices due to the large amounts of data and operations of the computations. They call for a holistic solution composed of both hardware acceleration and software mapping. Hardware/software (HW/SW) co-design optimizes the hardware and software in concert and produces high-quality solutions. There are two main challenges in the co-design ﬂow. First, multiple methods exist to partition tensor computation and have different impacts on performance and energy efﬁciency. Besides, the hardware part must be implemented by the intrinsic functions of spatial accelerators. It is hard for programmers to identify and analyze the partitioning methods manually. Second, the overall design space composed of HW/SW partitioning, hardware optimization, and software optimization is huge. The design space needs to be efﬁciently explored.},
	language = {en},
	author = {Xiao, Qingcheng and Zheng, Size and Wu, Bingzhe},
	pages = {14},
}

@article{lu_tenet_nodate,
	title = {{TENET}: {A} {Framework} for {Modeling} {Tensor} {Dataﬂow} {Based} on {Relation}-centric {Notation}},
	abstract = {Accelerating tensor applications on spatial architectures provides high performance and energy-efﬁciency, but requires accurate performance models for evaluating various dataﬂow alternatives. Such modeling relies on the notation of tensor dataﬂow and the formulation of performance metrics. Recent proposed compute-centric and data-centric notations describe the dataﬂow using imperative directives. However, these two notations are less expressive and thus lead to limited optimization opportunities and inaccurate performance models.},
	language = {en},
	author = {Lu, Liqiang and Luo, Zizhang and Guan, Naiqing and Wang, Yuyue and Jia, Liancheng and Yin, Jieming and Cong, Jason and Liang, Yun},
	pages = {14},
}

@article{jia_tensorlib_2021,
	title = {{TensorLib}: {A} {Spatial} {Accelerator} {Generation} {Framework} for {Tensor} {Algebra}},
	shorttitle = {{TensorLib}},
	url = {http://arxiv.org/abs/2104.12339},
	abstract = {Tensor algebra finds applications in various domains, and these applications, especially when accelerated on spatial hardware accelerators, can deliver high performance and low power. Spatial hardware accelerator exhibits complex design space. Prior approaches based on manual implementation lead to low programming productivity, rendering thorough design space exploration impossible. In this paper, we propose TensorLib, a framework for generating spatial hardware accelerator for tensor algebra applications. TensorLib is motivated by the observation that, different dataflows share common hardware modules, which can be reused across different designs. To build such a framework, TensorLib first uses Space-Time Transformation to explore different dataflows, which can compactly represent the hardware dataflow using a simple transformation matrix. Next, we identify the common structures of different dataflows and build parameterized hardware module templates with Chisel. Our generation framework can select the needed hardware modules for each dataflow, connect the modules using a specified interconnection pattern, and automatically generate the complete hardware accelerator design. TensorLib remarkably improves the productivity for the development and optimization of spatial hardware architecture, providing a rich design space with trade-offs in performance, area, and power. Experiments show that TensorLib can automatically generate hardware designs with different dataflows and achieve 21{\textbackslash}\% performance improvement on FPGA compared to the state-of-the-arts.},
	urldate = {2021-07-29},
	journal = {arXiv:2104.12339 [cs]},
	author = {Jia, Liancheng and Luo, Zizhang and Lu, Liqiang and Liang, Yun},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.12339},
	keywords = {Computer Science - Hardware Architecture},
}

@inproceedings{venkataramani_scaledeep_2017,
	title = {{SCALEDEEP}: {A} scalable compute architecture for learning and evaluating deep networks},
	shorttitle = {{SCALEDEEP}},
	doi = {10.1145/3079856.3080244},
	abstract = {Deep Neural Networks (DNNs) have demonstrated state-of-the-art performance on a broad range of tasks involving natural language, speech, image, and video processing, and are deployed in many real world applications. However, DNNs impose significant computational challenges owing to the complexity of the networks and the amount of data they process, both of which are projected to grow in the future. To improve the efficiency of DNNs, we propose SCALEDEEP, a dense, scalable server architecture, whose processing, memory and interconnect subsystems are specialized to leverage the compute and communication characteristics of DNNs. While several DNN accelerator designs have been proposed in recent years, the key difference is that SCALEDEEP primarily targets DNN training, as opposed to only inference or evaluation. The key architectural features from which SCALEDEEP derives its efficiency are: (i) heterogeneous processing tiles and chips to match the wide diversity in computational characteristics (FLOPs and Bytes/FLOP ratio) that manifest at different levels of granularity in DNNs, (ii) a memory hierarchy and 3-tiered interconnect topology that is suited to the memory access and communication patterns in DNNs, (iii) a low-overhead synchronization mechanism based on hardware data-flow trackers, and (iv) methods to map DNNs to the proposed architecture that minimize data movement and improve core utilization through nested pipelining. We have developed a compiler to allow any DNN topology to be programmed onto SCALEDEEP, and a detailed architectural simulator to estimate performance and energy. The simulator incorporates timing and power models of SCALEDEEP's components based on synthesis to Intel's 14nm technology. We evaluate an embodiment of SCALEDEEP with 7032 processing tiles that operates at 600 MHz and has a peak performance of 680 TFLOPs (single precision) and 1.35 PFLOPs (half-precision) at 1.4KW. Across 11 state-of-the-art DNNs containing 0.65M-14.9M neurons and 6.8M-145.9M weights, including winners from 5 years of the ImageNet competition, SCALEDEEP demonstrates 6×-28× speedup at iso-power over the state-of-the-art performance on GPUs.},
	booktitle = {2017 {ACM}/{IEEE} 44th {Annual} {International} {Symposium} on {Computer} {Architecture} ({ISCA})},
	author = {Venkataramani, Swagath and Ranjan, Ashish and Banerjee, Subarno and Das, Dipankar and Avancha, Sasikanth and Jagannathan, Ashok and Durg, Ajaya and Nagaraj, Dheemanth and Kaul, Bharat and Dubey, Pradeep and Raghunathan, Anand},
	month = jun,
	year = {2017},
	keywords = {Computer architecture, Deep Neural Networks, Hardware, Hardware Accelerators, Neurons, Parallel processing, Servers, System Architecture, Topology, Training},
	pages = {13--26},
}

@article{yang_interstellar_2020,
	title = {Interstellar: {Using} {Halide}'s {Scheduling} {Language} to {Analyze} {DNN} {Accelerators}},
	shorttitle = {Interstellar},
	url = {http://arxiv.org/abs/1809.04070},
	doi = {10.1145/3373376.3378514},
	abstract = {We show that DNN accelerator micro-architectures and their program mappings represent specific choices of loop order and hardware parallelism for computing the seven nested loops of DNNs, which enables us to create a formal taxonomy of all existing dense DNN accelerators. Surprisingly, the loop transformations needed to create these hardware variants can be precisely and concisely represented by Halide's scheduling language. By modifying the Halide compiler to generate hardware, we create a system that can fairly compare these prior accelerators. As long as proper loop blocking schemes are used, and the hardware can support mapping replicated loops, many different hardware dataflows yield similar energy efficiency with good performance. This is because the loop blocking can ensure that most data references stay on-chip with good locality and the processing units have high resource utilization. How resources are allocated, especially in the memory system, has a large impact on energy and performance. By optimizing hardware resource allocation while keeping throughput constant, we achieve up to 4.2X energy improvement for Convolutional Neural Networks (CNNs), 1.6X and 1.8X improvement for Long Short-Term Memories (LSTMs) and multi-layer perceptrons (MLPs), respectively.},
	urldate = {2021-07-28},
	journal = {Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems},
	author = {Yang, Xuan and Gao, Mingyu and Liu, Qiaoyi and Setter, Jeff Ou and Pu, Jing and Nayak, Ankita and Bell, Steven Emberton and Cao, Kaidi and Ha, Heonjae and Raina, Priyanka and Kozyrakis, Christos and Horowitz, Mark},
	month = mar,
	year = {2020},
	note = {arXiv: 1809.04070},
	keywords = {C.1.4, C.3, C.4, Computer Science - Distributed, Parallel, and Cluster Computing},
	pages = {369--383},
}

@misc{noauthor_eyeriss_nodate,
	title = {eyeriss v2 - {Google} {Suche}},
	url = {https://www.google.com/search?q=eyeriss+v2&newwindow=1&rlz=1C5CHFA_enDE933DE933&sxsrf=ALeKk01jkN6eBXm8njOgKv_fXp-4kQ2JlQ%3A1627459247689&ei=rw4BYby8KY799QOW3pKAAQ&oq=eyeriss+paper&gs_lcp=Cgdnd3Mtd2l6EAEYADIHCAAQRxCwAzIHCAAQRxCwAzIHCAAQRxCwAzIHCAAQRxCwAzIHCAAQRxCwAzIHCAAQRxCwAzIHCAAQRxCwAzIHCAAQRxCwA0oECEEYAFAAWABgoxpoAXACeACAAb0BiAG9AZIBAzAuMZgBAMgBCMABAQ&sclient=gws-wiz},
	urldate = {2021-07-28},
}

@article{chen_eyeriss_2019,
	title = {Eyeriss v2: {A} {Flexible} {Accelerator} for {Emerging} {Deep} {Neural} {Networks} on {Mobile} {Devices}},
	shorttitle = {Eyeriss v2},
	url = {http://arxiv.org/abs/1807.07928},
	abstract = {A recent trend in DNN development is to extend the reach of deep learning applications to platforms that are more resource and energy constrained, e.g., mobile devices. These endeavors aim to reduce the DNN model size and improve the hardware processing efficiency, and have resulted in DNNs that are much more compact in their structures and/or have high data sparsity. These compact or sparse models are different from the traditional large ones in that there is much more variation in their layer shapes and sizes, and often require specialized hardware to exploit sparsity for performance improvement. Thus, many DNN accelerators designed for large DNNs do not perform well on these models. In this work, we present Eyeriss v2, a DNN accelerator architecture designed for running compact and sparse DNNs. To deal with the widely varying layer shapes and sizes, it introduces a highly flexible on-chip network, called hierarchical mesh, that can adapt to the different amounts of data reuse and bandwidth requirements of different data types, which improves the utilization of the computation resources. Furthermore, Eyeriss v2 can process sparse data directly in the compressed domain for both weights and activations, and therefore is able to improve both processing speed and energy efficiency with sparse models. Overall, with sparse MobileNet, Eyeriss v2 in a 65nm CMOS process achieves a throughput of 1470.6 inferences/sec and 2560.3 inferences/J at a batch size of 1, which is 12.6x faster and 2.5x more energy efficient than the original Eyeriss running MobileNet. We also present an analysis methodology called Eyexam that provides a systematic way of understanding the performance limits for DNN processors as a function of specific characteristics of the DNN model and accelerator design; it applies these characteristics as sequential steps to increasingly tighten the bound on the performance limits.},
	urldate = {2021-07-28},
	journal = {arXiv:1807.07928 [cs]},
	author = {Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel and Sze, Vivienne},
	month = may,
	year = {2019},
	note = {arXiv: 1807.07928},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Distributed, Parallel, and Cluster Computing},
}

@inproceedings{chen_eyeriss_2016,
	title = {Eyeriss: {A} {Spatial} {Architecture} for {Energy}-{Efficient} {Dataflow} for {Convolutional} {Neural} {Networks}},
	shorttitle = {Eyeriss},
	doi = {10.1109/ISCA.2016.40},
	abstract = {Deep convolutional neural networks (CNNs) are widely used in modern AI systems for their superior accuracy but at the cost of high computational complexity. The complexity comes from the need to simultaneously process hundreds of filters and channels in the high-dimensional convolutions, which involve a significant amount of data movement. Although highly-parallel compute paradigms, such as SIMD/SIMT, effectively address the computation requirement to achieve high throughput, energy consumption still remains high as data movement can be more expensive than computation. Accordingly, finding a dataflow that supports parallel processing with minimal data movement cost is crucial to achieving energy-efficient CNN processing without compromising accuracy. In this paper, we present a novel dataflow, called row-stationary (RS), that minimizes data movement energy consumption on a spatial architecture. This is realized by exploiting local data reuse of filter weights and feature map pixels, i.e., activations, in the high-dimensional convolutions, and minimizing data movement of partial sum accumulations. Unlike dataflows used in existing designs, which only reduce certain types of data movement, the proposed RS dataflow can adapt to different CNN shape configurations and reduces all types of data movement through maximally utilizing the processing engine (PE) local storage, direct inter-PE communication and spatial parallelism. To evaluate the energy efficiency of the different dataflows, we propose an analysis framework that compares energy cost under the same hardware area and processing parallelism constraints. Experiments using the CNN configurations of AlexNet show that the proposed RS dataflow is more energy efficient than existing dataflows in both convolutional (1.4× to 2.5×) and fully-connected layers (at least 1.3× for batch size larger than 16). The RS dataflow has also been demonstrated on a fabricated chip, which verifies our energy analysis.},
	booktitle = {2016 {ACM}/{IEEE} 43rd {Annual} {International} {Symposium} on {Computer} {Architecture} ({ISCA})},
	author = {Chen, Yu-Hsin and Emer, Joel and Sze, Vivienne},
	month = jun,
	year = {2016},
	note = {ISSN: 1063-6897},
	keywords = {Arrays, Convolutional Neural Networks, Dataflow, Energy Efficiency, Parallel processing, Radio frequency, Random access memory, Shape, Spatial Architecture, Throughput},
	pages = {367--379},
}

@article{genc_gemmini_2021,
	title = {Gemmini: {Enabling} {Systematic} {Deep}-{Learning} {Architecture} {Evaluation} via {Full}-{Stack} {Integration}},
	shorttitle = {Gemmini},
	url = {http://arxiv.org/abs/1911.09925},
	abstract = {DNN accelerators are often developed and evaluated in isolation without considering the cross-stack, system-level effects in real-world environments. This makes it difficult to appreciate the impact of System-on-Chip (SoC) resource contention, OS overheads, and programming-stack inefficiencies on overall performance/energy-efficiency. To address this challenge, we present Gemmini, an open-source*, full-stack DNN accelerator generator. Gemmini generates a wide design-space of efficient ASIC accelerators from a flexible architectural template, together with flexible programming stacks and full SoCs with shared resources that capture system-level effects. Gemmini-generated accelerators have also been fabricated, delivering up to three orders-of-magnitude speedups over high-performance CPUs on various DNN benchmarks. * https://github.com/ucb-bar/gemmini},
	urldate = {2021-07-22},
	journal = {arXiv:1911.09925 [cs]},
	author = {Genc, Hasan and Kim, Seah and Amid, Alon and Haj-Ali, Ameer and Iyer, Vighnesh and Prakash, Pranav and Zhao, Jerry and Grubb, Daniel and Liew, Harrison and Mao, Howard and Ou, Albert and Schmidt, Colin and Steffl, Samuel and Wright, John and Stoica, Ion and Ragan-Kelley, Jonathan and Asanovic, Krste and Nikolic, Borivoje and Shao, Yakun Sophia},
	month = jul,
	year = {2021},
	note = {arXiv: 1911.09925},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Hardware Architecture, Computer Science - Machine Learning, Computer Science - Performance},
}

@article{hennessy_computer_nodate,
	title = {Computer {Architecture}: {A} {Quantitative} {Approach}},
	language = {en},
	author = {Hennessy, John L},
	pages = {1527},
}

@misc{noauthor_morgan_nodate,
	title = {[{The} {Morgan} {Kaufmann} {Series} in {Computer} {Architecture} and {Design}] {John} {L}. {Hennessy}, {David} {A}. {Patterson} - {Computer} {Architecture}, {Sixth} {Edition}\_ {A} {Quantitative} {Approach} (2017, {Morgan} {Kaufmann}).pdf},
	url = {https://drive.google.com/file/d/1i4dY8jOw_lcx5PN69WaskMDTQPHlyEW8/view?usp=sharing&usp=embed_facebook},
	urldate = {2021-07-15},
	journal = {Google Docs},
}

@article{naffziger_pioneering_nodate,
	title = {Pioneering {Chiplet} {Technology} and {Design} for the {AMD} {EPYC}™ and {Ryzen}™ {Processor} {Families}: {Industrial} {Product}},
	abstract = {For decades, Moore’s Law has delivered the ability to integrate an exponentially increasing number of devices in the same silicon area at a roughly constant cost. This has enabled tremendous levels of integration, where the capabilities of computer systems that previously occupied entire rooms can now fit on a single integrated circuit.},
	language = {en},
	author = {Naffziger, Samuel and Devices, Advanced Micro},
	pages = {14},
}

@inproceedings{he_sparse-tpu_2020,
	address = {Barcelona Spain},
	title = {Sparse-{TPU}: adapting systolic arrays for sparse matrices},
	isbn = {978-1-4503-7983-0},
	shorttitle = {Sparse-{TPU}},
	url = {https://dl.acm.org/doi/10.1145/3392717.3392751},
	doi = {10.1145/3392717.3392751},
	abstract = {While systolic arrays are widely used for dense-matrix operations, they are seldom used for sparse-matrix operations. In this paper, we show how a systolic array of Multiply-and-Accumulate (MAC) units, similar to Google’s Tensor Processing Unit (TPU), can be adapted to efficiently handle sparse matrices. TPU-like accelerators are built upon a 2D array of MAC units and have demonstrated high throughput and efficiency for dense matrix multiplication, which is a key kernel in machine learning algorithms and is the target of the TPU. In this work, we employ a co-designed approach of first developing a packing technique to condense a sparse matrix and then propose a systolic array based system, Sparse-TPU, abbreviated to STPU, to accommodate the matrix computations for the packed denser matrix counterparts. To demonstrate the efficacy of our co-designed approach, we evaluate sparse matrix-vector multiplication on a broad set of synthetic and real-world sparse matrices. Experimental results show that STPU delivers 16.08× higher performance while consuming 4.39× and 19.79× lower energy for integer (int8) and floating point (float32) implementations, respectively, over a TPU baseline. Meanwhile, STPU has 12.93\% area overhead and an average of 4.14\% increase in dynamic energy over the TPU baseline for the float32 implementation.},
	language = {en},
	urldate = {2021-06-20},
	booktitle = {Proceedings of the 34th {ACM} {International} {Conference} on {Supercomputing}},
	publisher = {ACM},
	author = {He, Xin and Pal, Subhankar and Amarnath, Aporva and Feng, Siying and Park, Dong-Hyeon and Rovinski, Austin and Ye, Haojie and Chen, Yuhan and Dreslinski, Ronald and Mudge, Trevor},
	month = jun,
	year = {2020},
	pages = {1--12},
}

@inproceedings{karageorgos_hardware-software_2020,
	address = {Valencia, Spain},
	title = {Hardware-{Software} {Co}-{Design} for {Brain}-{Computer} {Interfaces}},
	isbn = {978-1-72814-661-4},
	url = {https://ieeexplore.ieee.org/document/9138938/},
	doi = {10.1109/ISCA45697.2020.00041},
	abstract = {Brain-computer interfaces (BCIs) offer avenues to treat neurological disorders, shed light on brain function, and interface the brain with the digital world. Their wider adoption rests, however, on achieving adequate real-time performance, meeting stringent power constraints, and adhering to FDAmandated safety requirements for chronic implantation. BCIs have, to date, been designed as custom ASICs for speciﬁc diseases or for speciﬁc tasks in speciﬁc brain regions. General-purpose architectures that can be used to treat multiple diseases and enable various computational tasks are needed for wider BCI adoption, but the conventional wisdom is that such systems cannot meet necessary performance and power constraints.},
	language = {en},
	urldate = {2021-06-18},
	booktitle = {2020 {ACM}/{IEEE} 47th {Annual} {International} {Symposium} on {Computer} {Architecture} ({ISCA})},
	publisher = {IEEE},
	author = {Karageorgos, Ioannis and Sriram, Karthik and Vesely, Jan and Wu, Michael and Powell, Marc and Borton, David and Manohar, Rajit and Bhattacharjee, Abhishek},
	month = may,
	year = {2020},
	pages = {391--404},
}

@article{ragan-kelley_halide_nodate,
	title = {Halide: {A} {Language} and {Compiler} for {Optimizing} {Parallelism}, {Locality}, and {Recomputation} in {Image} {Processing} {Pipelines}},
	abstract = {Image processing pipelines combine the challenges of stencil computations and stream programs. They are composed of large graphs of different stencil stages, as well as complex reductions, and stages with global or data-dependent access patterns. Because of their complex structure, the performance difference between a naive implementation of a pipeline and an optimized one is often an order of magnitude. Efﬁcient implementations require optimization of both parallelism and locality, but due to the nature of stencils, there is a fundamental tension between parallelism, locality, and introducing redundant recomputation of shared values.},
	language = {en},
	author = {Ragan-Kelley, Jonathan and Barnes, Connelly and Adams, Andrew},
	pages = {12},
}

@article{nisa_load-balanced_2019,
	title = {Load-{Balanced} {Sparse} {MTTKRP} on {GPUs}},
	url = {http://arxiv.org/abs/1904.03329},
	abstract = {Sparse matricized tensor times Khatri-Rao product (MTTKRP) is one of the most computationally expensive kernels in sparse tensor computations. This work focuses on optimizing the MTTKRP operation on GPUs, addressing both performance and storage requirements. We begin by identifying the performance bottlenecks in directly extending the state-of-the-art CSF (compressed sparse fiber) format from CPUs to GPUs. A significant challenge with GPUs compared to multicore CPUs is that of utilizing the much greater degree of parallelism in a load-balanced fashion for irregular computations like sparse MTTKRP. To address this issue, we develop a new storage-efficient representation for tensors that enables high-performance, load-balanced execution of MTTKRP on GPUs. A GPU implementation of sparse MTTKRP using the new sparse tensor representation is shown to outperform all currently known parallel sparse CPU and GPU MTTKRP implementations.},
	urldate = {2021-06-02},
	journal = {arXiv:1904.03329 [cs]},
	author = {Nisa, Israt and Li, Jiajia and Sukumaran-Rajam, Aravind and Vuduc, Richard and Sadayappan, P.},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.03329},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
}

@misc{noauthor_optimized_nodate,
	title = {Optimized {Fast} {Walshâ}€“{Hadamard} {Transform} on {GPUs} for non-binary {LDPC} decoding {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0167819114000817?token=50A320EC6616570FAC1308FDF500E990A7D444CFF6C7FE31DE1EE7475A1A2B494CE4328CCBB23558952EEB1F7E3C57D5&originRegion=us-east-1&originCreation=20210601134313},
	language = {en},
	urldate = {2021-06-01},
	doi = {10.1016/j.parco.2014.07.001},
}

@article{zhang_sparch_2020,
	title = {{SpArch}: {Efficient} {Architecture} for {Sparse} {Matrix} {Multiplication}},
	shorttitle = {{SpArch}},
	url = {http://arxiv.org/abs/2002.08947},
	abstract = {Generalized Sparse Matrix-Matrix Multiplication (SpGEMM) is a ubiquitous task in various engineering and scientific applications. However, inner product based SpGENN introduces redundant input fetches for mismatched nonzero operands, while outer product based approach suffers from poor output locality due to numerous partial product matrices. Inefficiency in the reuse of either inputs or outputs data leads to extensive and expensive DRAM access. To address this problem, this paper proposes an efficient sparse matrix multiplication accelerator architecture, SpArch, which jointly optimizes the data locality for both input and output matrices. We first design a highly parallelized streaming-based merger to pipeline the multiply and merge stage of partial matrices so that partial matrices are merged on chip immediately after produced. We then propose a condensed matrix representation that reduces the number of partial matrices by three orders of magnitude and thus reduces DRAM access by 5.4x. We further develop a Huffman tree scheduler to improve the scalability of the merger for larger sparse matrices, which reduces the DRAM access by another 1.8x. We also resolve the increased input matrix read induced by the new representation using a row prefetcher with near-optimal buffer replacement policy, further reducing the DRAM access by 1.5x. Evaluated on 20 benchmarks, SpArch reduces the total DRAM access by 2.8x over previous state-of-the-art. On average, SpArch achieves 4x, 19x, 18x, 17x, 1285x speedup and 6x, 164x, 435x, 307x, 62x energy savings over OuterSPACE, MKL, cuSPARSE, CUSP, and ARM Armadillo, respectively.},
	urldate = {2021-06-01},
	journal = {arXiv:2002.08947 [cs]},
	author = {Zhang, Zhekai and Wang, Hanrui and Han, Song and Dally, William J.},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.08947},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Hardware Architecture},
}

@article{zhao_phism_nodate,
	title = {Phism: {Polyhedral} {High}-{Level} {Synthesis} in {MLIR}},
	abstract = {Polyhedral optimisation, a methodology that views nested loops as polyhedra and searches for their optimal transformation regarding specific objectives (parallelism, locality, etc.), sounds promising for mitigating difficulties in automatically optimising hardware designs described by high-level synthesis (HLS), which are typically software programs with nested loops. Nevertheless, existing polyhedral tools cannot meet the requirements from HLS developers for platform-specific customisation and software/hardware co-optimisation. This paper proposes ������������������ (Phism), a polyhedral HLS framework built on MLIR, to address these challenges through progressive lowering multi-level intermediate representations (IRs) from polyhedra to HLS designs.},
	language = {en},
	author = {Zhao, Ruizhe and Cheng, Jianyi},
	pages = {3},
}

@inproceedings{herklotz_finding_2020,
	address = {New York, NY, USA},
	series = {{FPGA} '20},
	title = {Finding and {Understanding} {Bugs} in {FPGA} {Synthesis} {Tools}},
	isbn = {978-1-4503-7099-8},
	url = {https://doi.org/10.1145/3373087.3375310},
	doi = {10.1145/3373087.3375310},
	abstract = {All software ultimately relies on hardware functioning correctly. Hardware correctness is becoming increasingly important due to the growing use of custom accelerators using FPGAs to speed up applications on servers. Furthermore, the increasing complexity of hardware also leads to ever more reliance on automation, meaning that the correctness of synthesis tools is vital for the reliability of the hardware. This paper aims to improve the quality of FPGA synthesis tools by introducing a method to test them automatically using randomly generated, correct Verilog, and checking that the synthesised netlist is always equivalent to the original design. The main contributions of this work are twofold: firstly a method for generating random behavioural Verilog free of undefined values, and secondly a Verilog test case reducer used to locate the cause of the bug that was found. These are implemented in a tool called Verismith. This paper also provides a qualitative and quantitative analysis of the bugs found in Yosys, Vivado, XST and Quartus Prime. Every synthesis tool except Quartus Prime was found to introduce discrepancies between the netlist and the design. In addition to that, Vivado and a development version of Yosys were found to crash when given valid input. Using Verismith, eleven bugs were reported to tool vendors, of which six have already been fixed.},
	urldate = {2021-05-25},
	booktitle = {Proceedings of the 2020 {ACM}/{SIGDA} {International} {Symposium} on {Field}-{Programmable} {Gate} {Arrays}},
	publisher = {Association for Computing Machinery},
	author = {Herklotz, Yann and Wickerson, John},
	month = feb,
	year = {2020},
	keywords = {fuzzing, logic synthesis, test case reduction, verilog},
	pages = {277--287},
}

@article{herklotz_high-level_nodate,
	title = {High-{Level} {Synthesis} {Tools} should be {Proven} {Correct}},
	abstract = {With hardware designs becoming ever more complex, and demand for custom accelerators ever growing, high-level synthesis (HLS) is increasingly being relied upon. However, HLS is known to be quite flaky, with each tool supporting subtly different fragments of the input language and sometimes even generating incorrect designs. We argue that a formally verified HLS tool could solve this issue by dramatically reducing the amount of trusted code, and providing a formal description of the input language that is supported. To this end, we are developing Vericert, a formally verified HLS tool, based on CompCert, a formally verified C compiler.},
	language = {en},
	author = {Herklotz, Yann and Wickerson, John},
	pages = {3},
}

@inproceedings{pit-claudel_effective_2021,
	address = {Virtual USA},
	title = {Effective simulation and debugging for a high-level hardware language using software compilers},
	isbn = {978-1-4503-8317-2},
	url = {https://dl.acm.org/doi/10.1145/3445814.3446720},
	doi = {10.1145/3445814.3446720},
	abstract = {Rule-based hardware-design languages (RHDLs) promise to enhance developer productivity by offering convenient abstractions. Advanced compiler technology keeps the cost of these abstractions low, generating circuits with excellent area and timing properties. Unfortunately, comparatively little effort has been spent on building simulators and debuggers for these languages, so users often simulate and debug their designs at the RTL level. This is problematic because generated circuits typically suffer from poor readability, as compiler optimizations can break high-level abstractions. Worse, optimizations that operate under the assumption that concurrency is essentially free yield faster circuits but often actively hurt simulation performance on platforms with limited concurrency, like desktop computers or servers. This paper demonstrates the benefits of completely separating the simulation and synthesis pipelines. We propose a new approach, yielding the first compiler designed for effective simulation and debugging of a language in the Bluespec family. We generate cycleaccurate C++ models that are readable, compatible with a wide range of traditional software-debugging tools, and fast (often two to three times faster than circuit-level simulation). We achieve these results by optimizing for sequential performance and using static analysis to minimize redundant work. The result is a vastly improved hardware-design experience, which we demonstrate on embedded processor designs and DSP building blocks using performance benchmarks and debugging case studies.},
	language = {en},
	urldate = {2021-05-25},
	booktitle = {Proceedings of the 26th {ACM} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Pit-Claudel, Clément and Bourgeat, Thomas and Lau, Stella and {Arvind} and Chlipala, Adam},
	month = apr,
	year = {2021},
	pages = {789--803},
}

@inproceedings{pit-claudel_effective_2021-1,
	address = {New York, NY, USA},
	series = {{ASPLOS} 2021},
	title = {Effective simulation and debugging for a high-level hardware language using software compilers},
	isbn = {978-1-4503-8317-2},
	url = {https://doi.org/10.1145/3445814.3446720},
	doi = {10.1145/3445814.3446720},
	abstract = {Rule-based hardware-design languages (RHDLs) promise to enhance developer productivity by offering convenient abstractions. Advanced compiler technology keeps the cost of these abstractions low, generating circuits with excellent area and timing properties. Unfortunately, comparatively little effort has been spent on building simulators and debuggers for these languages, so users often simulate and debug their designs at the RTL level. This is problematic because generated circuits typically suffer from poor readability, as compiler optimizations can break high-level abstractions. Worse, optimizations that operate under the assumption that concurrency is essentially free yield faster circuits but often actively hurt simulation performance on platforms with limited concurrency, like desktop computers or servers. This paper demonstrates the benefits of completely separating the simulation and synthesis pipelines. We propose a new approach, yielding the first compiler designed for effective simulation and debugging of a language in the Bluespec family. We generate cycle-accurate C++ models that are readable, compatible with a wide range of traditional software-debugging tools, and fast (often two to three times faster than circuit-level simulation). We achieve these results by optimizing for sequential performance and using static analysis to minimize redundant work. The result is a vastly improved hardware-design experience, which we demonstrate on embedded processor designs and DSP building blocks using performance benchmarks and debugging case studies.},
	urldate = {2021-05-24},
	booktitle = {Proceedings of the 26th {ACM} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Pit-Claudel, Clément and Bourgeat, Thomas and Lau, Stella and Arvind and Chlipala, Adam},
	month = apr,
	year = {2021},
	keywords = {Hardware simulation, compilation, hardware debugging},
	pages = {789--803},
}

@article{snyder_ten_2019,
	title = {Ten {Creative} {Uses} for {Verilator}},
	language = {en},
	author = {Snyder, Wilson},
	year = {2019},
	pages = {15},
}

@article{snyder_verilator_2018,
	title = {Verilator 4.0: {Open} {Simulation} {Goes} {Multithreaded}},
	language = {en},
	author = {Snyder, Wilson},
	year = {2018},
	pages = {31},
}

@article{snyder_verilator_nodate,
	title = {Verilator: {Fast}, {Free}, {But} for {Me}?},
	language = {en},
	author = {Snyder, Wilson},
	pages = {40},
}

@article{snyder_verilator_2020,
	title = {Verilator {Internals} \#1: {Debug}, {Stages}, {AstNode}, {V3Graph}},
	language = {en},
	author = {Snyder, Wilson},
	year = {2020},
	pages = {29},
}

@inproceedings{laeufer_rfuzz_2018,
	address = {San Diego California},
	title = {{RFUZZ}: coverage-directed fuzz testing of {RTL} on {FPGAs}},
	isbn = {978-1-4503-5950-4},
	shorttitle = {{RFUZZ}},
	url = {https://dl.acm.org/doi/10.1145/3240765.3240842},
	doi = {10.1145/3240765.3240842},
	abstract = {Dynamic verification is widely used to increase confidence in the correctness of RTL circuits during the pre-silicon design phase. Despite numerous attempts over the last decades to automate the stimuli generation based on coverage feedback, Coverage Directed Test Generation (CDG) has not found the widespread adoption that one would expect. Based on new ideas from the software testing community around coverage-guided mutational fuzz testing, we propose a new approach to the CDG problem which requires minimal setup and takes advantage of FPGA-accelerated simulation for rapid testing. We provide test input and coverage definitions that allow fuzz testing to be applied to RTL circuit verification. In addition we propose and implement a series of transformation passes that make it feasible to reset arbitrary RTL designs quickly, a requirement for deterministic test execution. Alongside this paper we provide rfuzz, a fully featured implementation of our testing methodology which we make available as open-source software to the research community. An empirical evaluation of rfuzz shows promising results on archiving coverage for a wide range of different RTL designs ranging from communication IPs to an industry scale 64-bit CPU.},
	language = {en},
	urldate = {2021-05-24},
	booktitle = {Proceedings of the {International} {Conference} on {Computer}-{Aided} {Design}},
	publisher = {ACM},
	author = {Laeufer, Kevin and Koenig, Jack and Kim, Donggyu and Bachrach, Jonathan and Sen, Koushik},
	month = nov,
	year = {2018},
	pages = {1--8},
}

@article{trippel_fuzzing_2021,
	title = {Fuzzing {Hardware} {Like} {Software}},
	url = {http://arxiv.org/abs/2102.02308},
	abstract = {Hardware flaws are permanent and potent: hardware cannot be patched once fabricated, and any flaws may undermine any software executing on top. Consequently, verification time dominates implementation time. The gold standard in hardware Design Verification (DV) is concentrated at two extremes: random dynamic verification and formal verification. Both struggle to root out the subtle flaws in complex hardware that often manifest as security vulnerabilities. The root problem with random verification is its undirected nature, making it inefficient, while formal verification is constrained by the state-space explosion problem, making it infeasible against complex designs. What is needed is a solution that is directed, yet under-constrained. Instead of making incremental improvements to existing DV approaches, we leverage the observation that existing software fuzzers already provide such a solution, and adapt them for hardware DV. Specifically, we translate RTL hardware to a software model and fuzz that model. The central challenge we address is how best to mitigate the differences between the hardware execution model and software execution model. This includes: 1) how to represent test cases, 2) what is the hardware equivalent of a crash, 3) what is an appropriate coverage metric, and 4) how to create a general-purpose fuzzing harness for hardware. To evaluate our approach, we fuzz four IP blocks from Google's OpenTitan SoC. Our experiments reveal a two orders-of-magnitude reduction in run time to achieve Finite State Machine (FSM) coverage over traditional dynamic verification schemes. Moreover, with our design-agnostic harness, we achieve over 88\% HDL line coverage in three out of four of our designs -- even without any initial seeds.},
	urldate = {2021-05-24},
	journal = {arXiv:2102.02308 [cs]},
	author = {Trippel, Timothy and Shin, Kang G. and Chernyakhovsky, Alex and Kelly, Garret and Rizzo, Dominic and Hicks, Matthew},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.02308},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Hardware Architecture},
}

@inproceedings{drucker_open_2020,
	title = {The {Open} {Domain}-{Specific} {Architecture}},
	doi = {10.1109/HOTI51249.2020.00019},
	abstract = {Chiplet technology can significantly reduce the cost and time needed to develop custom high performance silicon products. In order to realize a Chiplet-based product, a die-to-die (D2D) network to interconnect the chiplets is required. Almost all of today's chiplet-based products use proprietary D2D interfaces. Industry has primarily paid attention to PHY connectivity between chiplets in a package. A design also requires logical information flow between chiplets. Current designs use proprietary logic protocols between components. This approach makes it challenging to integrate chiplets from multiple vendors. The Open Domain-Specific Architecture (ODSA) is a project within the Open Compute Project (OCP) community that aims to establish open physical and logical D2D interfaces for chiplets. Ultimately, ODSA aims to create a marketplace of interoperable chiplets from multiple vendors based on open interfaces. This will allow product designers to develop best in class chiplets and System-In -a-Package (SIP) from multiple vendors. This paper reviews technical developments within the ODSA.},
	booktitle = {2020 {IEEE} {Symposium} on {High}-{Performance} {Interconnects} ({HOTI})},
	author = {Drucker, Kevin and Jani, Dharmesh and Agarwal, Ishwar and Miller, Gary and Mittal, Millind and Wang, Robert and Vinnakota, Bapiraju},
	month = aug,
	year = {2020},
	note = {ISSN: 2332-5569},
	keywords = {Computer architecture, Device-to-device communication, IP networks, Optical switches, Optimization, Packaging, Protocols, accelerators, chiplets, die-to-die interface, domain-specific accelerators, open interface, open source},
	pages = {25--32},
}

@article{vinnakota_open_2021,
	title = {The {Open} {Domain}-{Specific} {Architecture}},
	volume = {41},
	issn = {1937-4143},
	doi = {10.1109/MM.2020.3042383},
	abstract = {Chiplet technology can significantly reduce the cost and time needed to develop custom high-performance silicon products. To realize a chiplet-based product, a die-to-die (D2D) network to interconnect the chiplets is required. Almost all of today's chiplet-based products use proprietary D2D interfaces. Industry has primarily paid attention to D2D PHYs. A design also requires logical information flow between chiplets. Current designs use proprietary PHYs and logic protocols between components. This approach makes it challenging to integrate chiplets from multiple vendors. The open domain-specific architecture (ODSA) is a project within the open compute project (OCP) community that aims to establish open physical and logical D2D interfaces for chiplets. Ultimately, the ODSA aims to create open interfaces to enable a marketplace of interoperable chiplets. This will allow product designers to develop chiplet-based products that integrate best in class chiplets from multiple vendors. This article reviews technical developments within the ODSA.},
	number = {1},
	journal = {IEEE Micro},
	author = {Vinnakota, Bapi and Agarwal, Ishwar and Drucker, Kevin and Jani, Dharmesh and Miller, Gary and Mittal, Millind and Wang, Robert},
	month = jan,
	year = {2021},
	note = {Conference Name: IEEE Micro},
	keywords = {Computer architecture, Device-to-device communication, IP networks, Optimization, Packaging, Protocols, Transport protocols, accelerators, chiplets, die-to-die interface, domain-specific accelerators, open interface, open source},
	pages = {30--36},
}

@inproceedings{li_analytical_2021,
	address = {Virtual USA},
	title = {Analytical characterization and design space exploration for optimization of {CNNs}},
	isbn = {978-1-4503-8317-2},
	url = {https://dl.acm.org/doi/10.1145/3445814.3446759},
	doi = {10.1145/3445814.3446759},
	abstract = {Moving data through the memory hierarchy is a fundamental bottleneck that can limit the performance of core algorithms of machine learning, such as convolutional neural networks (CNNs). Looplevel optimization, including loop tiling and loop permutation, are fundamental transformations to reduce data movement. However, the search space for finding the best loop-level optimization configuration is explosively large. This paper develops an analytical modeling approach for finding the best loop-level optimization configuration for CNNs on multi-core CPUs. Experimental evaluation shows that this approach achieves comparable or better performance than state-of-the-art libraries and auto-tuning based optimizers for CNNs.},
	language = {en},
	urldate = {2021-05-06},
	booktitle = {Proceedings of the 26th {ACM} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Li, Rui and Xu, Yufan and Sukumaran-Rajam, Aravind and Rountev, Atanas and Sadayappan, P.},
	month = apr,
	year = {2021},
	pages = {928--942},
}

@incollection{li_analytical_2021-1,
	address = {New York, NY, USA},
	title = {Analytical characterization and design space exploration for optimization of {CNNs}},
	isbn = {978-1-4503-8317-2},
	url = {https://doi.org/10.1145/3445814.3446759},
	abstract = {Moving data through the memory hierarchy is a fundamental bottleneck that can limit the performance of core algorithms of machine learning, such as convolutional neural networks (CNNs). Loop-level optimization, including loop tiling and loop permutation, are fundamental transformations to reduce data movement. However, the search space for finding the best loop-level optimization configuration is explosively large. This paper develops an analytical modeling approach for finding the best loop-level optimization configuration for CNNs on multi-core CPUs. Experimental evaluation shows that this approach achieves comparable or better performance than state-of-the-art libraries and auto-tuning based optimizers for CNNs.},
	urldate = {2021-05-05},
	booktitle = {Proceedings of the 26th {ACM} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Li, Rui and Xu, Yufan and Sukumaran-Rajam, Aravind and Rountev, Atanas and Sadayappan, P.},
	month = apr,
	year = {2021},
	keywords = {Design space exploration, Neural networks, Performance modeling, Tile size optimization},
	pages = {928--942},
}

@inproceedings{zheng_flextensor_2020,
	address = {New York, NY, USA},
	series = {{ASPLOS} '20},
	title = {{FlexTensor}: {An} {Automatic} {Schedule} {Exploration} and {Optimization} {Framework} for {Tensor} {Computation} on {Heterogeneous} {System}},
	isbn = {978-1-4503-7102-5},
	shorttitle = {{FlexTensor}},
	url = {https://doi.org/10.1145/3373376.3378508},
	doi = {10.1145/3373376.3378508},
	abstract = {Tensor computation plays a paramount role in a broad range of domains, including machine learning, data analytics, and scientific computing. The wide adoption of tensor computation and its huge computation cost has led to high demand for flexible, portable, and high-performance library implementation on heterogeneous hardware accelerators such as GPUs and FPGAs. However, the current tensor library implementation mainly requires programmers to manually design low-level implementation and optimize from the algorithm, architecture, and compilation perspectives. Such a manual development process often takes months or even years, which falls far behind the rapid evolution of the application algorithms. In this paper, we introduce FlexTensor, which is a schedule exploration and optimization framework for tensor computation on heterogeneous systems. FlexTensor can optimize tensor computation programs without human interference, allowing programmers to only work on high-level programming abstraction without considering the hardware platform details. FlexTensor systematically explores the optimization design spaces that are composed of many different schedules for different hardware. Then, FlexTensor combines different exploration techniques, including heuristic method and machine learning method to find the optimized schedule configuration. Finally, based on the results of exploration, customized schedules are automatically generated for different hardware. In the experiments, we test 12 different kinds of tensor computations with totally hundreds of test cases and FlexTensor achieves average 1.83x performance speedup on NVIDIA V100 GPU compared to cuDNN; 1.72x performance speedup on Intel Xeon CPU compared to MKL-DNN for 2D convolution; 1.5x performance speedup on Xilinx VU9P FPGA compared to OpenCL baselines; 2.21x speedup on NVIDIA V100 GPU compared to the state-of-the-art.},
	urldate = {2021-05-04},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zheng, Size and Liang, Yun and Wang, Shuo and Chen, Renze and Sheng, Kaiwen},
	month = mar,
	year = {2020},
	keywords = {code generation, compiler optimization, heterogeneous systems, machine learning},
	pages = {859--873},
}

@inproceedings{josipovic_enriching_2016,
	title = {Enriching {C}-based {High}-{Level} {Synthesis} with parallel pattern templates},
	doi = {10.1109/FPT.2016.7929527},
	abstract = {Despite the popularity of C-based High-Level Synthesis (HLS) tools, their generic input programming languages make it challenging for the designer to find the expression that will result in adequate hardware quality and performance. Moreover, the syntactic variance of the input description often causes the inability of the HLS tool to fully identify and benefit from the properties of the computations. In this work, we propose extending standard C-based HLS tools with the concept of computational patterns. In particular, we present a template-based hardware generation strategy which enables complete exploitation of the pattern properties to produce high-quality hardware modules. The parametric templates allow us to automatically scale the implementation to the resource and data-bandwidth constraints of the target device, independent from the analysis abilities of the HLS tool. To demonstrate the benefits of our approach, we generated hardware implementations for six applications which we composed using a set of computational patterns (i.e. map, zip and reduce), achieving 1.3× to 2.8× speed-up over a state-of-the-art commercial HLS tool.},
	booktitle = {2016 {International} {Conference} on {Field}-{Programmable} {Technology} ({FPT})},
	author = {Josipovic, Lana and George, Nithin and Ienne, Paolo},
	month = dec,
	year = {2016},
	keywords = {Computer languages, Hardware, Optimization, Parallel processing, Standards, Throughput, Tools},
	pages = {177--180},
}

@inproceedings{koeplinger_automatic_2016,
	title = {Automatic {Generation} of {Efficient} {Accelerators} for {Reconfigurable} {Hardware}},
	doi = {10.1109/ISCA.2016.20},
	abstract = {Acceleration in the form of customized datapaths offer large performance and energy improvements over general purpose processors. Reconfigurable fabrics such as FPGAs are gaining popularity for use in implementing application-specific accelerators, thereby increasing the importance of having good high-level FPGA design tools. However, current tools for targeting FPGAs offer inadequate support for high-level programming, resource estimation, and rapid and automatic design space exploration. We describe a design framework that addresses these challenges. We introduce a new representation of hardware using parameterized templates that captures locality and parallelism information at multiple levels of nesting. This representation is designed to be automatically generated from high-level languages based on parallel patterns. We describe a hybrid area estimation technique which uses template-level models and design-level artificial neural networks to account for effects from hardware place-and-route tools, including routing overheads, register and block RAM duplication, and LUT packing. Our runtime estimation accounts for off-chip memory accesses. We use our estimation capabilities to rapidly explore a large space of designs across tile sizes, parallelization factors, and optional coarse-grained pipelining, all at multiple loop levels. We show that estimates average 4.8\% error for logic resources, 6.1\% error for runtimes, and are 279 to 6533 times faster than a commercial high-level synthesis tool. We compare the best-performing designs to optimized CPU code running on a server-grade 6 core processor and show speedups of up to 16.7×.},
	booktitle = {2016 {ACM}/{IEEE} 43rd {Annual} {International} {Symposium} on {Computer} {Architecture} ({ISCA})},
	author = {Koeplinger, David and Prabhakar, Raghu and Zhang, Yaqi and Delimitrou, Christina and Kozyrakis, Christos and Olukotun, Kunle},
	month = jun,
	year = {2016},
	note = {ISSN: 1063-6897},
	keywords = {Design tools, Estimation, FPGAs, Field programmable gate arrays, Hardware, Pipeline processing, Space exploration, application-specific accelerators, design space exploration, hardware definition language, hardware generation, parallel patterns, reconfigurable hardware},
	pages = {115--127},
}

@inproceedings{matai_composable_2016,
	title = {Composable, parameterizable templates for high-level synthesis},
	abstract = {High-level synthesis tools aim to make FPGA programming easier by raising the level of programming abstraction. Yet in order to get an efficient hardware design from HLS tools, the designer must know how to write HLS code that results in an efficient low level hardware architecture. Unfortunately, this requires substantial hardware knowledge, which limits wide adoption of HLS tools outside of hardware designers. In this work, we develop an approach based upon parameterizable templates that can be composed using common data access patterns. This creates a methodology for efficient hardware implementations. Our results demonstrate that a small number of optimized templates can be hierarchically composed to develop highly optimized hardware implementations for large applications.},
	booktitle = {2016 {Design}, {Automation} {Test} in {Europe} {Conference} {Exhibition} ({DATE})},
	author = {Matai, Janarbek and Lee, Dajung and Althoff, Alric and Kastner, Ryan},
	month = mar,
	year = {2016},
	note = {ISSN: 1558-1101},
	keywords = {Calculus, Field programmable gate arrays, Hardware, Histograms, Kernel, Pipeline processing, Programming},
	pages = {744--749},
}

@article{madsen_lycos_nodate,
	title = {{LYCOS}: the {Lyngby} {Co}-{Synthesis} {System}},
	abstract = {This paper describes the LYCOS system, an experimental co-synthesis environment. We present the motivation and philosophy of LYCOS and after an overview of the entire system, the individual parts are described. We use a single CPU, single ASIC target architecture and we describe the techniques we use to estimate metrics concerning hardware, software and communication in this architecture. Finally we present a novel partitioning technique called PACE, which has shown to produce excellent results, and we demonstrate how partitioning is used to do design space exploration.},
	language = {en},
	author = {Madsen, J and Grode, J and Knudsen, P V and Petersen, M E and Haxthausen, A},
	pages = {41},
}

@inproceedings{knudsen_graph_1999,
	title = {Graph based communication analysis for hardware/software codesign},
	doi = {10.1109/HSC.1999.777407},
	abstract = {In this paper we present a coarse grain CDFG (Control/Data Flow Graph) model suitable for hardware/software partitioning of single processes and demonstrate how it is necessary to perform various transformations on the graph structure before partitioning in order to achieve a structure that allows for accurate estimation of communication overhead between nodes mapped to different processors. In particular, we demonstrate how various transformations of control structures can lead to a more accurate communication analysis and more efficient implementations. The purpose of the transformations is to obtain a CDFG structure that is sufficiently fine grained as to support a correct communication analysis but not more fine grained than necessary as this will increase partitioning and analysis time.},
	booktitle = {Proceedings of the {Seventh} {International} {Workshop} on {Hardware}/{Software} {Codesign} ({CODES}'99) ({IEEE} {Cat}. {No}.{99TH8450})},
	author = {Knudsen, P.V. and Madsen, J.},
	month = mar,
	year = {1999},
	note = {ISSN: 1092-6100},
	keywords = {Application software, Arithmetic, Communication system control, Flow graphs, Hardware, Information technology, Permission, Repeaters, Testing},
	pages = {131--135},
}

@inproceedings{wang_itucome_2005,
	title = {{iTuCoMe}: {HCDFG}-based incremental tuning {HW}/{SW} co-design methodology for multi-level exploration},
	volume = {2},
	shorttitle = {{iTuCoMe}},
	doi = {10.1109/CSCWD.2005.194320},
	abstract = {In this paper, we present an iTuCoMe methodology which concentrates on providing a brand-new codesign framework of high-performance SoC systems for multilevel exploration. The main motivation of this work is that a fine trade-off between abstraction levels, design models and implementation accuracy can be explored under the design cycle as small as possible at system level. The proposed framework has been realized by relative algorithms and tools to map and transform a system specification to a feasible RTL implementation solution with arbitrarily linked processors, IP cores and ASICs. To improve the speed of convergence and reduce the iterative numbers of turnaround, iTuCoMe employs an incremental method to divide design space into three layers: 1) adaptive granularity for HW/SW partitioning; 2) incremental tuning for communication architecture generation; and 3) interconnect-driven high-level re-synthesis with floorplanning. Finally, we evaluate the iTuCoMe design methodology through an illustrative case study on JPEG decoder application.},
	booktitle = {Proceedings of the {Ninth} {International} {Conference} on {Computer} {Supported} {Cooperative} {Work} in {Design}, 2005.},
	author = {Wang, Haili and Bian, Jinian and Wu, Qiang and Wang, Yunfeng},
	month = may,
	year = {2005},
	keywords = {Amplitude shift keying, Circuit optimization, Computer science, Convergence, Design methodology, Embedded system, Iterative methods, Libraries, Space exploration, System-on-a-chip},
	pages = {978--983 Vol. 2},
}

@book{khalid_domain_2019,
	address = {Singapore},
	series = {Computer {Architecture} and {Design} {Methodologies}},
	title = {Domain {Specific} {High}-{Level} {Synthesis} for {Cryptographic} {Workloads}},
	isbn = {978-981-10-1069-9 978-981-10-1070-5},
	url = {http://link.springer.com/10.1007/978-981-10-1070-5},
	language = {en},
	urldate = {2021-05-02},
	publisher = {Springer Singapore},
	author = {Khalid, Ayesha and Paul, Goutam and Chattopadhyay, Anupam},
	year = {2019},
	doi = {10.1007/978-981-10-1070-5},
}

@inproceedings{wu_hierarchical_2002,
	title = {A hierarchical {CDFG} as intermediate representation for hardware/software codesign},
	volume = {2},
	doi = {10.1109/ICCCAS.2002.1179048},
	abstract = {A hierarchical CDFG model designed as an intermediate representation for hardware/software (HW/SW) codesign is presented in this paper. A new concept of transport node, which represents the communication resources of the system, is proposed in this model. Hierarchical feature can be straightly obtained through extending the definition of nodes, allowing them to nest sub-CDFG recursively. Then it is demonstrated how to build basic control constructs of branches and loops. Explaining in a short introduction to the translation process, such a hierarchical CDFG is suitable for HW/SW codesign as an intermediate representation. The hierarchical CDFG model can capture the design information from source file specified by VHDL or C language. It maintains relative simplicity while providing helpful features for HW/SW partitioning and High-level synthesis tools.},
	booktitle = {{IEEE} 2002 {International} {Conference} on {Communications}, {Circuits} and {Systems} and {West} {Sino} {Expositions}},
	author = {Wu, Qiang and Wang, Yunfeng and Bian, Jinian and Wu, Weimin and Xue, Hongxi},
	month = jun,
	year = {2002},
	keywords = {Communication system control, Computer science, Control system synthesis, Flow graphs, Hardware, High level synthesis, Research and development, Specification languages, Synthesizers, Wires},
	pages = {1429--1432 vol.2},
}

@article{li_analytical_2021-2,
	title = {Analytical {Characterization} and {Design} {Space} {Exploration} for {Optimization} of {CNNs}},
	abstract = {Moving data through the memory hierarchy is a fundamental bottleneck that can limit the performance of core algorithms of machine learning, such as convolutional neural networks (CNNs). Looplevel optimization, including loop tiling and loop permutation, are fundamental transformations to reduce data movement. However, the search space for finding the best loop-level optimization configuration is explosively large. This paper develops an analytical modeling approach for finding the best loop-level optimization configuration for CNNs on multi-core CPUs. Experimental evaluation shows that this approach achieves comparable or better performance than state-of-the-art libraries and auto-tuning based optimizers for CNNs.},
	language = {en},
	author = {Li, Rui and Xu, Yufan and Sukumaran-Rajam, Aravind and Rountev, Atanas and Sadayappan, P},
	year = {2021},
	pages = {15},
}

@inproceedings{paul_hardware-software_2019,
	address = {Sarawak, Malaysia, Malaysia},
	title = {Hardware-{Software} {Co}-design {Approach} for {Deep} {Learning} {Inference}},
	isbn = {978-1-72811-557-3},
	url = {https://ieeexplore.ieee.org/document/8843626/},
	doi = {10.1109/ICSCC.2019.8843626},
	abstract = {Hardware implementation of machine learning algorithms is a promising solution for higher performance and improved throughput. However, the most challenging task lies in the design of power, energy, and area efﬁcient architectures that can be deployed in tightly constrained embedded systems. In this paper, we investigate the concept of intermediate exit branches in a CNN architecture aiming to reduce latency and energy. We propose a heterogeneous hardware-software based architecture for performing inference in feed-forward neural networks which is capable of early exiting through intermediate exits according to the difﬁculty level of the input. Our proposed architecture can be reconﬁgured to support different kernel sizes and is fully scalable. Our experiments show an increase in classiﬁcation accuracy by 0.27\% for MNIST dataset (LeNet) with 2.2× decrease in average computations and 1.07\% for Cifar-10 dataset (AlexNet) with 1.55× decrease in average computations along with 1.39× reduction in energy consumption for LeNet architecture.},
	language = {en},
	urldate = {2021-04-24},
	booktitle = {2019 7th {International} {Conference} on {Smart} {Computing} \& {Communications} ({ICSCC})},
	publisher = {IEEE},
	author = {Paul, Debdeep and Singh, Jawar and Mathew, Jimson},
	month = jun,
	year = {2019},
	pages = {1--5},
}

@inproceedings{gong_widerframe_2020,
	title = {{WiderFrame}: {An} {Automatic} {Customization} {Framework} for {Building} {CNN} {Accelerators} on {FPGAs}: {Work}-in-{Progress}},
	shorttitle = {{WiderFrame}},
	doi = {10.1109/CODESISSS51650.2020.9244024},
	abstract = {Hardware acceleration based on FPGA has been an important means to improve the computational efficiency of CNNs. However, due to the increasing complexity of the modern CNNs and the diversity of neural computing engines, it is challenging to make full use of FPGAs' customizability for efficient and fast accelerator designs. This paper proposes Wider-Frame, an automatic customization framework for building CNN accelerators on FPGA. Towards fully exploiting the customiz-ability of FPGA for specific computing scenarios, WiderFrame integrates a systematical design space exploration methodology considered with different parallel and data reuse manners among various neural computing engines, a parameterized configurable code template with a set of macro instruction mechanism, for automatically generating the underlying hardware units and the control flow. Evaluation results show that WiderFrame can well support more CNN types, and can improve the performance and the energy efficiency up to 1.25 x and 1.68 x compared with state-of-the-art frameworks.},
	booktitle = {2020 {International} {Conference} on {Hardware}/{Software} {Codesign} and {System} {Synthesis} ({CODES}+{ISSS})},
	author = {Gong, Lei and Wang, Chao and Li, Xi and Zhou, Xuehai},
	month = sep,
	year = {2020},
	keywords = {Buildings, CNN, Design methodology, Energy efficiency, Engines, FPGA, Field programmable gate arrays, Framework, Hardware acceleration, Hardware accelerator, Space exploration},
	pages = {5--7},
}

@inproceedings{hu_formal_2020,
	title = {Formal {Verification} of {GCSE} in the {Scheduling} of {High}-level {Synthesis}: {Work}-in-{Progress}},
	shorttitle = {Formal {Verification} of {GCSE} in the {Scheduling} of {High}-level {Synthesis}},
	doi = {10.1109/CODESISSS51650.2020.9244039},
	abstract = {High-level synthesis entails application of a sequence of transformations to compile a high-level description of a hardware design (e.g., in C/C++/SystemC) into a register-transfer level (RTL) implementation. However, an error may exist in the RTL implementation from the compiler in the high-level synthesis due to the complex and error prone compiling process. Global common subexpression elimination (GCSE) is a commonly used code motion technique in the scheduling of high-level synthesis. In this paper, we present an equivalence checking method to verify GCSE in the scheduling of high-level synthesis by enhancing the path equivalence criteria. The initial experimental results demonstrate our method can indeed verify the GCSE which has not been properly addressed in the past.},
	booktitle = {2020 {International} {Conference} on {Hardware}/{Software} {Codesign} and {System} {Synthesis} ({CODES}+{ISSS})},
	author = {Hu, Jian and Hu, Yongyang and Yu, Long and Wang, Wentao and Yang, Haitao and Kang, Yun and Cheng, Jie},
	month = sep,
	year = {2020},
	keywords = {Equivalence Checking, FSMD, Formal verification, Global Common Subexpression Elimination, Hardware, High-level Synthesis},
	pages = {1--2},
}

@article{majumder_hir_2021,
	title = {{HIR}: {An} {MLIR}-based {Intermediate} {Representation} for {Hardware} {Accelerator} {Description}},
	shorttitle = {{HIR}},
	url = {http://arxiv.org/abs/2103.00194},
	abstract = {The emergence of machine learning, image and audio processing on edge devices has motivated research towards power efficient custom hardware accelerators. Though FPGAs are an ideal target for energy efficient custom accelerators, the difficulty of hardware design and the lack of vendor agnostic, standardized hardware compilation infrastructure has hindered their adoption. This paper introduces HIR, an MLIR-based intermediate representation (IR) to describe hardware accelerator designs. HIR combines high level language features, such as loops and multi-dimensional tensors, with programmer defined explicit scheduling, to provide a high-level IR suitable for DSL compiler pipelines without compromising control over the micro-architecture of the accelerator. HIR's explicit schedules allow it to express fine-grained, synchronization-free parallelism and optimizations such as retiming and pipelining. Built as a dialect in MLIR, it draws from best IR practices learnt from communities like those of LLVM. While offering rich optimization opportunities and a high level abstraction, HIR enables sharing of optimizations, utilities and passes with software compiler infrastructure. Our implementation shows that the code generation time of the HIR code generator is on average 1112x lower than that of Xilinx Vivado HLS on a range of kernels without a compromise on the quality of the generated hardware. We believe that these are significant steps forward in the design of IRs for hardware synthesis and in equipping domain-specific languages with a productive and performing compilation path to custom hardware acceleration.},
	urldate = {2021-04-23},
	journal = {arXiv:2103.00194 [cs]},
	author = {Majumder, Kingshuk and Bondhugula, Uday},
	month = feb,
	year = {2021},
	note = {arXiv: 2103.00194},
	keywords = {Computer Science - Hardware Architecture, Computer Science - Programming Languages},
}

@article{noauthor_arbeitsblatt_nodate,
	title = {Arbeitsblatt {Lokale}},
	language = {de},
	pages = {3},
}

@article{zaruba_manticore_2020,
	title = {Manticore: {A} 4096-core {RISC}-{V} {Chiplet} {Architecture} for {Ultra}-efficient {Floating}-point {Computing}},
	shorttitle = {Manticore},
	url = {http://arxiv.org/abs/2008.06502},
	abstract = {Data-parallel problems demand ever growing floating-point (FP) operations per second under tight area- and energy-efficiency constraints. In this work, we present Manticore, a general-purpose, ultra-efficient chiplet-based architecture for data-parallel FP workloads. We have manufactured a prototype of the chiplet's computational core in Globalfoundries 22FDX process and demonstrate more than 5x improvement in energy efficiency on FP intensive workloads compared to CPUs and GPUs. The compute capability at high energy and area efficiency is provided by Snitch clusters containing eight small integer cores, each controlling a large FPU. The core supports two custom ISA extensions: The SSR extension elides explicit load and store instructions by encoding them as register reads and writes. The FREP extension decouples the integer core from the FPU allowing floating-point instructions to be issued independently. These two extensions allow the single-issue core to minimize its instruction fetch bandwidth and saturate the instruction bandwidth of the FPU, achieving FPU utilization above 90\%, with more than 40\% of core area dedicated to the FPU.},
	urldate = {2021-04-16},
	journal = {arXiv:2008.06502 [cs]},
	author = {Zaruba, Florian and Schuiki, Fabian and Benini, Luca},
	month = nov,
	year = {2020},
	note = {arXiv: 2008.06502},
	keywords = {Computer Science - Hardware Architecture},
}

@article{gao_tangram_nodate,
	title = {Tangram: {Optimized} {Coarse}-{Grained} {Dataflow} for {Scalable} {NN} {Accelerators}},
	abstract = {The use of increasingly larger and more complex neural networks (NNs) makes it critical to scale the capabilities and efficiency of NN accelerators. Tiled architectures provide an intuitive scaling solution that supports both coarse-grained parallelism in NNs: intra-layer parallelism, where all tiles process a single layer, and inter-layer pipelining, where multiple layers execute across tiles in a pipelined manner. This work proposes dataflow optimizations to address the shortcomings of existing parallel dataflow techniques for tiled NN accelerators. For intra-layer parallelism, we develop buffer sharing dataflow that turns the distributed buffers into an idealized shared buffer, eliminating excessive data duplication and the memory access overheads. For interlayer pipelining, we develop alternate layer loop ordering that forwards the intermediate data in a more fine-grained and timely manner, reducing the buffer requirements and pipeline delays. We also make inter-layer pipelining applicable to NNs with complex DAG structures. These optimizations improve the performance of tiled NN accelerators by 2× and reduce their energy consumption by 45\% across a wide range of NNs. The effectiveness of our optimizations also increases with the NN size and complexity.},
	language = {en},
	author = {Gao, Mingyu and Yang, Xuan and Pu, Jing and Horowitz, Mark and Kozyrakis, Christos},
	pages = {14},
}

@inproceedings{naffziger_22_2020,
	title = {2.2 {AMD} {Chiplet} {Architecture} for {High}-{Performance} {Server} and {Desktop} {Products}},
	doi = {10.1109/ISSCC19947.2020.9063103},
	abstract = {AMO's “Rome” and “Matisse” are second-generation AMD Infinity Fabric-based SoCs using 3 unique hybrid process technology chiplets to achieve leading performance, performance/\$ and performance/W, targeting server and client markets, respectively (Fig. 2.2.1). The chiplet architecture enables leading edge 7nm [1] CPUs for multiple markets, while retaining backward compatibility to complex 10 and memory subsystems in a scalable design with high reuse for improved time-to-market. A key benefit is the heterogeneous technology deployed between the CPUs and the 10/mixed-signaIP. It is well known that shrink factors in advanced nodes are much lower for analog circuitry than for digital logic and SRAM. By keeping the memory interfaces and SerOes in mature 12nm technology, costs are mitigated since those circuits see a very small shrink factor to 7nm and very little performance or power gain from advanced nodes. A low-cost 12nm 10 die (IOD) with the high-yielding 8 “Zen2” core, 74mm2 7nm CPU compute die (CCD) combine to provide very cost-effective performance.},
	booktitle = {2020 {IEEE} {International} {Solid}- {State} {Circuits} {Conference} - ({ISSCC})},
	author = {Naffziger, S. and Lepak, K. and Paraschou, M. and Subramony, M.},
	month = feb,
	year = {2020},
	note = {ISSN: 2376-8606},
	keywords = {Bandwidth, Charge coupled devices, Clocks, Computer architecture, Fabrics, Routing, Servers},
	pages = {44--45},
}

@inproceedings{arunkumar_mcm-gpu_2017,
	address = {Toronto ON Canada},
	title = {{MCM}-{GPU}: {Multi}-{Chip}-{Module} {GPUs} for {Continued} {Performance} {Scalability}},
	isbn = {978-1-4503-4892-8},
	shorttitle = {{MCM}-{GPU}},
	url = {https://dl.acm.org/doi/10.1145/3079856.3080231},
	doi = {10.1145/3079856.3080231},
	abstract = {Historically, improvements in GPU-based high performance computing have been tightly coupled to transistor scaling. As Moore’s law slows down, and the number of transistors per die no longer grows at historical rates, the performance curve of single monolithic GPUs will ultimately plateau. However, the need for higher performing GPUs continues to exist in many domains. To address this need, in this paper we demonstrate that package-level integration of multiple GPU modules to build larger logical GPUs can enable continuous performance scaling beyond Moore’s law. Specifically, we propose partitioning GPUs into easily manufacturable basic GPU Modules (GPMs), and integrating them on package using high bandwidth and power efficient signaling technologies. We lay out the details and evaluate the feasibility of a basic Multi-Chip-Module GPU (MCMGPU) design. We then propose three architectural optimizations that significantly improve GPM data locality and minimize the sensitivity on inter-GPM bandwidth. Our evaluation shows that the optimized MCM-GPU achieves 22.8\% speedup and 5x inter-GPM bandwidth reduction when compared to the basic MCM-GPU architecture. Most importantly, the optimized MCM-GPU design is 45.5\% faster than the largest implementable monolithic GPU, and performs within 10\% of a hypothetical (and unbuildable) monolithic GPU. Lastly we show that our optimized MCM-GPU is 26.8\% faster than an equally equipped Multi-GPU system with the same total number of SMs and DRAM bandwidth.},
	language = {en},
	urldate = {2021-04-15},
	booktitle = {Proceedings of the 44th {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {ACM},
	author = {Arunkumar, Akhil and Bolotin, Evgeny and Cho, Benjamin and Milic, Ugljesa and Ebrahimi, Eiman and Villa, Oreste and Jaleel, Aamer and Wu, Carole-Jean and Nellans, David},
	month = jun,
	year = {2017},
	pages = {320--332},
}

@inproceedings{arunkumar_mcm-gpu_2017-1,
	address = {New York, NY, USA},
	series = {{ISCA} '17},
	title = {{MCM}-{GPU}: {Multi}-{Chip}-{Module} {GPUs} for {Continued} {Performance} {Scalability}},
	isbn = {978-1-4503-4892-8},
	shorttitle = {{MCM}-{GPU}},
	url = {https://doi.org/10.1145/3079856.3080231},
	doi = {10.1145/3079856.3080231},
	abstract = {Historically, improvements in GPU-based high performance computing have been tightly coupled to transistor scaling. As Moore's law slows down, and the number of transistors per die no longer grows at historical rates, the performance curve of single monolithic GPUs will ultimately plateau. However, the need for higher performing GPUs continues to exist in many domains. To address this need, in this paper we demonstrate that package-level integration of multiple GPU modules to build larger logical GPUs can enable continuous performance scaling beyond Moore's law. Specifically, we propose partitioning GPUs into easily manufacturable basic GPU Modules (GPMs), and integrating them on package using high bandwidth and power efficient signaling technologies. We lay out the details and evaluate the feasibility of a basic Multi-Chip-Module GPU (MCM-GPU) design. We then propose three architectural optimizations that significantly improve GPM data locality and minimize the sensitivity on inter-GPM bandwidth. Our evaluation shows that the optimized MCM-GPU achieves 22.8\% speedup and 5x inter-GPM bandwidth reduction when compared to the basic MCM-GPU architecture. Most importantly, the optimized MCM-GPU design is 45.5\% faster than the largest implementable monolithic GPU, and performs within 10\% of a hypothetical (and unbuildable) monolithic GPU. Lastly we show that our optimized MCM-GPU is 26.8\% faster than an equally equipped Multi-GPU system with the same total number of SMs and DRAM bandwidth.},
	urldate = {2021-04-15},
	booktitle = {Proceedings of the 44th {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {Association for Computing Machinery},
	author = {Arunkumar, Akhil and Bolotin, Evgeny and Cho, Benjamin and Milic, Ugljesa and Ebrahimi, Eiman and Villa, Oreste and Jaleel, Aamer and Wu, Carole-Jean and Nellans, David},
	month = jun,
	year = {2017},
	keywords = {Graphics Processing Units, Moore's Law, Multi-Chip-Modules, NUMA Systems},
	pages = {320--332},
}

@inproceedings{venkatesan_011_2019,
	title = {A 0.11 {PJ}/{OP}, 0.32-128 {Tops}, {Scalable} {Multi}-{Chip}-{Module}-{Based} {Deep} {Neural} {Network} {Accelerator} {Designed} with {A} {High}-{Productivity} vlsi {Methodology}},
	doi = {10.1109/HOTCHIPS.2019.8875657},
	abstract = {This article discusses a scalable multichip-module-based deep neural network accelerator designed with a high-productivity VLSI methodology.},
	booktitle = {2019 {IEEE} {Hot} {Chips} 31 {Symposium} ({HCS})},
	author = {Venkatesan, R. and Shao, Y. S. and Zimmer, B. and Clemons, J. and Fojtik, M. and Jiang, N. and Keller, B. and Klinefelter, A. and Pinckney, N. and Raina, P. and Tell, S. G. and Zhang, Y. and Dally, W. J. and Emer, J. S. and Gray, C. T. and Keckler, S. W. and Khailany, B.},
	month = aug,
	year = {2019},
	note = {ISSN: 2573-2048},
	pages = {1--24},
}

@article{zimmer_032128_2020,
	title = {A 0.32–128 {TOPS}, {Scalable} {Multi}-{Chip}-{Module}-{Based} {Deep} {Neural} {Network} {Inference} {Accelerator} {With} {Ground}-{Referenced} {Signaling} in 16 nm},
	volume = {55},
	issn = {1558-173X},
	doi = {10.1109/JSSC.2019.2960488},
	abstract = {Custom accelerators improve the energy efficiency, area efficiency, and performance of deep neural network (DNN) inference. This article presents a scalable DNN accelerator consisting of 36 chips connected in a mesh network on a multi-chip-module (MCM) using ground-referenced signaling (GRS). While previous accelerators fabricated on a single monolithic chip are optimal for specific network sizes, the proposed architecture enables flexible scaling for efficient inference on a wide range of DNNs, from mobile to data center domains. Communication energy is minimized with large on-chip distributed weight storage and a hierarchical network-on-chip and network-on-package, and inference energy is minimized through extensive data reuse. The 16-nm prototype achieves 1.29-TOPS/mm2 area efficiency, 0.11 pJ/op (9.5 TOPS/W) energy efficiency, 4.01-TOPS peak performance for a one-chip system, and 127.8 peak TOPS and 1903 images/s ResNet-50 batch-1 inference for a 36-chip system.},
	number = {4},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Zimmer, B. and Venkatesan, R. and Shao, Y. S. and Clemons, J. and Fojtik, M. and Jiang, N. and Keller, B. and Klinefelter, A. and Pinckney, N. and Raina, P. and Tell, S. G. and Zhang, Y. and Dally, W. J. and Emer, J. S. and Gray, C. T. and Keckler, S. W. and Khailany, B.},
	month = apr,
	year = {2020},
	note = {Conference Name: IEEE Journal of Solid-State Circuits},
	keywords = {Bandwidth, Computer architecture, Convolution, Deep neural networks (DNNs), Neural networks, Prototypes, System-on-chip, Tensors, ground-referenced signaling (GRS), inference accelerator, multi-chip modules, single-ended signaling},
	pages = {920--932},
}

@inproceedings{shao_simba_2019,
	address = {Columbus OH USA},
	title = {Simba: {Scaling} {Deep}-{Learning} {Inference} with {Multi}-{Chip}-{Module}-{Based} {Architecture}},
	isbn = {978-1-4503-6938-1},
	shorttitle = {Simba},
	url = {https://dl.acm.org/doi/10.1145/3352460.3358302},
	doi = {10.1145/3352460.3358302},
	abstract = {Package-level integration using multi-chip-modules (MCMs) is a promising approach for building large-scale systems. Compared to a large monolithic die, an MCM combines many smaller chiplets into a larger system, substantially reducing fabrication and design costs. Current MCMs typically only contain a handful of coarsegrained large chiplets due to the high area, performance, and energy overheads associated with inter-chiplet communication. This work investigates and quantifies the costs and benefits of using MCMs with fine-grained chiplets for deep learning inference, an application area with large compute and on-chip storage requirements. To evaluate the approach, we architected, implemented, fabricated, and tested Simba, a 36-chiplet prototype MCM system for deeplearning inference. Each chiplet achieves 4 TOPS peak performance, and the 36-chiplet MCM package achieves up to 128 TOPS and up to 6.1 TOPS/W. The MCM is configurable to support a flexible mapping of DNN layers to the distributed compute and storage units. To mitigate inter-chiplet communication overheads, we introduce three tiling optimizations that improve data locality. These optimizations achieve up to 16\% speedup compared to the baseline layer mapping. Our evaluation shows that Simba can process 1988 images/s running ResNet-50 with batch size of one, delivering inference latency of 0.50 ms.},
	language = {en},
	urldate = {2021-04-15},
	booktitle = {Proceedings of the 52nd {Annual} {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture}},
	publisher = {ACM},
	author = {Shao, Yakun Sophia and Clemons, Jason and Venkatesan, Rangharajan and Zimmer, Brian and Fojtik, Matthew and Jiang, Nan and Keller, Ben and Klinefelter, Alicia and Pinckney, Nathaniel and Raina, Priyanka and Tell, Stephen G. and Zhang, Yanqing and Dally, William J. and Emer, Joel and Gray, C. Thomas and Khailany, Brucek and Keckler, Stephen W.},
	month = oct,
	year = {2019},
	pages = {14--27},
}

@inproceedings{ellinidou_microlet_2019,
	title = {{MicroLET}: {A} {New} {SDNoC}-{Based} {Communication} {Protocol} for {ChipLET}-{Based} {Systems}},
	shorttitle = {{MicroLET}},
	doi = {10.1109/DSD.2019.00019},
	abstract = {Currently the industry moves to smaller process nodes even if the cost for yielding large dies continues to increase, moving to the 5nm and even 3nm nodes. Hence a chiplet-based design has been initiated and quickly gain attention from industry, academia and government agencies. This cutting edge approach became advantageous to break down a large die into smaller chiplets in order to improve yield and binning. In order to exploit this new approach the interconnect fabric connecting the nodes of the entire system should be of high importance to enable the properly distribution of the data. Each individual chiplet may contain its own local Network on Chip (NoC), which operates for intra-chiplet traffic. However the communication over chiplet-based systems is complicated enough, due to various routing algorithms and NoC topologies and an alternative solution is needed. In this paper we introduce an SDNoC(Software Define Network on Chip)-based communication protocol for chiplet-based systems, called MicroLET, which consists of a flexible and modular SDNoC architecture and 3 main phases: Handshake, Network Monitoring, Routing. An implementation of the SDNoC architecture and an evaluation of the proposed routing algorithm compared to the XY and the Odd-Even algorithms within different traffic scenarios is presented. Through the evaluation of the MicroLET protocol, it is proven that it could be a good candidate for the future chiplet-based systems.},
	booktitle = {2019 22nd {Euromicro} {Conference} on {Digital} {System} {Design} ({DSD})},
	author = {Ellinidou, S. and Sharma, G. and Kontogiannis, S. and Markowitch, O. and Dricot, J. and Gogniat, G.},
	month = aug,
	year = {2019},
	keywords = {Chilet System, Chiplets, Communication Protocol, Computer architecture, Industries, Integrated circuit interconnections, NoC, Protocols, Routing, SDNoC, Silicon},
	pages = {61--68},
}

@article{vivet_intact_2021,
	title = {{IntAct}: {A} 96-{Core} {Processor} {With} {Six} {Chiplets} {3D}-{Stacked} on an {Active} {Interposer} {With} {Distributed} {Interconnects} and {Integrated} {Power} {Management}},
	volume = {56},
	issn = {1558-173X},
	shorttitle = {{IntAct}},
	doi = {10.1109/JSSC.2020.3036341},
	abstract = {In the context of high-performance computing, the integration of more computing capabilities with generic cores or dedicated accelerators for artificial intelligence (AI) application is raising more and more challenges. Due to the increasing costs of advanced nodes and the difficulties of shrinking analog and circuit input output signals (IOs), alternative architecture solutions to single die are becoming mainstream. Chiplet-based systems using 3D technologies enable modular and scalable architecture and technology partitioning. Nevertheless, there are still limitations due to chiplet integration on passive interposers-silicon or organic. In this article we present the first CMOS active interposer, integrating: 1) power management without any external components; 2) distributed interconnects enabling any chiplet-to-chiplet communication; and 3) system infrastructure, design-for-test, and circuit IOs. The IntAct circuit prototype integrates six chiplets in FDSOI 28-nm technology, which are 3D-stacked onto this active interposer in 65-nm process, offering a total of 96 computing cores. Full scalability of the computing system is achieved using an innovative scalable cache-coherent memory hierarchy, enabled by distributed network-on-chips, with 3-Tbit/s/mm2 high bandwidth 3D-plug interfaces using 20-μm pitch micro-bumps, 0.6-ns/mm low latency asynchronous interconnects, while the six chiplets are locally power-supplied with 156-mW/mm2 at 82\%-peak-efficiency dc-dc converters through the active interposer. Thermal dissipation is studied showing the feasibility of such approach.},
	number = {1},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Vivet, P. and Guthmuller, E. and Thonnart, Y. and Pillonnet, G. and Fuguet, C. and Miro-Panades, I. and Moritz, G. and Durupt, J. and Bernard, C. and Varreau, D. and Pontes, J. and Thuries, S. and Coriat, D. and Harrand, M. and Dutoit, D. and Lattard, D. and Arnaud, L. and Charbonnier, J. and Coudrain, P. and Garnier, A. and Berger, F. and Gueugnot, A. and Greiner, A. and Meunier, Q. L. and Farcy, A. and Arriordaz, A. and Chéramy, S. and Clermidy, F.},
	month = jan,
	year = {2021},
	note = {Conference Name: IEEE Journal of Solid-State Circuits},
	keywords = {3D technology, Bridge circuits, CMOS technology, Integrated circuit interconnections, Memory management, Power system management, Substrates, Three-dimensional displays, active interposer, chiplet, network-on-chip (NoC), power management, thermal dissipation},
	pages = {79--97},
}

@article{stow_cost-effective_nodate,
	title = {Cost-{Effective} {Design} of {Scalable} {High}-{Performance} {Systems} {Using} {Active} and {Passive} {Interposers}},
	abstract = {Cutting-edge high-performance systems demand larger and denser processors, but future lithographic nodes are expected to introduce higher manufacturing costs and yield challenges. Die-level integration technologies like passive interposerbased 2.5D have demonstrated the potential for cost reductions through die partitioning and yield improvement, but system performance and scalability may be impacted. Alternatively, active interposer technology, the intersection of 3D and 2.5D methodologies, can provide higher-performance interconnect networks to integrate chiplets, but the active interposer die is itself subject to cost and yield concerns. In this work, we perform a cost and performance comparison between traditional monolithic 2D SoCs, 2.5D passive interposers, and 2.5D/3D active interposers to demonstrate the trade-offs between the interposer types for current and future high-performance systems. This work introduces a multi-die core-binning cost model to demonstrate the yield improvements from interposer-based die partitioning of large multi-core processors. The relative cost and performance scaling trade-offs of passive and active interposer dies are then compared for the target systems, demonstrating that both methodologies can indeed provide cost-effective integration for different system requirements. Finally, this work demonstrates how the extra “prepaid” silicon area of the interposers can be leveraged for fault tolerance to improve yield and cost-effectiveness. In summary, this work concludes that both active and passive interposers can cost-effectively improve the functional and parametric yield of high-performance systems, together providing a cost versus performance space to meet a range of design requirements.},
	language = {en},
	author = {Stow, Dylan and Xie, Yuan and Siddiqua, Taniya and Loh, Gabriel H},
	pages = {8},
}

@inproceedings{jerger_noc_2014,
	title = {{NoC} {Architectures} for {Silicon} {Interposer} {Systems}: {Why} {Pay} for more {Wires} when you {Can} {Get} them (from your interposer) for {Free}?},
	shorttitle = {{NoC} {Architectures} for {Silicon} {Interposer} {Systems}},
	doi = {10.1109/MICRO.2014.61},
	abstract = {Silicon interposer technology ("2.5D" stacking) enables the integration of multiple memory stacks with a processor chip, thereby greatly increasing in-package memory capacity while largely avoiding the thermal challenges of 3D stacking DRAM on the processor. Systems employing interposers for memory integration use the interposer to provide point-to-point interconnects between chips. However, these interconnects only utilize a fraction of the interposer's overall routing capacity, and in this work we explore how to take advantage of this otherwise unused resource. We describe a general approach for extending the architecture of a network-on-chip (NoC) to better exploit the additional routing resources of the silicon interposer. We propose an asymmetric organization that distributes the NoC across both a multi-core chip and the interposer, where each sub-network is different from the other in terms of the traffic types, topologies, the use or non-use of concentration, direct vs. Indirect network organizations, and other network attributes. Through experimental evaluation, we show that exploiting the otherwise unutilized routing resources of the interposer can lead to significantly better performance.},
	booktitle = {2014 47th {Annual} {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture}},
	author = {Jerger, N. E. and Kannan, A. and Li, Z. and Loh, G. H.},
	month = dec,
	year = {2014},
	note = {ISSN: 2379-3155},
	keywords = {Bandwidth, Metals, Multicore processing, Routing, Silicon, Stacking, Topology},
	pages = {458--470},
}

@inproceedings{pano_3d_2019,
	address = {New York New York},
	title = {{3D} {NoCs} with active interposer for multi-die systems},
	isbn = {978-1-4503-6700-4},
	url = {https://dl.acm.org/doi/10.1145/3313231.3352380},
	doi = {10.1145/3313231.3352380},
	abstract = {Advances in interconnect technologies for system-in-package manufacturing have re-introduced multi-chip module (MCM) architectures as an alternative to the current monolithic approach. MCMs or multi-die systems implement multiple smaller chiplets in a single package. ese MCMs are connected through various package interconnect technologies, such as current industry solutions in AMD’s In nity Fabric, Intel’s Foveros active interposer, and Marvell’s Mochi Interconnect. Although MCMs improve manufacturing yields and are cost-e ective, additional challenges on the Network-onChip (NoC) within a single chiplet and across multiple chiplets need to be addressed. ese challenges include routing, scalability performance, and resource allocation. is work introduces a scalable MCM 3D interconnect infrastructure called ‘‘MCM-3D-NoC’’ with multiple 3D chiplets connected through an active interposer. System-level simulations of MCM-3D-NoC are performed to validate the proposed architecture and provide performance evaluation of network latency, throughput, and EDP.},
	language = {en},
	urldate = {2021-04-15},
	booktitle = {Proceedings of the 13th {IEEE}/{ACM} {International} {Symposium} on {Networks}-on-{Chip}},
	publisher = {ACM},
	author = {Pano, Vasil and Kuttappa, Ragh and Taskin, Baris},
	month = oct,
	year = {2019},
	pages = {1--8},
}

@article{zhao_phism_2021,
	title = {Phism: {Polyhedral} {High}-{Level} {Synthesis} in {MLIR}},
	shorttitle = {Phism},
	url = {http://arxiv.org/abs/2103.15103},
	abstract = {Polyhedral optimisation, a methodology that views nested loops as polyhedra and searches for their optimal transformation regarding specific objectives (parallelism, locality, etc.), sounds promising for mitigating difficulties in automatically optimising hardware designs described by high-level synthesis (HLS), which are typically software programs with nested loops. Nevertheless, existing polyhedral tools cannot meet the requirements from HLS developers for platform-specific customisation and software/hardware co-optimisation. This paper proposes ������������������ (Phism), a polyhedral HLS framework built on MLIR, to address these challenges through progressive lowering multi-level intermediate representations (IRs) from polyhedra to HLS designs.},
	language = {en},
	urldate = {2021-04-12},
	journal = {arXiv:2103.15103 [cs]},
	author = {Zhao, Ruizhe and Cheng, Jianyi},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.15103},
	keywords = {Computer Science - Hardware Architecture, Computer Science - Programming Languages},
}

@article{gysi_domain-specific_2020,
	title = {Domain-{Specific} {Multi}-{Level} {IR} {Rewriting} for {GPU}},
	url = {http://arxiv.org/abs/2005.13014},
	abstract = {Traditional compilers operate on a single generic intermediate representation (IR). These IRs are usually low-level and close to machine instructions. As a result, optimizations relying on domain-speciﬁc information are either not possible or require complex analysis to recover the missing information. In contrast, multi-level rewriting instantiates a hierarchy of dialects (IRs), lowers programs level-by-level, and performs code transformations at the most suitable level. We demonstrate the effectiveness of this approach for the weather and climate domain. In particular, we develop a prototype compiler and design stenciland GPU-speciﬁc dialects based on a set of newly introduced design principles. We ﬁnd that two domain-speciﬁc optimizations (500 lines of code) realized on top of LLVM’s extensible MLIR compiler infrastructure sufﬁce to outperform state-of-the-art solutions. In essence, multi-level rewriting promises to herald the age of specialized compilers composed from domain- and targetspeciﬁc dialects implemented on top of a shared infrastructure.},
	language = {en},
	urldate = {2021-04-12},
	journal = {arXiv:2005.13014 [cs]},
	author = {Gysi, Tobias and Müller, Christoph and Zinenko, Oleksandr and Herhut, Stephan and Davis, Eddie and Wicky, Tobias and Fuhrer, Oliver and Hoefler, Torsten and Grosser, Tobias},
	month = jul,
	year = {2020},
	note = {arXiv: 2005.13014},
	keywords = {Computer Science - Programming Languages},
}

@inproceedings{sharifian_ir_2019,
	address = {Columbus OH USA},
	title = {μ{IR} -{An} intermediate representation for transforming and optimizing the microarchitecture of application accelerators},
	isbn = {978-1-4503-6938-1},
	url = {https://dl.acm.org/doi/10.1145/3352460.3358292},
	doi = {10.1145/3352460.3358292},
	abstract = {Creating high quality application-speciﬁc accelerators requires us to make iterative changes to both algorithm behavior and microarchitecture, and this is a tedious and error-prone process. High-Level Synthesis (HLS) tools [5, 10] generate RTL for application accelerators from annotated software. Unfortunately, the generated RTL is challenging to change and optimize. The primary limitation of HLS is that the functionality and microarchitecture are conﬂated together in a single language (such as C++). Making changes to the accelerator design may require code restructuring, and microarchitecture optimizations are tied with program correctness. We propose a generalized intermediate representation for describing accelerator microarchitecture, µIR, and an associated pass framework, µopt. µIR represents the accelerator as a concurrent structural graph in which the components roughly correspond to microarchitecture level hardware blocks (e.g., function units, network, memory banks). There are two important beneﬁts i) it decouples microarchitecture optimizations from algorithm/program optimizations. ii) it decouples microarchitecture optimizations from the RTL generation. Computer architects express their ideas as a set of iterative transformations of the µIR graph that successively reﬁne the accelerator architecture. The µIR graph is then translated to Chisel, while maintaining the execution model and cycle-level performance characteristics. In this paper, we study three broad classes of optimizations: Timing (e.g., Pipeline re-timing), Spatial (e.g., Compute tiling), and Higher-order Ops (e.g., Tensor function units) that deliver between 1.5 — 8× improvement in performance; overall 5—20× speedup compared to an ARM A9 1Ghz. We evaluate the quality of the autogenerated accelerators on an Arria 10 FPGA and under ASIC UMC 28nm technology.},
	language = {en},
	urldate = {2021-04-12},
	booktitle = {Proceedings of the 52nd {Annual} {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture}},
	publisher = {ACM},
	author = {Sharifian, Amirali and Hojabr, Reza and Rahimi, Navid and Liu, Sihao and Guha, Apala and Nowatzki, Tony and Shriraman, Arrvindh},
	month = oct,
	year = {2019},
	pages = {940--953},
}

@article{baleani_hwsw_nodate,
	title = {{HW}/{SW} {Partitioning} and {Code} {Generation} of {Embedded} {Control} {Applications} on a {Reconfigurable} {Architecture} {Platform}},
	abstract = {This paper studies the use of a reconfigurable architecture platform for embedded control applications aimed at improving real time performance. The hw/sw codesign methodology from POLLS is used. It starts from high-level specifications, optimizes an intermediate model of computation (Extended Finite State Machines) and derives both hardware and software, based on performance constraints. We study a particular architecture platform, which consists of a general purpose processor core, augmented with a reconfigurable function unit and data-path to improve run time performance. A new mapping flow and algorithms to partition hardware and software are proposed to generate implementations that best utilize this architecture. Encouraging preliminary results are shown for automotive electronic control examples.},
	language = {en},
	author = {Baleani, Massimo and Gennari, Frank},
	pages = {6},
}

@incollection{hutchison_polyhedral_2010,
	address = {Berlin, Heidelberg},
	title = {The {Polyhedral} {Model} {Is} {More} {Widely} {Applicable} {Than} {You} {Think}},
	volume = {6011},
	isbn = {978-3-642-11969-9 978-3-642-11970-5},
	url = {http://link.springer.com/10.1007/978-3-642-11970-5_16},
	abstract = {The polyhedral model is a powerful framework for automatic optimization and parallelization. It is based on an algebraic representation of programs, allowing to construct and search for complex sequences of optimizations. This model is now mature and reaches production compilers. The main limitation of the polyhedral model is known to be its restriction to statically predictable, loop-based program parts. This paper removes this limitation, allowing to operate on general data-dependent control-ﬂow. We embed control and exit predicates as ﬁrst-class citizens of the algebraic representation, from program analysis to code generation. Complementing previous (partial) attempts in this direction, our work concentrates on extending the code generation step and does not compromise the expressiveness of the model. We present experimental evidence that our extension is relevant for program optimization and parallelization, showing performance improvements on benchmarks that were thought to be out of reach of the polyhedral model.},
	language = {en},
	urldate = {2021-04-12},
	booktitle = {Compiler {Construction}},
	publisher = {Springer Berlin Heidelberg},
	author = {Benabderrahmane, Mohamed-Walid and Pouchet, Louis-Noël and Cohen, Albert and Bastoul, Cédric},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Gupta, Rajiv},
	year = {2010},
	doi = {10.1007/978-3-642-11970-5_16},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {283--303},
}

@article{moses_polygeist_2021,
	title = {Polygeist: {Affine} {C} in {MLIR}},
	abstract = {We present Polygeist, a new tool that reroutes polyhedral compilation flows to use the representation available in the recent MLIR compilation infrastructure. It consists of two parts: a C and C++ frontend capable of converting a wide variety of existing codes into MLIR suitable for polyhedral transformation, and a bi-directional conversion between MLIR’s polyhedral representation and existing polyhedral exchange formats. We demonstrate Polygeist’s flow by converting the entire Polybench/C benchmark suite into MLIR, and by performing an IR-to-IR optimization leveraging an existing polyhedral compiler (Pluto). Our flow produces results within 1.25\% of the state-of-the-art Clang compiler, enabling direct comparison of source-to-source and IR-to-binary compilers. We believe Polygeist can improve the interoperation between MLIR and the existing polyhedral tooling, benefiting both the research and the production compiler communities.},
	language = {en},
	author = {Moses, William S and Zhao, Ruizhe and Chelini, Lorenzo and Zinenko, Oleksandr},
	year = {2021},
	pages = {12},
}

@article{noauthor_arbeitsblatt_nodate-1,
	title = {Arbeitsblatt {Temporale}},
	language = {de},
	pages = {2},
}

@article{nigam_compiler_2021,
	title = {A {Compiler} {Infrastructure} for {Accelerator} {Generators}},
	url = {http://arxiv.org/abs/2102.09713},
	abstract = {We present Calyx, a new intermediate language (IL) for compiling high-level programs into hardware designs. Calyx combines a hardware-like structural language with a software-like control flow representation with loops and conditionals. This split representation enables a new class of hardware-focused optimizations that require both structural and control flow information which are crucial for high-level programming models for hardware design. The Calyx compiler lowers control flow constructs using finite-state machines and generates synthesizable hardware descriptions. We have implemented Calyx in an optimizing compiler that translates high-level programs to hardware. We demonstrate Calyx using two DSL-to-RTL compilers, a systolic array generator and one for a recent imperative accelerator language, and compare them to equivalent designs generated using high-level synthesis (HLS). The systolic arrays are 4.6× faster and 1.11× larger on average than HLS implementations, and the HLS-like imperative language compiler is within a few factors of a highly optimized commercial HLS toolchain. We also describe three optimizations implemented in the Calyx compiler.},
	language = {en},
	urldate = {2021-04-08},
	journal = {arXiv:2102.09713 [cs]},
	author = {Nigam, Rachit and Thomas, Samuel and Li, Zhijing and Sampson, Adrian},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.09713},
	keywords = {Computer Science - Hardware Architecture, Computer Science - Programming Languages},
}

@inproceedings{hong_adaptive_2019,
	address = {Washington District of Columbia},
	title = {Adaptive sparse tiling for sparse matrix multiplication},
	isbn = {978-1-4503-6225-2},
	url = {https://dl.acm.org/doi/10.1145/3293883.3295712},
	doi = {10.1145/3293883.3295712},
	abstract = {Tiling is a key technique for data locality optimization and is widely used in high-performance implementations of dense matrix-matrix multiplication for multicore/manycore CPUs and GPUs. However, the irregular and matrix-dependent data access pattern of sparse matrix multiplication makes it challenging to use tiling to enhance data reuse. In this paper, we devise an adaptive tiling strategy and apply it to enhance the performance of two primitives: SpMM (product of sparse matrix and dense matrix) and SDDMM (sampled dense-dense matrix multiplication). In contrast to studies that have resorted to non-standard sparse-matrix representations to enhance performance, we use the standard Compressed Sparse Row (CSR) representation, within which intra-row reordering is performed to enable adaptive tiling. Experimental evaluation using an extensive set of matrices from the Sparse Suite collection demonstrates significant performance improvement over currently available state-ofthe-art alternatives.},
	language = {en},
	urldate = {2021-03-29},
	booktitle = {Proceedings of the 24th {Symposium} on {Principles} and {Practice} of {Parallel} {Programming}},
	publisher = {ACM},
	author = {Hong, Changwan and Sukumaran-Rajam, Aravind and Nisa, Israt and Singh, Kunal and Sadayappan, P.},
	month = feb,
	year = {2019},
	pages = {300--314},
}

@article{venkat_loop_nodate,
	title = {Loop and {Data} {Transformations} for {Sparse} {Matrix} {Code}},
	abstract = {This paper introduces three new compiler transformations for representing and transforming sparse matrix computations and their data representations. In cooperation with run-time inspection, our compiler derives transformed matrix representations and associated transformed code to implement a variety of representations targeting different architecture platforms. This systematic approach to combining code and data transformations on sparse computations, which extends a polyhedral transformation and code generation framework, permits the compiler to compose these transformations with other transformations to generate code that is on average within 5\% and often exceeds manually-tuned, highperformance sparse matrix libraries CUSP and OSKI. Additionally, the compiler-generated inspector codes are on average 1.5× faster than OSKI and perform comparably to CUSP, respectively.},
	language = {en},
	author = {Venkat, Anand and Hall, Mary and Strout, Michelle},
	pages = {12},
}

@article{venkat_loop_nodate-1,
	title = {Loop and {Data} {Transformations} for {Sparse} {Matrix} {Code}},
	abstract = {This paper introduces three new compiler transformations for representing and transforming sparse matrix computations and their data representations. In cooperation with run-time inspection, our compiler derives transformed matrix representations and associated transformed code to implement a variety of representations targeting different architecture platforms. This systematic approach to combining code and data transformations on sparse computations, which extends a polyhedral transformation and code generation framework, permits the compiler to compose these transformations with other transformations to generate code that is on average within 5\% and often exceeds manually-tuned, highperformance sparse matrix libraries CUSP and OSKI. Additionally, the compiler-generated inspector codes are on average 1.5× faster than OSKI and perform comparably to CUSP, respectively.},
	language = {en},
	author = {Venkat, Anand and Hall, Mary and Strout, Michelle},
	pages = {12},
}

@inproceedings{achour_noise-aware_2020,
	address = {Lausanne Switzerland},
	title = {Noise-{Aware} {Dynamical} {System} {Compilation} for {Analog} {Devices} with {Legno}},
	isbn = {978-1-4503-7102-5},
	url = {https://dl.acm.org/doi/10.1145/3373376.3378449},
	doi = {10.1145/3373376.3378449},
	abstract = {Reconfigurable analog devices are a powerful new computing substrate especially appropriate for executing computationally intensive dynamical system computations in an energy efficient manner. We present Legno, a compilation toolchain for programmable analog devices. Legno targets the HCDCv2, a programmable analog device designed to execute general nonlinear dynamical systems. To the best of our knowledge, Legno is the first compiler to successfully target a physical (as opposed to simulated) programmable analog device for dynamical systems and this paper is the first to present experimental results for any compiled computation executing on any physical programmable analog device of this class. The Legno compiler synthesizes analog circuits from parametric and specialized blocks and account for analog noise, quantization error, and manufacturing variations within the device. We evaluate the compiled configurations on the Sendyne S100Asy RevU development board on twelve benchmarks from physics, controls, and biology. Our results show that Legno produces accurate computations on the analog device. The computations execute in 0.50-5.92 ms and consume 0.28-5.67 µJ of energy.},
	language = {en},
	urldate = {2021-03-28},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Achour, Sara and Rinard, Martin},
	month = mar,
	year = {2020},
	pages = {149--166},
}

@inproceedings{hegde_extensor_2019,
	address = {Columbus OH USA},
	title = {{ExTensor}: {An} {Accelerator} for {Sparse} {Tensor} {Algebra}},
	isbn = {978-1-4503-6938-1},
	shorttitle = {{ExTensor}},
	url = {https://dl.acm.org/doi/10.1145/3352460.3358275},
	doi = {10.1145/3352460.3358275},
	abstract = {Generalized tensor algebra is a prime candidate for acceleration via customized ASICs. Modern tensors feature a wide range of data sparsity, with the density of non-zero elements ranging from 10−6\% to 50\%. This paper proposes a novel approach to accelerate tensor kernels based on the principle of hierarchical elimination of computation in the presence of sparsity. This approach relies on rapidly inding intersectionsÐsituations where both operands of a multiplication are non-zeroÐenabling new data fetching mechanisms and avoiding memory latency overheads associated with sparse kernels implemented in software.},
	language = {en},
	urldate = {2021-03-27},
	booktitle = {Proceedings of the 52nd {Annual} {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture}},
	publisher = {ACM},
	author = {Hegde, Kartik and Asghari-Moghaddam, Hadi and Pellauer, Michael and Crago, Neal and Jaleel, Aamer and Solomonik, Edgar and Emer, Joel and Fletcher, Christopher W.},
	month = oct,
	year = {2019},
	pages = {319--333},
}

@inproceedings{wang_autosa_2021,
	address = {Virtual Event USA},
	title = {{AutoSA}: {A} {Polyhedral} {Compiler} for {High}-{Performance} {Systolic} {Arrays} on {FPGA}},
	isbn = {978-1-4503-8218-2},
	shorttitle = {{AutoSA}},
	url = {https://dl.acm.org/doi/10.1145/3431920.3439292},
	doi = {10.1145/3431920.3439292},
	abstract = {While systolic array architectures have the potential to deliver tremendous performance, it is notoriously challenging to customize an efficient systolic array processor for a target application. Designing systolic arrays requires knowledge for both high-level characteristics of the application and low-level hardware details, thus making it a demanding and inefficient process. To relieve users from the manual iterative trial-and-error process, we present AutoSA, an end-to-end compilation framework for generating systolic arrays on FPGA. AutoSA is based on the polyhedral framework, and further incorporates a set of optimizations on different dimensions to boost performance. An efficient and comprehensive design space exploration is performed to search for high-performance designs. We have demonstrated AutoSA on a wide range of applications, on which AutoSA achieves high performance within a short amount of time. As an example, for matrix multiplication, AutoSA achieves 934 GFLOPs, 3.41 TOPs, and 6.95 TOPs in floating point, 16-bit and 8-bit integer data types on Xilinx Alveo U250.},
	language = {en},
	urldate = {2021-03-26},
	booktitle = {The 2021 {ACM}/{SIGDA} {International} {Symposium} on {Field}-{Programmable} {Gate} {Arrays}},
	publisher = {ACM},
	author = {Wang, Jie and Guo, Licheng and Cong, Jason},
	month = feb,
	year = {2021},
	pages = {93--104},
}

@inproceedings{smith_splatt_2015,
	address = {Hyderabad, India},
	title = {{SPLATT}: {Efficient} and {Parallel} {Sparse} {Tensor}-{Matrix} {Multiplication}},
	isbn = {978-1-4799-8649-1},
	shorttitle = {{SPLATT}},
	url = {http://ieeexplore.ieee.org/document/7161496/},
	doi = {10.1109/IPDPS.2015.27},
	abstract = {Multi-dimensional arrays, or tensors, are increasingly found in ﬁelds such as signal processing and recommender systems. Real-world tensors can be enormous in size and often very sparse. There is a need for efﬁcient, high-performance tools capable of processing the massive sparse tensors of today and the future. This paper introduces SPLATT, a C library with shared-memory parallelism for three-mode tensors. SPLATT contains algorithmic improvements over competing state of the art tools for sparse tensor factorization. SPLATT has a fast, parallel method of multiplying a matricized tensor by a KhatriRao product, which is a key kernel in tensor factorization methods. SPLATT uses a novel data structure that exploits the sparsity patterns of tensors. This data structure has a small memory footprint similar to competing methods and allows for the computational improvements featured in our work. We also present a method of ﬁnding cache-friendly reorderings and utilizing them with a novel form of cache tiling. To our knowledge, this is the ﬁrst work to investigate reordering and cache tiling in this context. SPLATT averages almost 30× speedup compared to our baseline when using 16 threads and reaches over 80× speedup on NELL-2.},
	language = {en},
	urldate = {2021-03-19},
	booktitle = {2015 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium}},
	publisher = {IEEE},
	author = {Smith, Shaden and Ravindran, Niranjay and Sidiropoulos, Nicholas D. and Karypis, George},
	month = may,
	year = {2015},
	pages = {61--70},
}

@inproceedings{qiang_wu_hierarchical_2002,
	address = {Chengdu, China},
	title = {A hierarchical {CDFG} as intermediate representation for hardware/software codesign},
	volume = {2},
	isbn = {978-0-7803-7547-5},
	url = {http://ieeexplore.ieee.org/document/1179048/},
	doi = {10.1109/ICCCAS.2002.1179048},
	abstract = {A hierarchical CDFG model designed as an intermediate representation for hardwarekoftware (HW/SW) codesign is presented in this paper. A new concept of transport node, which represents the communication resources of the system, is proposed in this model. Hierarchical feaNre can he straightly obtained through extending the definition of nodes, allowing them to nest sub-CDFG recursively. Then it is demonstrated how to build basic control constructs of branches and loops. Explaining in a short introduction to the translation process, such a hierarchical CDFG is suitable for HWISW codesign as an intermediate representation.},
	language = {en},
	urldate = {2021-03-17},
	booktitle = {{IEEE} 2002 {International} {Conference} on {Communications}, {Circuits} and {Systems} and {West} {Sino} {Expositions}},
	publisher = {IEEE},
	author = {{Qiang Wu} and {Yunfeng Wang} and {Jinian Bian} and {Weimin Wu} and {Hongxi Xue}},
	year = {2002},
	pages = {1429--1432},
}

@article{chen_tvm_nodate,
	title = {{TVM}: {An} {Automated} {End}-to-{End} {Optimizing} {Compiler} for {Deep} {Learning}},
	abstract = {There is an increasing need to bring machine learning to a wide diversity of hardware devices. Current frameworks rely on vendor-speciﬁc operator libraries and optimize for a narrow range of server-class GPUs. Deploying workloads to new platforms – such as mobile phones, embedded devices, and accelerators (e.g., FPGAs, ASICs) – requires signiﬁcant manual effort. We propose TVM, a compiler that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends. TVM solves optimization challenges speciﬁc to deep learning, such as high-level operator fusion, mapping to arbitrary hardware primitives, and memory latency hiding. It also automates optimization of low-level programs to hardware characteristics by employing a novel, learning-based cost modeling method for rapid exploration of code optimizations. Experimental results show that TVM delivers performance across hardware back-ends that are competitive with state-ofthe-art, hand-tuned libraries for low-power CPU, mobile GPU, and server-class GPUs. We also demonstrate TVM’s ability to target new accelerator back-ends, such as the FPGA-based generic deep learning accelerator. The system is open sourced and in production use inside several major companies.},
	language = {en},
	author = {Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng and Zheng, Lianmin and Yan, Eddie and Cowan, Meghan and Shen, Haichen and Wang, Leyuan and Hu, Yuwei and Ceze, Luis and Guestrin, Carlos and Krishnamurthy, Arvind},
	pages = {17},
}

@inproceedings{pourhabibi_optimus_2020,
	address = {Lausanne Switzerland},
	title = {Optimus {Prime}: {Accelerating} {Data} {Transformation} in {Servers}},
	isbn = {978-1-4503-7102-5},
	shorttitle = {Optimus {Prime}},
	url = {https://dl.acm.org/doi/10.1145/3373376.3378501},
	doi = {10.1145/3373376.3378501},
	abstract = {Modern online services are shifting away from monolithic applications to loosely-coupled microservices because of their improved scalability, reliability, programmability and development velocity. Microservices communicating over the datacenter network require data transformation (DT) to convert messages back and forth between their internal formats. This work identifies DT as a bottleneck due to reductions in latency of the surrounding system components, namely application runtimes, protocol stacks, and network hardware. We therefore propose Optimus Prime (OP), a programmable DT accelerator that uses a novel abstraction, an in-memory schema, to represent DT operations. The schema is compatible with today’s DT frameworks and enables any compliant accelerator to perform the transformations comprising a request in parallel. Our evaluation shows that OP’s DT throughput matches the line rate of today’s NICs and has {\textasciitilde}60× higher throughput compared to software, at a tiny fraction of the CPU’s silicon area and power. We also evaluate a set of microservices running on Thrift, and show up to 30\% reduction in service latency.},
	language = {en},
	urldate = {2021-03-16},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Pourhabibi, Arash and Gupta, Siddharth and Kassir, Hussein and Sutherland, Mark and Tian, Zilu and Drumond, Mario Paulo and Falsafi, Babak and Koch, Christoph},
	month = mar,
	year = {2020},
	pages = {1203--1216},
}

@inproceedings{lai_heterocl_2019,
	address = {Seaside CA USA},
	title = {{HeteroCL}: {A} {Multi}-{Paradigm} {Programming} {Infrastructure} for {Software}-{Defined} {Reconfigurable} {Computing}},
	isbn = {978-1-4503-6137-8},
	shorttitle = {{HeteroCL}},
	url = {https://dl.acm.org/doi/10.1145/3289602.3293910},
	doi = {10.1145/3289602.3293910},
	abstract = {With the pursuit of improving compute performance under strict power constraints, there is an increasing need for deploying applications to heterogeneous hardware architectures with accelerators, such as GPUs and FPGAs. However, although these heterogeneous computing platforms are becoming widely available, they are very di�cult to program especially with FPGAs. As a result, the use of such platforms has been limited to a small subset of programmers with specialized hardware knowledge.},
	language = {en},
	urldate = {2021-03-16},
	booktitle = {Proceedings of the 2019 {ACM}/{SIGDA} {International} {Symposium} on {Field}-{Programmable} {Gate} {Arrays}},
	publisher = {ACM},
	author = {Lai, Yi-Hsiang and Chi, Yuze and Hu, Yuwei and Wang, Jie and Yu, Cody Hao and Zhou, Yuan and Cong, Jason and Zhang, Zhiru},
	month = feb,
	year = {2019},
	pages = {242--251},
}

@article{duarte_fast_2018,
	title = {Fast inference of deep neural networks in {FPGAs} for particle physics},
	volume = {13},
	issn = {1748-0221},
	url = {http://arxiv.org/abs/1804.06913},
	doi = {10.1088/1748-0221/13/07/P07027},
	abstract = {Recent results at the Large Hadron Collider (LHC) have pointed to enhanced physics capabilities through the improvement of the real-time event processing techniques. Machine learning methods are ubiquitous and have proven to be very powerful in LHC physics, and particle physics as a whole. However, exploration of the use of such techniques in low-latency, low-power FPGA hardware has only just begun. FPGA-based trigger and data acquisition (DAQ) systems have extremely low, sub-microsecond latency requirements that are unique to particle physics. We present a case study for neural network inference in FPGAs focusing on a classifier for jet substructure which would enable, among many other physics scenarios, searches for new dark sector particles and novel measurements of the Higgs boson. While we focus on a specific example, the lessons are far-reaching. We develop a package based on High-Level Synthesis (HLS) called hls4ml to build machine learning models in FPGAs. The use of HLS increases accessibility across a broad user community and allows for a drastic decrease in firmware development time. We map out FPGA resource usage and latency versus neural network hyperparameters to identify the problems in particle physics that would benefit from performing neural network inference with FPGAs. For our example jet substructure model, we fit well within the available resources of modern FPGAs with a latency on the scale of 100 ns.},
	language = {en},
	number = {07},
	urldate = {2021-03-16},
	journal = {Journal of Instrumentation},
	author = {Duarte, Javier and Han, Song and Harris, Philip and Jindariani, Sergo and Kreinar, Edward and Kreis, Benjamin and Ngadiuba, Jennifer and Pierini, Maurizio and Rivera, Ryan and Tran, Nhan and Wu, Zhenbin},
	month = jul,
	year = {2018},
	note = {arXiv: 1804.06913},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, High Energy Physics - Experiment, Physics - Instrumentation and Detectors, Statistics - Machine Learning},
	pages = {P07027--P07027},
}

@article{prabhakar_generating_nodate,
	title = {Generating {Conﬁgurable} {Hardware} from {Parallel} {Patterns}},
	abstract = {In recent years the computing landscape has seen an increasing shift towards specialized accelerators. Field programmable gate arrays (FPGAs) are particularly promising for the implementation of these accelerators, as they offer signiﬁcant performance and energy improvements over CPUs for a wide class of applications and are far more ﬂexible than ﬁxed-function ASICs. However, FPGAs are difﬁcult to program. Traditional programming models for reconﬁgurable logic use low-level hardware description languages like Verilog and VHDL, which have none of the productivity features of modern software languages but produce very efﬁcient designs, and low-level software languages like C and OpenCL coupled with high-level synthesis (HLS) tools that typically produce designs that are far less efﬁcient.},
	language = {en},
	author = {Prabhakar, Raghu and Koeplinger, David and Brown, Kevin J and Lee, HyoukJoong},
	pages = {15},
}

@inproceedings{wang_flexcl_2017,
	address = {Austin TX USA},
	title = {{FlexCL}: {An} {Analytical} {Performance} {Model} for {OpenCL} {Workloads} on {Flexible} {FPGAs}},
	isbn = {978-1-4503-4927-7},
	shorttitle = {{FlexCL}},
	url = {https://dl.acm.org/doi/10.1145/3061639.3062251},
	doi = {10.1145/3061639.3062251},
	abstract = {The recent adoption of OpenCL programming model by FPGA vendors has realized the function portability of OpenCL workloads on FPGA. However, the poor performance portability prevents its wide adoption. To harness the power of FPGAs using OpenCL programming model, it is advantageous to design an analytical performance model to estimate the performance of OpenCL workloads on FPGAs and provide insights into the performance bottlenecks of OpenCL model on FPGA architecture. To this end, this paper presents FlexCL, an analytical performance model for OpenCL workloads on ﬂexible FPGAs. FlexCL estimates the overall performance by tightly coupling the oﬀchip global memory and on-chip computation models based on the communication mode. Experiments demonstrate that with respect to RTL-based implementation, the average of absolute error of FlexCL is 9.5\% and 8.7\% for the Rodinia and PolyBench suite, respectively. Moreover, FlexCL enables rapid exploration of the design space within seconds instead of hours or days.},
	language = {en},
	urldate = {2021-03-16},
	booktitle = {Proceedings of the 54th {Annual} {Design} {Automation} {Conference} 2017},
	publisher = {ACM},
	author = {Wang, Shuo and Liang, Yun and Zhang, Wei},
	month = jun,
	year = {2017},
	pages = {1--6},
}

@inproceedings{zhao_comba_2017,
	address = {Irvine, CA},
	title = {{COMBA}: {A} comprehensive model-based analysis framework for high level synthesis of real applications},
	isbn = {978-1-5386-3093-8},
	shorttitle = {{COMBA}},
	url = {http://ieeexplore.ieee.org/document/8203809/},
	doi = {10.1109/ICCAD.2017.8203809},
	abstract = {High Level Synthesis (HLS) relies on the use of synthesis pragmas to generate digital designs meeting a set of speciﬁcations. However, the selection of a set of pragmas depends largely on designer experience and knowledge of the target architecture and digital design. Existing automated methods of pragma selection are very limited in scope and capability to analyze complex design descriptions in high-level languages to be synthesized using HLS. In this paper, we propose COMBA, a comprehensive model-based analysis framework capable of analyzing the effects of a multitude of pragmas related to functions, loops and arrays in the design description using pluggable analytical models, a recursive data collector (RDC) and a metricguided design space exploration algorithm (MGDSE). When compared with HLS tools like Vivado HLS, COMBA reports an average error of around 1\% in estimating performance, while taking only a few seconds for analysis of Polybench benchmark applications and a few minutes for real-life applications like JPEG, Seidel and Rician. The synthesis pragmas recommended by COMBA result in an average 100x speed-up in performance for the analyzed applications, which establishes COMBA as a superior alternative to current state-of-the-art approaches.},
	language = {en},
	urldate = {2021-03-16},
	booktitle = {2017 {IEEE}/{ACM} {International} {Conference} on {Computer}-{Aided} {Design} ({ICCAD})},
	publisher = {IEEE},
	author = {Zhao, Jieru and Feng, Liang and Sinha, Sharad and Zhang, Wei and Liang, Yun and He, Bingsheng},
	month = nov,
	year = {2017},
	pages = {430--437},
}

@inproceedings{pal_outerspace_2018,
	address = {Vienna},
	title = {{OuterSPACE}: {An} {Outer} {Product} {Based} {Sparse} {Matrix} {Multiplication} {Accelerator}},
	isbn = {978-1-5386-3659-6},
	shorttitle = {{OuterSPACE}},
	url = {http://ieeexplore.ieee.org/document/8327050/},
	doi = {10.1109/HPCA.2018.00067},
	abstract = {Sparse matrices are widely used in graph and data analytics, machine learning, engineering and scientiﬁc applications. This paper describes and analyzes OuterSPACE, an accelerator targeted at applications that involve large sparse matrices. OuterSPACE is a highly-scalable, energy-eﬃcient, reconﬁgurable design, consisting of massively parallel Single Program, Multiple Data (SPMD)style processing units, distributed memories, high-speed crossbars and High Bandwidth Memory (HBM). We identify redundant memory accesses to non-zeros as a key bottleneck in traditional sparse matrix-matrix multiplication algorithms. To ameliorate this, we implement an outer product based matrix multiplication technique that eliminates redundant accesses by decoupling multiplication from accumulation. We demonstrate that traditional architectures, due to limitations in their memory hierarchies and ability to harness parallelism in the algorithm, are unable to take advantage of this reduction without incurring signiﬁcant overheads. OuterSPACE is designed to speciﬁcally overcome these challenges.},
	language = {en},
	urldate = {2021-03-14},
	booktitle = {2018 {IEEE} {International} {Symposium} on {High} {Performance} {Computer} {Architecture} ({HPCA})},
	publisher = {IEEE},
	author = {Pal, Subhankar and Beaumont, Jonathan and Park, Dong-Hyeon and Amarnath, Aporva and Feng, Siying and Chakrabarti, Chaitali and Kim, Hun-Seok and Blaauw, David and Mudge, Trevor and Dreslinski, Ronald},
	month = feb,
	year = {2018},
	pages = {724--736},
}

@inproceedings{pal_outerspace_2018-1,
	address = {Vienna},
	title = {{OuterSPACE}: {An} {Outer} {Product} {Based} {Sparse} {Matrix} {Multiplication} {Accelerator}},
	isbn = {978-1-5386-3659-6},
	shorttitle = {{OuterSPACE}},
	url = {http://ieeexplore.ieee.org/document/8327050/},
	doi = {10.1109/HPCA.2018.00067},
	abstract = {Sparse matrices are widely used in graph and data analytics, machine learning, engineering and scientiﬁc applications. This paper describes and analyzes OuterSPACE, an accelerator targeted at applications that involve large sparse matrices. OuterSPACE is a highly-scalable, energy-eﬃcient, reconﬁgurable design, consisting of massively parallel Single Program, Multiple Data (SPMD)style processing units, distributed memories, high-speed crossbars and High Bandwidth Memory (HBM). We identify redundant memory accesses to non-zeros as a key bottleneck in traditional sparse matrix-matrix multiplication algorithms. To ameliorate this, we implement an outer product based matrix multiplication technique that eliminates redundant accesses by decoupling multiplication from accumulation. We demonstrate that traditional architectures, due to limitations in their memory hierarchies and ability to harness parallelism in the algorithm, are unable to take advantage of this reduction without incurring signiﬁcant overheads. OuterSPACE is designed to speciﬁcally overcome these challenges.},
	language = {en},
	urldate = {2021-03-14},
	booktitle = {2018 {IEEE} {International} {Symposium} on {High} {Performance} {Computer} {Architecture} ({HPCA})},
	publisher = {IEEE},
	author = {Pal, Subhankar and Beaumont, Jonathan and Park, Dong-Hyeon and Amarnath, Aporva and Feng, Siying and Chakrabarti, Chaitali and Kim, Hun-Seok and Blaauw, David and Mudge, Trevor and Dreslinski, Ronald},
	month = feb,
	year = {2018},
	pages = {724--736},
}

@article{gale_sparse_2020,
	title = {Sparse {GPU} {Kernels} for {Deep} {Learning}},
	url = {http://arxiv.org/abs/2006.10901},
	abstract = {Scientiﬁc workloads have traditionally exploited high levels of sparsity to accelerate computation and reduce memory requirements. While deep neural networks can be made sparse, achieving practical speedups on GPUs is difﬁcult because these applications have relatively moderate levels of sparsity that are not sufﬁcient for existing sparse kernels to outperform their dense counterparts. In this work, we study sparse matrices from deep learning applications and identify favorable properties that can be exploited to accelerate computation. Based on these insights, we develop high-performance GPU kernels for two sparse matrix operations widely applicable in neural networks: sparse matrix–dense matrix multiplication and sampled dense–dense matrix multiplication. Our kernels reach 27\% of singleprecision peak on Nvidia V100 GPUs. Using our kernels, we demonstrate sparse Transformer and MobileNet models that achieve 1.2–2.1× speedups and up to 12.8× memory savings without sacriﬁcing accuracy.},
	language = {en},
	urldate = {2021-03-14},
	journal = {arXiv:2006.10901 [cs, stat]},
	author = {Gale, Trevor and Zaharia, Matei and Young, Cliff and Elsen, Erich},
	month = aug,
	year = {2020},
	note = {arXiv: 2006.10901},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{wang_flexcl_2017-1,
	address = {Austin TX USA},
	title = {{FlexCL}: {An} {Analytical} {Performance} {Model} for {OpenCL} {Workloads} on {Flexible} {FPGAs}},
	isbn = {978-1-4503-4927-7},
	shorttitle = {{FlexCL}},
	url = {https://dl.acm.org/doi/10.1145/3061639.3062251},
	doi = {10.1145/3061639.3062251},
	abstract = {The recent adoption of OpenCL programming model by FPGA vendors has realized the function portability of OpenCL workloads on FPGA. However, the poor performance portability prevents its wide adoption. To harness the power of FPGAs using OpenCL programming model, it is advantageous to design an analytical performance model to estimate the performance of OpenCL workloads on FPGAs and provide insights into the performance bottlenecks of OpenCL model on FPGA architecture. To this end, this paper presents FlexCL, an analytical performance model for OpenCL workloads on ﬂexible FPGAs. FlexCL estimates the overall performance by tightly coupling the oﬀchip global memory and on-chip computation models based on the communication mode. Experiments demonstrate that with respect to RTL-based implementation, the average of absolute error of FlexCL is 9.5\% and 8.7\% for the Rodinia and PolyBench suite, respectively. Moreover, FlexCL enables rapid exploration of the design space within seconds instead of hours or days.},
	language = {en},
	urldate = {2021-03-11},
	booktitle = {Proceedings of the 54th {Annual} {Design} {Automation} {Conference} 2017},
	publisher = {ACM},
	author = {Wang, Shuo and Liang, Yun and Zhang, Wei},
	month = jun,
	year = {2017},
	pages = {1--6},
}

@inproceedings{srivastava_matraptor_2020,
	address = {Athens, Greece},
	title = {{MatRaptor}: {A} {Sparse}-{Sparse} {Matrix} {Multiplication} {Accelerator} {Based} on {Row}-{Wise} {Product}},
	isbn = {978-1-72817-383-2},
	shorttitle = {{MatRaptor}},
	url = {https://ieeexplore.ieee.org/document/9251978/},
	doi = {10.1109/MICRO50266.2020.00068},
	abstract = {Sparse-sparse matrix multiplication (SpGEMM) is a computation kernel widely used in numerous application domains such as data analytics, graph processing, and scientiﬁc computing. In this work we propose MatRaptor, a novel SpGEMM accelerator that is high performance and highly resource efﬁcient. Unlike conventional methods using inner or outer product as the meta operation for matrix multiplication, our approach is based on row-wise product, which offers a better tradeoff in terms of data reuse and on-chip memory requirements, and achieves higher performance for large sparse matrices. We further propose a new hardware-friendly sparse storage format, which allows parallel compute engines to access the sparse data in a vectorized and streaming fashion, leading to high utilization of memory bandwidth. We prototype and simulate our accelerator architecture using gem5 on a diverse set of matrices. Our experiments show that MatRaptor achieves 129.2× speedup over single-threaded CPU, 8.8× speedup over GPU and 1.8× speedup over the state-of-the-art SpGEMM accelerator (OuterSPACE). MatRaptor also has 7.2× lower power consumption and 31.3× smaller area compared to OuterSPACE.},
	language = {en},
	urldate = {2021-03-04},
	booktitle = {2020 53rd {Annual} {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture} ({MICRO})},
	publisher = {IEEE},
	author = {Srivastava, Nitish and Jin, Hanchen and Liu, Jie and Albonesi, David and Zhang, Zhiru},
	month = oct,
	year = {2020},
	pages = {766--780},
}

@inproceedings{josipovic_buffer_2020,
	address = {Seaside CA USA},
	title = {Buffer {Placement} and {Sizing} for {High}-{Performance} {Dataflow} {Circuits}},
	isbn = {978-1-4503-7099-8},
	url = {https://dl.acm.org/doi/10.1145/3373087.3375314},
	doi = {10.1145/3373087.3375314},
	abstract = {Commercial high-level synthesis tools typically produce statically scheduled circuits. Yet, effective C-to-circuit conversion of arbitrary software applications calls for dataflow circuits, as they can handle efficiently variable latencies (e.g., caches) and unpredictable memory dependencies. Dataflow circuits exhibit an unconventional property: registers (usually referred to as “buffers”) can be placed anywhere in the circuit without changing its semantics, in strong contrast to what happens in traditional datapaths. Yet, although functionally irrelevant, this placement has a significant impact on the circuit’s timing and throughput. In this work, we show how to strategically place buffers into a dataflow circuit to optimize its performance. Our approach extracts a set of choice-free critical loops from arbitrary dataflow circuits and relies on the theory of marked graphs to optimize the buffer placement and sizing. We demonstrate the performance benefits of our approach on a set of dataflow circuits obtained from imperative code.},
	language = {en},
	urldate = {2021-02-27},
	booktitle = {Proceedings of the 2020 {ACM}/{SIGDA} {International} {Symposium} on {Field}-{Programmable} {Gate} {Arrays}},
	publisher = {ACM},
	author = {Josipović, Lana and Sheikhha, Shabnam and Guerrieri, Andrea and Ienne, Paolo and Cortadella, Jordi},
	month = feb,
	year = {2020},
	pages = {186--196},
}

@article{kjolstad_tensor_2017,
	title = {The tensor algebra compiler},
	volume = {1},
	issn = {2475-1421, 2475-1421},
	url = {https://dl.acm.org/doi/10.1145/3133901},
	doi = {10.1145/3133901},
	language = {en},
	number = {OOPSLA},
	urldate = {2021-02-27},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Kjolstad, Fredrik and Kamil, Shoaib and Chou, Stephen and Lugato, David and Amarasinghe, Saman},
	month = oct,
	year = {2017},
	pages = {1--29},
}

@article{senanayake_sparse_2020,
	title = {A sparse iteration space transformation framework for sparse tensor algebra},
	volume = {4},
	issn = {2475-1421, 2475-1421},
	url = {https://dl.acm.org/doi/10.1145/3428226},
	doi = {10.1145/3428226},
	abstract = {We address the problem of optimizing sparse tensor algebra in a compiler and show how to define standard loop transformationsÐsplit, collapse, and reorderÐon sparse iteration spaces. The key idea is to track the transformation functions that map the original iteration space to derived iteration spaces. These functions are needed by the code generator to emit code that maps coordinates between iteration spaces at runtime, since the coordinates in the sparse data structures remain in the original iteration space. We further demonstrate that derived iteration spaces can tile both the universe of coordinates and the subset of nonzero coordinates: the former is analogous to tiling dense iteration spaces, while the latter tiles sparse iteration spaces into statically load-balanced blocks of nonzeros. Tiling the space of nonzeros lets the generated code efficiently exploit heterogeneous compute resources such as threads, vector units, and GPUs. We implement these concepts by extending the sparse iteration theory implementation in the TACO system. The associated scheduling API can be used by performance engineers or it can be the target of an automatic scheduling system. We outline one heuristic autoscheduling system, but other systems are possible. Using the scheduling API, we show how to optimize mixed sparse-dense tensor algebra expressions on CPUs and GPUs. Our results show that the sparse transformations are sufficient to generate code with competitive performance to hand-optimized implementations from the literature, while generalizing to all of the tensor algebra. CCS Concepts: · Software and its engineering → Source code generation; Domain specific languages.},
	language = {en},
	number = {OOPSLA},
	urldate = {2021-02-27},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Senanayake, Ryan and Hong, Changwan and Wang, Ziheng and Wilson, Amalee and Chou, Stephen and Kamil, Shoaib and Amarasinghe, Saman and Kjolstad, Fredrik},
	month = nov,
	year = {2020},
	pages = {1--30},
}

@inproceedings{steinberg_nova_2010,
	address = {Paris, France},
	title = {{NOVA}: a microhypervisor-based secure virtualization architecture},
	isbn = {978-1-60558-577-2},
	shorttitle = {{NOVA}},
	url = {http://portal.acm.org/citation.cfm?doid=1755913.1755935},
	doi = {10.1145/1755913.1755935},
	abstract = {The availability of virtualization features in modern CPUs has reinforced the trend of consolidating multiple guest operating systems on top of a hypervisor in order to improve platform-resource utilization and reduce the total cost of ownership. However, today’s virtualization stacks are unduly large and therefore prone to attacks. If an adversary manages to compromise the hypervisor, subverting the security of all hosted operating systems is easy. We show how a thin and simple virtualization layer reduces the attack surface signiﬁcantly and thereby increases the overall security of the system. We have designed and implemented a virtualization architecture that can host multiple unmodiﬁed guest operating systems. Its trusted computing base is at least an order of magnitude smaller than that of existing systems. Furthermore, on recent hardware, our implementation outperforms contemporary full virtualization environments.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Proceedings of the 5th {European} conference on {Computer} systems - {EuroSys} '10},
	publisher = {ACM Press},
	author = {Steinberg, Udo and Kauer, Bernhard},
	year = {2010},
	pages = {209},
}

@article{zhao_high-assurance_2017,
	title = {High-{Assurance} {Separation} {Kernels}: {A} {Survey} on {Formal} {Methods}},
	shorttitle = {High-{Assurance} {Separation} {Kernels}},
	url = {http://arxiv.org/abs/1701.01535},
	abstract = {Separation kernels provide temporal/spatial separation and controlled information flow to their hosted applications. They are introduced to decouple the analysis of applications in partitions from the analysis of the kernel itself. More than 20 implementations of separation kernels have been developed and widely applied in critical domains, e.g., avionics/aerospace, military/defense, and medical devices. Formal methods are mandated by the security/safety certification of separation kernels and have been carried out since this concept emerged. However, this field lacks a survey to systematically study, compare, and analyze related work. On the other hand, high-assurance separation kernels by formal methods still face big challenges. In this paper, an analytical framework is first proposed to clarify the functionalities, implementations, properties and standards, and formal methods application of separation kernels. Based on the proposed analytical framework, a taxonomy is designed according to formal methods application, functionalities, and properties of separation kernels. Research works in the literature are then categorized and overviewed by the taxonomy. In accordance with the analytical framework, a comprehensive analysis and discussion of related work are presented. Finally, four challenges and their possible technical directions for future research are identified, e.g. specification bottleneck, multicore and concurrency, and automation of full formal verification.},
	language = {en},
	urldate = {2021-02-24},
	journal = {arXiv:1701.01535 [cs]},
	author = {Zhao, Yongwang and Sanan, David and Zhang, Fuyuan and Liu, Yang},
	month = jan,
	year = {2017},
	note = {arXiv: 1701.01535},
	keywords = {Computer Science - Software Engineering},
}

@article{noauthor_modelsim_nodate,
	title = {{ModelSim} {Command} {Reference} {Manual}},
	language = {en},
	pages = {564},
}

@article{sutherland_synthesizing_2013,
	title = {Synthesizing {SystemVerilog} {Busting} the {Myth} that {SystemVerilog} is only for {Verification}},
	abstract = {SystemVerilog is not just for Verification! When the SystemVerilog standard was first devised, one of the primary goals was to enable creating synthesizable models of complex hardware designs more accurately and with fewer lines of code. That goal was achieved, and Synopsys has done a great job of implementing SystemVerilog in both Design Compiler (DC) and Synplify-Pro. This paper examines in detail the synthesizable subset of SystemVerilog for ASIC and FPGA designs, and presents the advantages of using these constructs over traditional Verilog. Readers will take away from this paper new RTL modeling skills that will indeed enable modeling with fewer lines of code, while at the same time reducing potential design errors and achieving high synthesis Quality of Results (QoR).},
	language = {en},
	author = {Sutherland, Stuart and Mills, Don},
	year = {2013},
	pages = {45},
}

@inproceedings{leng_asymmetric_2020,
	address = {San Diego, CA, USA},
	title = {Asymmetric {Resilience}: {Exploiting} {Task}-{Level} {Idempotency} for {Transient} {Error} {Recovery} in {Accelerator}-{Based} {Systems}},
	isbn = {978-1-72816-149-5},
	shorttitle = {Asymmetric {Resilience}},
	url = {https://ieeexplore.ieee.org/document/9065577/},
	doi = {10.1109/HPCA47549.2020.00014},
	abstract = {Accelerators make the task of building systems that are resilient against transient errors like voltage noise and soft errors hard. Architects integrate accelerators into the system as black box third-party IP components. So a fault in one or more accelerators may threaten the system’s reliability if there are no established failure semantics for how an error propagates from the accelerator to the main CPU. Existing solutions that assure system reliability come at the cost of sacriﬁcing accelerator generality, efﬁciency, and incur signiﬁcant overhead, even in the absence of errors. To overcome these drawbacks, we examine reliability management of accelerator systems via hardware-software co-design, coupling an efﬁcient architecture design with compiler and runtime support, to cope with transient errors. We introduce asymmetric resilience that architects reliability at the system level, centered around a hardened CPU, rather than at the accelerator level. At runtime, the system exploits task-level idempotency to contain accelerator errors and use memory protection instead of taking checkpoints to mitigate overheads. We also leverage the fact that errors rarely occur in systems, and exploit the trade-off between error recovery performance and improved error-free performance to enhance system efﬁciency. Using GPUs, which are at the forefront of accelerator systems, we demonstrate how our system architecture manages reliability in both integrated and discrete systems, under voltage-noise and soft-error related faults, leading to extremely low overhead (less than 1\%) and substantial gains (20\% energy savings on average).},
	language = {en},
	urldate = {2021-01-19},
	booktitle = {2020 {IEEE} {International} {Symposium} on {High} {Performance} {Computer} {Architecture} ({HPCA})},
	publisher = {IEEE},
	author = {Leng, Jingwen and Buyuktosunoglu, Alper and Bertran, Ramon and Bose, Pradip and Chen, Quan and Guo, Minyi and Janapa Reddi, Vijay},
	month = feb,
	year = {2020},
	pages = {44--57},
}

@inproceedings{gizopoulos_modern_2019,
	address = {Rhodes, Greece},
	title = {Modern {Hardware} {Margins}: {CPUs}, {GPUs}, {FPGAs} {Recent} {System}-{Level} {Studies}},
	isbn = {978-1-72812-490-2},
	shorttitle = {Modern {Hardware} {Margins}},
	url = {https://ieeexplore.ieee.org/document/8854386/},
	doi = {10.1109/IOLTS.2019.8854386},
	abstract = {Modern large-scale computing systems (data centers, supercomputers, cloud and edge setups and high-end cyber-physical systems) employ heterogeneous architectures that consist of multicore CPUs, general-purpose many-core GPUs, and programmable FPGAs. The effective utilization of these architectures poses several challenges, among which a primary one is power consumption. Voltage reduction is one of the most efficient methods to reduce power consumption of a chip. With the galloping adoption of hardware accelerators (i.e., GPUs and FPGAs) in large datacenters and other large-scale computing infrastructures, a comprehensive evaluation of the safe voltage reduction levels for each different chip can be employed for efficient reduction of the total power. We present a survey of recent studies in voltage margins reduction at the system level for modern CPUs, GPUs and FPGAs. The pessimistic voltage guardbands inserted by the silicon vendors can be exploited in all devices for significant power savings. Voltage reduction can reach 12\% in multicore CPUs, 20\% in manycore GPUs and 39\% in FPGAs.},
	language = {en},
	urldate = {2021-01-19},
	booktitle = {2019 {IEEE} 25th {International} {Symposium} on {On}-{Line} {Testing} and {Robust} {System} {Design} ({IOLTS})},
	publisher = {IEEE},
	author = {Gizopoulos, Dimitris and Papadimitriou, George and Chatzidimitriou, Athanasios and Reddi, Vijay Janapa and Salami, Behzad and Unsal, Osman S. and Kestelman, Adrian Cristal and Leng, Jingwen},
	month = jul,
	year = {2019},
	pages = {129--134},
}

@article{leng_asymmetric_2019,
	title = {Asymmetric {Resilience} for {Accelerator}-{Rich} {Systems}},
	volume = {18},
	issn = {1556-6056, 1556-6064, 2473-2575},
	url = {https://ieeexplore.ieee.org/document/8718383/},
	doi = {10.1109/LCA.2019.2917898},
	abstract = {Accelerators are becoming popular owing to their exceptional performance and power-efﬁciency. However, researchers are yet to pay close attention to their reliability—a key challenge as technology scaling makes building reliable systems challenging. A straightforward solution to make accelerators reliable is to design the accelerator from the ground-up to be reliable by itself. However, such a myopic view of the system, where each accelerator is designed in isolation, is unsustainable as the number of integrated accelerators continues to rise in SoCs. To address this challenge, we propose a paradigm called “asymmetric resilience” that avoids accelerator-speciﬁc reliability design. Instead, its core principle is to develop the reliable heterogeneous system around the CPU architecture. We explain the implications of architecting such a system and the modiﬁcations needed in a heterogeneous system to adopt such an approach. As an example, we demonstrate how to use asymmetric resilience to handle GPU execution errors using the CPU with minimal overhead. The general principles can be extended to include other accelerators.},
	language = {en},
	number = {1},
	urldate = {2021-01-19},
	journal = {IEEE Computer Architecture Letters},
	author = {Leng, Jingwen and Buyuktosunoglu, Alper and Bertran, Ramon and Bose, Pradip and Reddi, Vijay Janapa},
	month = jan,
	year = {2019},
	pages = {83--86},
}

@article{reddi_mlperf_2020,
	title = {{MLPerf} {Mobile} {Inference} {Benchmark}: {Why} {Mobile} {AI} {Benchmarking} {Is} {Hard} and {What} to {Do} {About} {It}},
	shorttitle = {{MLPerf} {Mobile} {Inference} {Benchmark}},
	url = {http://arxiv.org/abs/2012.02328},
	abstract = {MLPerf Mobile is the ﬁrst industry-standard opensource mobile benchmark developed by industry members and academic researchers to allow performance/accuracy evaluation of mobile devices with different AI chips and software stacks. The benchmark draws from the expertise of leading mobile-SoC vendors, ML-framework providers, and model producers. In this paper, we motivate the drive to demystify mobile-AI performance and present MLPerf Mobile’s design considerations, architecture, and implementation. The benchmark comprises a suite of models that operate under standard data sets, quality metrics, and run rules. For the ﬁrst iteration, we developed an Android app to provide an “out-of-the-box” inference-performance benchmark for computer vision and natural-language processing on mobile devices. The benchmark also supports non-smartphone devices such as laptops and mobile PCs. As a whole, the MLPerf Mobile inference benchmark can serve as a framework for integrating future models, for customizing quality-target thresholds to evaluate system performance, for comparing software frameworks, and for assessing heterogeneous-hardware capabilities for machine learning, all fairly and faithfully with reproducible results.},
	language = {en},
	urldate = {2021-01-19},
	journal = {arXiv:2012.02328 [cs]},
	author = {Reddi, Vijay Janapa and Kanter, David and Mattson, Peter and Duke, Jared and Nguyen, Thai and Chukka, Ramesh and Shiring, Kenneth and Tan, Koan-Sin and Charlebois, Mark and Chou, William and El-Khamy, Mostafa and Hong, Jungwook and Buch, Michael and Trinh, Cindy and Atta-fosu, Thomas and Cakir, Fatih and Charkhabi, Masoud and Chen, Xiaodong and Chiang, Jimmy and Dexter, Dave and Heo, Woncheol and Schmuelling, Guenther and Shabani, Maryam and Zika, Dylan},
	month = dec,
	year = {2020},
	note = {arXiv: 2012.02328},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
}

@article{banbury_micronets_2020,
	title = {{MicroNets}: {Neural} {Network} {Architectures} for {Deploying} {TinyML} {Applications} on {Commodity} {Microcontrollers}},
	shorttitle = {{MicroNets}},
	url = {http://arxiv.org/abs/2010.11267},
	abstract = {Executing machine learning workloads locally on resource constrained microcontrollers (MCUs) promises to drastically expand the application space of IoT. However, so-called TinyML presents severe technical challenges, as deep neural network inference demands a large compute and memory budget. To address this challenge, neural architecture search (NAS) promises to help design accurate ML models that meet the tight MCU memory, latency and energy constraints. A key component of NAS algorithms is their latency/energy model, i.e., the mapping from a given neural network architecture to its inference latency/energy on an MCU. In this paper, we observe an intriguing property of NAS search spaces for MCU model design: on average, model latency varies linearly with model operation (op) count under a uniform prior over models in the search space. Exploiting this insight, we employ differentiable NAS (DNAS) to search for models with low memory usage and low op count, where op count is treated as a viable proxy to latency. Experimental results validate our methodology, yielding our MicroNet models, which we deploy on MCUs using Tensorﬂow Lite Micro, a standard open-source NN inference runtime widely used in the TinyML community. MicroNets demonstrate state-of-the-art results for all three TinyMLperf industry-standard benchmark tasks: visual wake words, audio keyword spotting, and anomaly detection.},
	language = {en},
	urldate = {2021-01-19},
	journal = {arXiv:2010.11267 [cs]},
	author = {Banbury, Colby and Zhou, Chuteng and Fedorov, Igor and Navarro, Ramon Matas and Thakker, Urmish and Gope, Dibakar and Reddi, Vijay Janapa and Mattina, Matthew and Whatmough, Paul N.},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.11267},
	keywords = {Computer Science - Machine Learning},
}

@article{papadimitriou_exceeding_2020,
	title = {Exceeding {Conservative} {Limits}: {A} {Consolidated} {Analysis} on {Modern} {Hardware} {Margins}},
	volume = {20},
	issn = {1530-4388, 1558-2574},
	shorttitle = {Exceeding {Conservative} {Limits}},
	url = {https://ieeexplore.ieee.org/document/9076808/},
	doi = {10.1109/TDMR.2020.2989813},
	abstract = {Modern large-scale computing systems (data centers, supercomputers, cloud and edge setups and high-end cyber-physical systems) employ heterogeneous architectures that consist of multicore CPUs, general-purpose many-core GPUs, and programmable FPGAs. The effective utilization of these architectures poses several challenges, among which a primary one is power consumption. Voltage reduction is one of the most efficient methods to reduce power consumption of a chip. With the galloping adoption of hardware accelerators (i.e., GPUs and FPGAs) in large datacenters and other large-scale computing infrastructures, a comprehensive evaluation of the safe voltage reduction levels for each different chip can be employed for efficient reduction of the total power. We present a survey of recent studies in voltage margins reduction at the system level for modern CPUs, GPUs and FPGAs. The pessimistic voltage guardbands inserted by the silicon vendors can be exploited in all devices for significant power savings. On average, voltage reduction can reach 12\% in multicore CPUs, 20\% in manycore GPUs and 39\% in FPGAs.},
	language = {en},
	number = {2},
	urldate = {2021-01-19},
	journal = {IEEE Transactions on Device and Materials Reliability},
	author = {Papadimitriou, George and Chatzidimitriou, Athanasios and Gizopoulos, Dimitris and Reddi, Vijay Janapa and Leng, Jingwen and Salami, Behzad and Unsal, Osman Sabri and Kestelman, Adrian Cristal},
	month = jun,
	year = {2020},
	pages = {341--350},
}

@article{azad_end--end_nodate,
	title = {An end-to-end {RISC}-{V} solution for {ML} on the edge using in-pipeline support},
	abstract = {Machine Learning (ML) is widely used today in many mobile applications. To preserve user privacy, there is a need to perform ML inference on the mobile devices. Given that ML inference is a computationally intensive task, the common technique used in mobile devices is ofﬂoading the task to a neural accelerator. However, the speed-up gained from ofﬂoading these tasks on the accelerators is limited by the overhead of frequent host-accelerator communication. In this paper, we propose a complete end-to-end solution that uses in-pipeline machine learning processing unit for accelerating ML workloads. First we introduce the software infrastructure we developed to support compilation and execution of machine learning models used in TensorFlow Lite framework. Then we discuss the microarchitecture we plan to implement for supporting the execution of our vectorized machine learning kernels.},
	language = {en},
	author = {Azad, Zahra and Louis, Marcia Sahaya and Delshadtehrani, Leila and Ducimo, Anthony and Gupta, Suyog and Warden, Pete and Reddi, Vijay Janapa and Joshi, Ajay},
	pages = {2},
}

@inproceedings{richins_missing_2020,
	address = {San Diego, CA, USA},
	title = {Missing the {Forest} for the {Trees}: {End}-to-{End} {AI} {Application} {Performance} in {Edge} {Data} {Centers}},
	isbn = {978-1-72816-149-5},
	shorttitle = {Missing the {Forest} for the {Trees}},
	url = {https://ieeexplore.ieee.org/document/9065599/},
	doi = {10.1109/HPCA47549.2020.00049},
	abstract = {Artiﬁcial intelligence and machine learning are experiencing widespread adoption in the industry, academia, and even public consciousness. This has been driven by the rapid advances in the applications and accuracy of AI through increasingly complex algorithms and models; this, in turn, has spurred research into developing specialized hardware AI accelerators. The rapid pace of the advances makes it easy to miss the forest for the trees: they are often developed and evaluated in a vacuum without considering the full application environment in which they must eventually operate.},
	language = {en},
	urldate = {2021-01-19},
	booktitle = {2020 {IEEE} {International} {Symposium} on {High} {Performance} {Computer} {Architecture} ({HPCA})},
	publisher = {IEEE},
	author = {Richins, Daniel and Doshi, Dharmisha and Blackmore, Matthew and Thulaseedharan Nair, Aswathy and Pathapati, Neha and Patel, Ankit and Daguman, Brainard and Dobrijalowski, Daniel and Illikkal, Ramesh and Long, Kevin and Zimmerman, David and Janapa Reddi, Vijay},
	month = feb,
	year = {2020},
	pages = {515--528},
}

@article{hill_accelerator_nodate,
	title = {Accelerator {Level} {Parallelism}},
	language = {en},
	author = {Hill, Mark D and Reddi, Vijay Janapa},
	pages = {6},
}

@inproceedings{hills_trig_2018,
	address = {San Francisco California},
	title = {{TRIG}: hardware accelerator for inference-based applications and experimental demonstration using carbon nanotube {FETs}},
	isbn = {978-1-4503-5700-5},
	shorttitle = {{TRIG}},
	url = {https://dl.acm.org/doi/10.1145/3195970.3196132},
	doi = {10.1145/3195970.3196132},
	abstract = {The energy efficiency demands of future abundant-data applications, e.g., those which use inference-based techniques to classify large amounts of data, exceed the capabilities of digital systems today. Field-effect transistors (FETs) built using nanotechnologies, such as carbon nanotubes (CNTs), can improve energy efficiency significantly. However, carbon nanotube FETs (CNFETs) are subject to process variations inherent to CNTs: variations in CNT type (semiconductor or metallic), CNT density, or CNT diameter, to name a few. These CNT variations can degrade CNFET benefits at advanced technology nodes. One path to overcome CNT variations is to co-optimize CNT processing and CNFET circuit design; however, the required CNT process advancements have not been achieved experimentally. We present a new design approach (TRIG, Technique for Reducing errors using Iterative Gray code) to overcome process variations in hardware accelerators targeting inference-based applications that use serial matrix operations (serial: accumulated over at least 2 clock cycles). We demonstrate that TRIG can retain the major energy efficiency benefits (quantified using Energy Delay Product or EDP) of CNFETs despite CNT variations that exist in today’s CNFET fabrication – without requiring further CNT processing improvements to overcome CNT variations. As a case study, we analyze the effectiveness of TRIG for a binary neural network hardware accelerator that classifies images. Despite CNT variations that exist today, TRIG can maintain 99\% (90\%) of projected EDP benefits of CNFET digital circuits for 90\% (99\%) image classification accuracy target. We also demonstrate experimentally fabricated CNFET circuits to compute scalar product (a common matrix operation, also called dot product), with and without TRIG: TRIG reduces the mean difference between the expected result (no errors) and the experimentally computed result by 30× in the presence of CNT variations, shown experimentally.},
	language = {en},
	urldate = {2021-01-14},
	booktitle = {Proceedings of the 55th {Annual} {Design} {Automation} {Conference}},
	publisher = {ACM},
	author = {Hills, Gage and Bankman, Daniel and Moons, Bert and Yang, Lita and Hillard, Jake and Kahng, Alex and Park, Rebecca and Verhelst, Marian and Murmann, Boris and Shulaker, Max M. and Wong, H.-S. Philip and Mitra, Subhasish},
	month = jun,
	year = {2018},
	pages = {1--10},
}

@article{srimani_monolithic_nodate,
	title = {Monolithic {Three}-{Dimensional} {Imaging} {System}: {Carbon} {Nanotube} {Computing} {Circuitry} {Integrated} {Directly} {Over} {Silicon} {Imager}},
	abstract = {Here we show a hardware prototype of a monolithic threedimensional (3D) imaging system that integrates computing layers directly in the back-end-of-line (BEOL) of a conventional silicon imager. Such systems can transform imager output from raw pixel data to highly processed information. To realize our imager, we fabricate 3 vertical circuit layers directly on top of each other: a bottom layer of silicon pixels followed by two layers of CMOS carbon nanotube FETs (CNFETs) (comprising 2,784 CNFETs) that perform in-situ edge detection in real-time, before storing data in memory. This approach promises to enable image classification systems with improved processing latencies.},
	language = {en},
	author = {Srimani, Tathagata and Hills, Gage and Lau, Christian and Shulaker, Max},
	pages = {2},
}

@article{kanhaiya_carbon_2019,
	title = {Carbon {Nanotube}-{Based} {CMOS} {SRAM}: 1 kbit {6T} {SRAM} {Arrays} and {10T} {SRAM} {Cells}},
	volume = {66},
	issn = {0018-9383, 1557-9646},
	shorttitle = {Carbon {Nanotube}-{Based} {CMOS} {SRAM}},
	url = {https://ieeexplore.ieee.org/document/8897710/},
	doi = {10.1109/TED.2019.2945533},
	abstract = {We experimentally demonstrate the ﬁrst static random-access memory (SRAM) arrays based on carbon nanotube (CNT) ﬁeld-effect transistors (CNFETs). We demonstrate 1 kbit (1024) 6 transistor (6T) SRAM arrays fabricated with complementary metal-oxide-semiconductor (CMOS) CNFETs (totaling 6144 p- and n-type CNFETs), with all 1024 cells functioning correctly without any per-unit customization. Moreover, we show the ﬁrst demonstration of CNFET CMOS 10T SRAM cells, capable of operating at highly scaled voltages down to 300 mV. We characterize the CNFET CMOS SRAM and demonstrate robust operation by writing and reading multiple patterns (to both the kbit arrays as well as the 10T SRAM cells), measuring SRAM variations in read, write, and hold margins and repeat cycling of cells. Moreover, due to the low-temperature back-end-of-line (BEOL)-compatible CNT-speciﬁc processing, CNFET SRAM enables new opportunities for digital systems, since: 1) CNFET SRAM can be fabricated directly on top of computing logic to realize three-dimensional integrated circuits; and 2) CNFET circuits can utilize metal routing both above and below the CNFET device layer (e.g., as in our demonstration which utilizes buried power rails, whereby the power rails are fabricated underneath the FETs while metal routing is fabricated above the FETs), providing opportunities for further SRAM density scaling.},
	language = {en},
	number = {12},
	urldate = {2021-01-14},
	journal = {IEEE Transactions on Electron Devices},
	author = {Kanhaiya, Pritpal S. and Lau, Christian and Hills, Gage and Bishop, Mindy D. and Shulaker, Max M.},
	month = dec,
	year = {2019},
	pages = {5375--5380},
}

@article{hills_modern_nodate,
	title = {Modern microprocessor built from complementary carbon nanotube transistors},
	language = {en},
	author = {Hills, Gage},
	pages = {21},
}

@inproceedings{hills_advances_2020,
	address = {Taipei Taiwan},
	title = {Advances in {Carbon} {Nanotube} {Technologies}: {From} {Transistors} to a {RISC}-{V} {Microprocessor}},
	isbn = {978-1-4503-7091-2},
	shorttitle = {Advances in {Carbon} {Nanotube} {Technologies}},
	url = {https://dl.acm.org/doi/10.1145/3372780.3378170},
	doi = {10.1145/3372780.3378170},
	abstract = {Carbon nanotube (CNT) field-effect transistors (CNFETs) promise to improve the energy efficiency of very-large-scale integrated (VLSI) systems. However, multiple challenges have prevented VLSI CNFET circuits from being realized, including inherent nanoscale material defects, robust processing for yielding complementary CNFETs (i.e., CNT CMOS: including both PMOS and NMOS CNFETs), and major CNT variations. Here, we summarize techniques that we have recently developed to overcome these outstanding challenges, enabling VLSI CNFET circuits to be experimentally realized today using standard VLSI processing and design flows. Leveraging these techniques, we demonstrate the most complex CNFET circuits and systems todate, including a three-dimensional (3D) imaging system comprising CNFETs fabricated directly on top of a silicon imager, CNT CMOS analog and mixed-signal circuits, 1 kilobit CNFET static random-access memory (SRAM) memory arrays, and a 16bit RISC-V microprocessor built entirely out of CNFETs.},
	language = {en},
	urldate = {2021-01-14},
	booktitle = {Proceedings of the 2020 {International} {Symposium} on {Physical} {Design}},
	publisher = {ACM},
	author = {Hills, Gage and Lau, Christian and Srimani, Tathagata and Bishop, Mindy D. and Kanhaiya, Pritpal and Ho, Rebecca and Amer, Aya and Shulaker, Max M.},
	month = mar,
	year = {2020},
	pages = {33--38},
}

@inproceedings{srimani_heterogeneous_2020,
	address = {Honolulu, HI, USA},
	title = {Heterogeneous {Integration} of {BEOL} {Logic} and {Memory} in a {Commercial} {Foundry}: {Multi}-{Tier} {Complementary} {Carbon} {Nanotube} {Logic} and {Resistive} {RAM} at a 130 nm node},
	isbn = {978-1-72816-460-1},
	shorttitle = {Heterogeneous {Integration} of {BEOL} {Logic} and {Memory} in a {Commercial} {Foundry}},
	url = {https://ieeexplore.ieee.org/document/9265083/},
	doi = {10.1109/VLSITechnology18217.2020.9265083},
	abstract = {The inevitable slowing of two-dimensional scaling is motivating efforts to continue scaling along a new physical axis: the 3rd dimension. Here we report back-end-of-line (BEOL) integration of multi-tier logic and memory established within a commercial foundry. This is enabled by a low-temperature BEOLcompatible complementary carbon nanotube (CNT) field-effect transistor (CNFET) logic technology, alongside a BEOLcompatible Resistive RAM (RRAM) technology. All vertical layers are fabricated sequentially over the same starting substrate, using conventional BEOL nano-scale inter-layer vias (ILVs) as vertical interconnects (e.g., monolithic 3D integration, rather than chip-stacking and bonding). In addition, we develop the entire VLSI design infrastructure required for a foundry technology offering, including an industry-practice monolithic 3D process design kit (PDK) as well as a complete monolithic 3D standard cell library. The initial foundry process integrates 4 device tiers (2 tiers of complementary CNFET logic and 2 tiers of RRAM memory) with 15 metal layers at a {\textasciitilde}130 nm technology node. We fabricate and experimentally validate the standard cell library across all monolithic 3D tiers, as well as a range of sub-systems including memories (BEOL SRAM, 1T1R memory arrays) as well as logic (including the compute core of a 16-bit microprocessor) –all of which is fabricated in the foundry within the BEOL interconnect stack. All fabrication is VLSI-compatible and leverages existing silicon CMOS infrastructure, and the entire design flow is compatible with existing commercial electronic design automation tools.},
	language = {en},
	urldate = {2021-01-14},
	booktitle = {2020 {IEEE} {Symposium} on {VLSI} {Technology}},
	publisher = {IEEE},
	author = {Srimani, T. and Hills, G. and Bishop, M. and Lau, C. and Kanhaiya, P. and Ho, R. and Amer, A. and Chao, M. and Yu, A. and Wright, A. and Ratkovich, A. and Aguilar, D. and Bramer, A. and Cecman, C. and Chov, A. and Clark, G. and Michaelson, G. and Johnson, M. and Kelley, K. and Manos, P. and Mi, K. and Suriono, U. and Vuntangboon, S. and Xue, H. and Humes, J. and Soares, S. and Jones, B. and Burack, S. and {Arvind} and Chandrakasan, A. and Ferguson, B. and Nelson, M. and Shulaker, M. M.},
	month = jun,
	year = {2020},
	pages = {1--2},
}

@inproceedings{tumeo_invited_2020,
	address = {San Francisco, CA, USA},
	title = {Invited: {Software} {Defined} {Accelerators} {From} {Learning} {Tools} {Environment}},
	isbn = {978-1-72811-085-1},
	shorttitle = {Invited},
	url = {https://ieeexplore.ieee.org/document/9218489/},
	doi = {10.1109/DAC18072.2020.9218489},
	abstract = {Next generation systems, such as edge devices, will need to provide efﬁcient processing of machine learning (ML) algorithms along several metrics, including energy, performance, area, and latency. However, the quickly evolving ﬁeld of ML makes it extremely difﬁcult to generate accelerators able to support a wide variety of algorithms. At the same time, designing accelerators in hardware description languages (HDLs) by hand is hard and time consuming, and does not allow quick exploration of the design space. In this paper we present the Software Deﬁned Accelerators From Learning Tools Environment (SODALITE), an automated open source high-level ML framework-to-verilog compiler targeting ML Application-Speciﬁc Integrated Circuits (ASICs) chiplets. The SODALITE approach will implement optimal designs by seamlessly combining custom components generated through high-level synthesis (HLS) with templated and fully tunable Intellectual Properties (IPs) and macros, integrated in an extendable resource library. Through a closed loop design space exploration engine, developers will be able to quickly explore their hardware designs along different dimensions.},
	language = {en},
	urldate = {2021-01-08},
	booktitle = {2020 57th {ACM}/{IEEE} {Design} {Automation} {Conference} ({DAC})},
	publisher = {IEEE},
	author = {Tumeo, Antonino and Minutoli, Marco and Castellana, Vito Giovanni and Manzano, Joseph and Amatya, Vinay and Brooks, David and Wei, Gu-Yeon},
	month = jul,
	year = {2020},
	pages = {1--6},
}

@article{wang_exploiting_2021,
	title = {Exploiting {Parallelism} {Opportunities} with {Deep} {Learning} {Frameworks}},
	volume = {18},
	issn = {1544-3566, 1544-3973},
	url = {https://dl.acm.org/doi/10.1145/3431388},
	doi = {10.1145/3431388},
	language = {en},
	number = {1},
	urldate = {2021-01-08},
	journal = {ACM Transactions on Architecture and Code Optimization},
	author = {Wang, Yu Emma and Wu, Carole-Jean and Wang, Xiaodong and Hazelwood, Kim and Brooks, David},
	month = jan,
	year = {2021},
	pages = {1--23},
}

@article{donato_memti_2019,
	title = {{MEMTI}: {Optimizing} {On}-{Chip} {Nonvolatile} {Storage} for {Visual} {Multitask} {Inference} at the {Edge}},
	volume = {39},
	issn = {0272-1732, 1937-4143},
	shorttitle = {{MEMTI}},
	url = {https://ieeexplore.ieee.org/document/8859219/},
	doi = {10.1109/MM.2019.2944782},
	abstract = {The combination of specialized hardware and embedded nonvolatile memories (eNVM) holds promise for energy-efﬁcient deep neural network (DNN) inference at the edge. However, integrating DNN hardware accelerators with eNVMs still presents several challenges. Multilevel programming is desirable for achieving maximal storage density on chip, but the stochastic nature of eNVM writes makes them prone to errors and further increases the write energy and latency. In this article, we present MEMTI, a memory architecture that leverages a multitask learning technique for maximal reuse of DNN parameters across multiple visual tasks. We show that by retraining and updating only 10\% of all DNN parameters, we can achieve efﬁcient model adaptation across a variety of visual inference tasks. The system performance is evaluated by integrating the memory with the open-source NVIDIA deep learning architecture.},
	language = {en},
	number = {6},
	urldate = {2021-01-08},
	journal = {IEEE Micro},
	author = {Donato, Marco and Pentecost, Lillian and Brooks, David and Wei, Gu-Yeon},
	month = nov,
	year = {2019},
	pages = {73--81},
}

@inproceedings{tambe_algorithm-hardware_2020,
	address = {San Francisco, CA, USA},
	title = {Algorithm-{Hardware} {Co}-{Design} of {Adaptive} {Floating}-{Point} {Encodings} for {Resilient} {Deep} {Learning} {Inference}},
	isbn = {978-1-72811-085-1},
	url = {https://ieeexplore.ieee.org/document/9218516/},
	doi = {10.1109/DAC18072.2020.9218516},
	abstract = {Conventional hardware-friendly quantization methods, such as �xed-point or integer, tend to perform poorly at very low precision as their shrunken dynamic ranges cannot adequately capture the wide data distributions commonly seen in sequence transduction models. We present an algorithm-hardware co-design centered around a novel �oating-point inspired number format, AdaptivFloat, that dynamically maximizes and optimally clips its available dynamic range, at a layer granularity, in order to create faithful encodings of neural network parameters. AdaptivFloat consistently produces higher inference accuracies compared to block �oating-point, uniform, IEEE-like �oat or posit encodings at low bit precision ( 8-bit) across a diverse set of state-of-the-art neural networks, exhibiting narrow to wide weight distribution. Notably, at 4-bit weight precision, only a 2.1 degradation in BLEU score is observed on the AdaptivFloat-quantized Transformer network compared to total accuracy loss when encoded in the above-mentioned prominent datatypes. Furthermore, experimental results on a deep neural network (DNN) processing element (PE), exploiting AdaptivFloat logic in its computational datapath, demonstrate per-operation energy and area that is 0.9⇥ and 1.14⇥, respectively, that of an equivalent bit width NVDLA-like integer-based PE.},
	language = {en},
	urldate = {2021-01-08},
	booktitle = {2020 57th {ACM}/{IEEE} {Design} {Automation} {Conference} ({DAC})},
	publisher = {IEEE},
	author = {Tambe, Thierry and Yang, En-Yu and Wan, Zishen and Deng, Yuntian and Janapa Reddi, Vijay and Rush, Alexander and Brooks, David and Wei, Gu-Yeon},
	month = jul,
	year = {2020},
	pages = {1--6},
}

@article{tambe_edgebert_2020,
	title = {{EdgeBERT}: {Optimizing} {On}-{Chip} {Inference} for {Multi}-{Task} {NLP}},
	shorttitle = {{EdgeBERT}},
	url = {http://arxiv.org/abs/2011.14203},
	abstract = {Transformer-based language models such as BERT provide signiﬁcant accuracy improvement to a multitude of natural language processing (NLP) tasks. However, their hefty computational and memory demands make them challenging to deploy to resource-constrained edge platforms with strict latency requirements. We present EdgeBERT, an in-depth and principled algorithm and hardware design methodology to achieve minimal latency and energy consumption on multi-task NLP inference. Compared to the ALBERT baseline, we achieve up to 2.4× and 13.4× inference latency and memory savings, respectively, with less than 1\%-pt drop in accuracy on several GLUE benchmarks by employing a calibrated combination of 1) entropy-based early stopping, 2) adaptive attention span, 3) movement and magnitude pruning, and 4) ﬂoating-point quantization.},
	language = {en},
	urldate = {2021-01-08},
	journal = {arXiv:2011.14203 [cs]},
	author = {Tambe, Thierry and Hooper, Coleman and Pentecost, Lillian and Yang, En-Yu and Donato, Marco and Sanh, Victor and Rush, Alexander M. and Brooks, David and Wei, Gu-Yeon},
	month = nov,
	year = {2020},
	note = {arXiv: 2011.14203},
	keywords = {Computer Science - Computation and Language, Computer Science - Hardware Architecture},
}

@inproceedings{athalye_notary_2019,
	address = {Huntsville Ontario Canada},
	title = {Notary: a device for secure transaction approval},
	isbn = {978-1-4503-6873-5},
	shorttitle = {Notary},
	url = {https://dl.acm.org/doi/10.1145/3341301.3359661},
	doi = {10.1145/3341301.3359661},
	abstract = {Notary is a new hardware and software architecture for running isolated approval agents in the form factor of a USB stick with a small display and buttons. Approval agents allow factoring out critical security decisions, such as getting the user’s approval to sign a Bitcoin transaction or to delete a backup, to a secure environment. The key challenge addressed by Notary is to securely switch between agents on the same device. Prior systems either avoid the problem by building single-function devices like a USB U2F key, or they provide weak isolation that is susceptible to kernel bugs, side channels, or Rowhammer-like attacks. Notary achieves strong isolation using reset-based switching, along with the use of physically separate systems-on-a-chip for agent code and for the kernel, and a machine-checked proof of both the hardware’s register-transfer-level design and software, showing that reset-based switching leaks no state. Notary also provides a trustworthy I/O path between the agent code and the user, which prevents an adversary from tampering with the user’s screen or buttons.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 27th {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Athalye, Anish and Belay, Adam and Kaashoek, M. Frans and Morris, Robert and Zeldovich, Nickolai},
	month = oct,
	year = {2019},
	pages = {97--113},
}

@inproceedings{lockerman_livia_2020,
	address = {Lausanne Switzerland},
	title = {Livia: {Data}-{Centric} {Computing} {Throughout} the {Memory} {Hierarchy}},
	isbn = {978-1-4503-7102-5},
	shorttitle = {Livia},
	url = {https://dl.acm.org/doi/10.1145/3373376.3378497},
	doi = {10.1145/3373376.3378497},
	abstract = {In order to scale, future systems will need to dramatically reduce data movement. Data movement is expensive in current designs because (i) traditional memory hierarchies force computation to happen unnecessarily far away from data and (ii) processing-in-memory approaches fail to exploit locality. We propose Memory Services, a flexible programming model that enables data-centric computing throughout the memory hierarchy. In Memory Services, applications express functionality as graphs of simple tasks, each task indicating the data it operates on. We design and evaluate Livia, a new system architecture for Memory Services that dynamically schedules tasks and data at the location in the memory hierarchy that minimizes overall data movement. Livia adds less than 3\% area overhead to a tiled multicore and accelerates challenging irregular workloads by 1.3× to 2.4× while reducing dynamic energy by 1.2× to 4.7×.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Lockerman, Elliot and Feldmann, Axel and Bakhshalipour, Mohammad and Stanescu, Alexandru and Gupta, Shashwat and Sanchez, Daniel and Beckmann, Nathan},
	month = mar,
	year = {2020},
	pages = {417--433},
}

@article{whatmough_chipkit_2020,
	title = {{CHIPKIT}: {An} {Agile}, {Reusable} {Open}-{Source} {Framework} for {Rapid} {Test} {Chip} {Development}},
	volume = {40},
	issn = {0272-1732, 1937-4143},
	shorttitle = {{CHIPKIT}},
	url = {https://ieeexplore.ieee.org/document/9096507/},
	doi = {10.1109/MM.2020.2995809},
	abstract = {The current trend for domain-speciﬁc architectures (DSAs) has led to renewed interest in research test chips to demonstrate new specialized hardware. Tape-outs also offer huge pedagogical value garnered from real hands-on exposure to the whole system stack. However, success with tape-outs requires hard-earned experience, and the design process is time consuming and fraught with challenges. Therefore, custom chips have remained the preserve of a small number of research groups, typically focused on circuit design research. This paper describes the CHIPKIT framework: a reusable SoC subsystem which provides basic IO, an on-chip programmable host, off-chip hosting, memory and peripherals. This subsystem can be readily extended with new IP blocks to generate custom test chips. Central to CHIPKIT, is an agile RTL development ﬂow, including a code generation tool called VGEN. Finally, we discuss best practices for full-chip validation across the entire design cycle.},
	language = {en},
	number = {4},
	urldate = {2020-12-25},
	journal = {IEEE Micro},
	author = {Whatmough, Paul N. and Donato, Marco and Ko, Glenn G. and Lee, Sae Kyu and Brooks, David and Wei, Gu-Yeon},
	month = jul,
	year = {2020},
	keywords = {Computer Science - Hardware Architecture},
	pages = {32--40},
}

@article{xu_automatic_nodate,
	title = {Automatic {Code} {Generation} for {Rocket} {Chip} {RoCC} {Accelerators}},
	abstract = {Heterogeneous SoCs that are coupled with accelerators are becoming prevalent for various deep learning applications thanks to their outstanding flexibility and performance. However, programming for these platforms remains hard due to their low-level programming interface and complex memory systems. Meanwhile, automatic code generation for tensor programs provides reasonable performance with great accessibility and flexibility. In this work, we bring these two topics together by proposing a flow of automatic code generation for heterogeneous SoCs. We present how to implement the proposed flow using TVM for RoCC. We also develop a performance evaluation platform to enable practical automatic code generation on embedded devices. Experiments using TVM for the Gemmini GEMM accelerator demonstrate that the generated code achieves a peak of 25.24 GIOPS and a best-case 3.6x speedup compared to the hand-tuned kernels from Gemmini developers.},
	language = {en},
	author = {Xu, Pengcheng and Liang, Yun},
	pages = {8},
}

@article{cavalcante_ara_2019,
	title = {Ara: {A} 1 {GHz}+ {Scalable} and {Energy}-{Efficient} {RISC}-{V} {Vector} {Processor} with {Multi}-{Precision} {Floating} {Point} {Support} in 22 nm {FD}-{SOI}},
	shorttitle = {Ara},
	url = {http://arxiv.org/abs/1906.00478},
	abstract = {In this paper, we present Ara, a 64-bit vector processor based on the version 0.5 draft of RISC-V’s vector extension, implemented in GLOBALFOUNDRIES 22FDX FD-SOI technology. Ara’s microarchitecture is scalable, as it is composed of a set of identical lanes, each containing part of the processor’s vector register ﬁle and functional units. It achieves up to 97\% FPU utilization when running a 256 × 256 double precision matrix multiplication on sixteen lanes. Ara runs at more than 1 GHz in the typical corner (TT/0.80 V/25 ◦C), achieving a performance up to 33 DP−GFLOPS. In terms of energy efﬁciency, Ara achieves up to 41 DP−GFLOPS/W under the same conditions, which is slightly superior to similar vector processors found in literature. An analysis on several vectorizable linear algebra computation kernels for a range of different matrix and vector sizes gives insight into performance limitations and bottlenecks for vector processors and outlines directions to maintain high energy efﬁciency even for small matrix sizes where the vector architecture achieves suboptimal utilization of the available FPUs.},
	language = {en},
	urldate = {2020-12-25},
	journal = {arXiv:1906.00478 [cs]},
	author = {Cavalcante, Matheus and Schuiki, Fabian and Zaruba, Florian and Schaffner, Michael and Benini, Luca},
	month = oct,
	year = {2019},
	note = {arXiv: 1906.00478},
	keywords = {Computer Science - Hardware Architecture},
}

@inproceedings{zhang_sdc-based_2013,
	address = {San Jose, CA},
	title = {{SDC}-based modulo scheduling for pipeline synthesis},
	isbn = {978-1-4799-1071-7},
	url = {http://ieeexplore.ieee.org/document/6691121/},
	doi = {10.1109/ICCAD.2013.6691121},
	abstract = {Modulo scheduling is a popular technique to enable pipelined execution of successive loop iterations for performance improvement. While a variety of modulo scheduling algorithms exist for software pipelining, they are not amenable to many complex design constraints and optimization goals that arise in the hardware synthesis context.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2013 {IEEE}/{ACM} {International} {Conference} on {Computer}-{Aided} {Design} ({ICCAD})},
	publisher = {IEEE},
	author = {Zhang, Zhiru and Liu, Bin},
	month = nov,
	year = {2013},
	pages = {211--218},
}

@inproceedings{balkind_openpiton_2016,
	address = {Atlanta Georgia USA},
	title = {{OpenPiton}: {An} {Open} {Source} {Manycore} {Research} {Framework}},
	isbn = {978-1-4503-4091-5},
	shorttitle = {{OpenPiton}},
	url = {https://dl.acm.org/doi/10.1145/2872362.2872414},
	doi = {10.1145/2872362.2872414},
	abstract = {Industry is building larger, more complex, manycore processors on the back of strong institutional knowledge, but academic projects face difﬁculties in replicating that scale. To alleviate these difﬁculties and to develop and share knowledge, the community needs open architecture frameworks for simulation, synthesis, and software exploration which support extensibility, scalability, and conﬁgurability, alongside an established base of veriﬁcation tools and supported software. In this paper we present OpenPiton, an open source framework for building scalable architecture research prototypes from 1 core to 500 million cores. OpenPiton is the world’s ﬁrst open source, general-purpose, multithreaded manycore processor and framework. OpenPiton leverages the industry hardened OpenSPARC T1 core with modiﬁcations and builds upon it with a scratch-built, scalable uncore creating a ﬂexible, modern manycore design. In addition, OpenPiton provides synthesis and backend scripts for ASIC and FPGA to enable other researchers to bring their designs to implementation. OpenPiton provides a complete veriﬁcation infrastructure of over 8000 tests, is supported by mature software tools, runs full-stack multiuser Debian Linux, and is written in industry standard Verilog. Multiple implementations of OpenPiton have been created including a taped-out 25-core implementation in IBM’s 32nm process and multiple Xilinx FPGA prototypes.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Twenty}-{First} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Balkind, Jonathan and McKeown, Michael and Fu, Yaosheng and Nguyen, Tri and Zhou, Yanqi and Lavrov, Alexey and Shahrad, Mohammad and Fuchs, Adi and Payne, Samuel and Liang, Xiaohua and Matl, Matthew and Wentzlaff, David},
	month = mar,
	year = {2016},
	pages = {217--232},
}

@inproceedings{moradi_skycore_2018,
	address = {New Delhi India},
	title = {{SkyCore}: {Moving} {Core} to the {Edge} for {Untethered} and {Reliable} {UAV}-based {LTE} {Networks}},
	isbn = {978-1-4503-5903-0},
	shorttitle = {{SkyCore}},
	url = {https://dl.acm.org/doi/10.1145/3241539.3241549},
	doi = {10.1145/3241539.3241549},
	abstract = {The advances in unmanned aerial vehicle (UAV) technology have empowered mobile operators to deploy LTE base stations (BSs) on UAVs, and provide on-demand, adaptive connectivity to hotspot venues as well as emergency scenarios. However, today’s evolved packet core (EPC) that orchestrates the LTE RAN faces fundamental limitations in catering to such a challenging, wireless and mobile UAV environment, particularly in the presence of multiple BSs (UAVs). In this work, we argue for and propose an alternate, radical edge EPC design, called SkyCore that pushes the EPC functionality to the extreme edge of the core network – collapses the EPC into a single, light-weight, self-contained entity that is co-located with each of the UAV BS. SkyCore incorporates elements that are designed to address the unique challenges facing such a distributed design in the UAV environment, namely the resource-constraints of UAV platforms, and the distributed management of pronounced UAV and UE mobility. We build and deploy a fully functional version of SkyCore on a two-UAV LTE network and showcase its (i) ability to interoperate with commercial LTE BSs as well as smartphones, (ii) support for both hotspot and standalone multi-UAV deployments, and (iii) superior control and data plane performance compared to other EPC variants in this environment.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 24th {Annual} {International} {Conference} on {Mobile} {Computing} and {Networking}},
	publisher = {ACM},
	author = {Moradi, Mehrdad and Sundaresan, Karthikeyan and Chai, Eugene and Rangarajan, Sampath and Mao, Z. Morley},
	month = oct,
	year = {2018},
	pages = {35--49},
}

@article{noauthor_zcu102_2019,
	title = {{ZCU102} {Evaluation} {Board} {User} {Guide}},
	language = {en},
	year = {2019},
	pages = {125},
}

@article{waterman_volume_nodate,
	title = {Volume {II}: {Privileged} {Architecture}},
	language = {en},
	author = {Waterman, Andrew and Asanovic, Krste and Division, CS},
	pages = {135},
}

@book{pierce_types_2002,
	address = {Cambridge, Mass},
	title = {Types and programming languages},
	isbn = {978-0-262-16209-8},
	language = {en},
	publisher = {MIT Press},
	author = {Pierce, Benjamin C.},
	year = {2002},
	keywords = {Programming languages (Electronic computers)},
}

@book{catlin_windows_2017,
	address = {Redmond},
	edition = {Seventh edition},
	series = {Windows internals ; {Part} 1},
	title = {Windows {Internals} {Seventh} {Edition} {Part} 1: {System} architecture, processes, threads, memory management, and more},
	isbn = {978-0-7356-8418-8},
	language = {en},
	publisher = {Microsoft},
	author = {Catlin, Brian and Hanrahan, Jamie E. and Russinovich, Mark E. and Solomon, David A. and Ionescu, Alex},
	year = {2017},
	note = {OCLC: on1012946187},
	keywords = {Microsoft Windows (Computer file), Operating systems (Computers), Windows (Computer programs)},
}

@article{de_bruijn_defining_1976,
	title = {Defining reals without the use of rationals},
	volume = {79},
	issn = {13857258},
	url = {https://linkinghub.elsevier.com/retrieve/pii/138572587690055X},
	doi = {10.1016/1385-7258(76)90055-X},
	language = {en},
	number = {2},
	urldate = {2020-12-25},
	journal = {Indagationes Mathematicae (Proceedings)},
	author = {de Bruijn, N.G},
	year = {1976},
	pages = {100--108},
}

@article{garofalo_pulp-nn_2020,
	title = {{PULP}-{NN}: {Accelerating} {Quantized} {Neural} {Networks} on {Parallel} {Ultra}-{Low}-{Power} {RISC}-{V} {Processors}},
	volume = {378},
	issn = {1364-503X, 1471-2962},
	shorttitle = {{PULP}-{NN}},
	url = {http://arxiv.org/abs/1908.11263},
	doi = {10.1098/rsta.2019.0155},
	abstract = {We present PULP-NN, an optimized computing library for a parallel ultra-low-power tightly coupled cluster of RISC-V processors. The key innovation in PULP-NN is a set of kernels for Quantized Neural Network (QNN) inference, targeting byte and sub-byte data types, down to INT-1, tuned for the recent trend toward aggressive quantization in deep neural network inference. The proposed library exploits both the digital signal processing (DSP) extensions available in the PULP RISCV processors and the cluster’s parallelism, achieving up to 15.5 MACs/cycle on INT-8 and improving performance by up to 63× with respect to a sequential implementation on a single RISC-V core implementing the baseline RV32IMC ISA. Using PULP-NN, a CIFAR-10 network on an octa-core cluster runs in 30× and 19.6× less clock cycles than the current state-of-the-art ARM CMSIS-NN library, running on STM32L4 and STM32H7 MCUs, respectively. The proposed library, when running on GAP-8 processor, outperforms by 36.8× and by 7.45× the execution on energy efﬁcient MCUs such as STM32L4 and high-end MCUs such as STM32H7 respectively, when operating at the maximum frequency. The energy efﬁciency on GAP-8 is 14.1× higher than STM32L4 and 39.5× higher than STM32H7, at the maximum efﬁciency operating point.},
	language = {en},
	number = {2164},
	urldate = {2020-12-25},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Garofalo, Angelo and Rusci, Manuele and Conti, Francesco and Rossi, Davide and Benini, Luca},
	month = feb,
	year = {2020},
	note = {arXiv: 1908.11263},
	keywords = {Computer Science - Neural and Evolutionary Computing},
	pages = {20190155},
}

@article{lattner_mlir_2020,
	title = {{MLIR}: {A} {Compiler} {Infrastructure} for the {End} of {Moore}'s {Law}},
	shorttitle = {{MLIR}},
	url = {http://arxiv.org/abs/2002.11054},
	abstract = {This work presents MLIR, a novel approach to building reusable and extensible compiler infrastructure. MLIR aims to address software fragmentation, improve compilation for heterogeneous hardware, signiﬁcantly reduce the cost of building domain speciﬁc compilers, and aid in connecting existing compilers together.},
	language = {en},
	urldate = {2020-12-25},
	journal = {arXiv:2002.11054 [cs]},
	author = {Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.11054},
	keywords = {Computer Science - Machine Learning, Computer Science - Programming Languages},
}

@article{bondhugula_high_2020,
	title = {High {Performance} {Code} {Generation} in {MLIR}: {An} {Early} {Case} {Study} with {GEMM}},
	shorttitle = {High {Performance} {Code} {Generation} in {MLIR}},
	url = {http://arxiv.org/abs/2003.00532},
	abstract = {This article is primarily meant to present an early case study on using MLIR [1], a new compiler intermediate representation infrastructure, for high-performance code generation. Aspects of MLIR covered in particular include memrefs, the afﬁne dialect, and polyhedral utilities and pass infrastructure surrounding those. This article is also aimed at showing the role compiler infrastructure could play in generating code that is competitive with highly tuned manually developed libraries, albeit in a more modular, reusable, and automatable way.},
	language = {en},
	urldate = {2020-12-25},
	journal = {arXiv:2003.00532 [cs]},
	author = {Bondhugula, Uday},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.00532},
	keywords = {Computer Science - Performance},
}

@article{jeffrey_unlocking_2016,
	title = {Unlocking {Ordered} {Parallelism} with the {Swarm} {Architecture}},
	volume = {36},
	issn = {0272-1732, 1937-4143},
	url = {https://ieeexplore.ieee.org/document/7436649/},
	doi = {10.1109/MM.2016.12},
	language = {en},
	number = {3},
	urldate = {2020-12-25},
	journal = {IEEE Micro},
	author = {Jeffrey, Mark C. and Subramanian, Suvinay and Yan, Cong and Emer, Joel and Sanchez, Daniel},
	month = may,
	year = {2016},
	pages = {105--117},
}

@inproceedings{subramanian_fractal_2017,
	address = {Toronto ON Canada},
	title = {Fractal: {An} {Execution} {Model} for {Fine}-{Grain} {Nested} {Speculative} {Parallelism}},
	isbn = {978-1-4503-4892-8},
	shorttitle = {Fractal},
	url = {https://dl.acm.org/doi/10.1145/3079856.3080218},
	doi = {10.1145/3079856.3080218},
	abstract = {Most systems that support speculative parallelization, like hardware transactional memory (HTM), do not support nested parallelism. This sacriﬁces substantial parallelism and precludes composing parallel algorithms. And the few HTMs that do support nested parallelism focus on parallelizing at the coarsest (shallowest) levels, incurring large overheads that squander most of their potential.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 44th {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {ACM},
	author = {Subramanian, Suvinay and Jeffrey, Mark C. and Abeydeera, Maleen and Lee, Hyun Ryong and Ying, Victor A. and Emer, Joel and Sanchez, Daniel},
	month = jun,
	year = {2017},
	pages = {587--599},
}

@inproceedings{colin_reconfigurable_2018,
	address = {Williamsburg VA USA},
	title = {A {Reconfigurable} {Energy} {Storage} {Architecture} for {Energy}-harvesting {Devices}},
	isbn = {978-1-4503-4911-6},
	url = {https://dl.acm.org/doi/10.1145/3173162.3173210},
	doi = {10.1145/3173162.3173210},
	abstract = {Battery-free, energy-harvesting devices operate using energy collected exclusively from their environment. Energyharvesting devices allow maintenance-free deployment in extreme environments, but requires a power system to provide the right amount of energy when an application needs it. Existing systems must provision energy capacity statically based on an application’s peak demand which compromises efficiency and responsiveness when not at peak demand. This work presents Capybara: a co-designed hardware/software power system with dynamically reconfigurable energy storage capacity that meets varied application energy demand. The Capybara software interface allows programmers to specify the energy mode of an application task. Capybara’s runtime system reconfigures Capybara’s hardware energy capacity to match application demand. Capybara also allows a programmer to write reactive application tasks that pre-allocate a burst of energy that it can spend in response to an asynchronous (e.g., external) event. We instantiated Capybara’s hardware design in two EH devices and implemented three reactive sensing applications using its software interface. Capybara improves event detection accuracy by 2x-4x over statically-provisioned energy capacity, maintains response latency within 1.5x of a continuously-powered baseline, and enables reactive applications that are intractable with existing power systems.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Twenty}-{Third} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Colin, Alexei and Ruppel, Emily and Lucia, Brandon},
	month = mar,
	year = {2018},
	pages = {767--781},
}

@inproceedings{jeffrey_harmonizing_2018,
	address = {Fukuoka},
	title = {Harmonizing {Speculative} and {Non}-{Speculative} {Execution} in {Architectures} for {Ordered} {Parallelism}},
	isbn = {978-1-5386-6240-3},
	url = {https://ieeexplore.ieee.org/document/8574543/},
	doi = {10.1109/MICRO.2018.00026},
	abstract = {Multicore systems should support both speculative and non-speculative parallelism. Speculative parallelism is easy to use and is crucial to scale many challenging applications, while non-speculative parallelism is more efﬁcient and allows parallel irrevocable actions (e.g., parallel I/O). Unfortunately, prior techniques are far from this goal. Hardware transactional memory (HTM) systems support speculative (transactional) and non-speculative (non-transactional) work, but lack coordination mechanisms between the two, and are limited to unordered parallelism. Prior work has extended HTMs to avoid the limitations of speculative execution, e.g., through escape actions and open-nested transactions. But these mechanisms are incompatible with systems that exploit ordered parallelism, which parallelize a broader range of applications and are easier to use.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2018 51st {Annual} {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture} ({MICRO})},
	publisher = {IEEE},
	author = {Jeffrey, Mark C. and Ying, Victor A. and Subramanian, Suvinay and Lee, Hyun Ryong and Emer, Joel and Sanchez, Daniel},
	month = oct,
	year = {2018},
	pages = {217--230},
}

@inproceedings{abeydeera_chronos_2020,
	address = {Lausanne Switzerland},
	title = {Chronos: {Efficient} {Speculative} {Parallelism} for {Accelerators}},
	isbn = {978-1-4503-7102-5},
	shorttitle = {Chronos},
	url = {https://dl.acm.org/doi/10.1145/3373376.3378454},
	doi = {10.1145/3373376.3378454},
	abstract = {We present Chronos, a framework to build accelerators for applications with speculative parallelism. These applications consist of atomic tasks, sometimes with order constraints, and need speculative execution to extract parallelism. Prior work extended conventional multicores to support speculative parallelism, but these prior architectures are a poor match for accelerators because they rely on cache coherence and add non-trivial hardware to detect conflicts among tasks. Chronos instead relies on a novel execution model, Spatially Located Ordered Tasks (SLOT), that uses order as the only synchronization mechanism and limits task accesses to a single read-write object. This simplification avoids the need for cache coherence and makes speculative execution cheap and distributed. Chronos abstracts the complexities of speculative parallelism, making accelerator design easy.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Abeydeera, Maleen and Sanchez, Daniel},
	month = mar,
	year = {2020},
	pages = {1247--1262},
}

@inproceedings{tsai_safecracker_2020,
	address = {Lausanne Switzerland},
	title = {Safecracker: {Leaking} {Secrets} through {Compressed} {Caches}},
	isbn = {978-1-4503-7102-5},
	shorttitle = {Safecracker},
	url = {https://dl.acm.org/doi/10.1145/3373376.3378453},
	doi = {10.1145/3373376.3378453},
	abstract = {The hardware security crisis brought on by recent speculative execution attacks has shown that it is crucial to adopt a security-conscious approach to architecture research, analyzing the security of promising architectural techniques before they are deployed in hardware. This paper offers the first security analysis of cache compression, one such promising technique that is likely to appear in future processors. We find that cache compression is insecure because the compressibility of a cache line reveals information about its contents. Compressed caches introduce a new side channel that is especially insidious, as simply storing data transmits information about it.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Tsai, Po-An and Sanchez, Andres and Fletcher, Christopher W. and Sanchez, Daniel},
	month = mar,
	year = {2020},
	pages = {1125--1140},
}

@article{noauthor_intel_2019,
	title = {Intel® 64 and {IA}-32 {Architectures} {Software} {Developer}’s {Manual}, {Combined} {Volumes}: 1, {2A}, {2B}, {2C}, {2D}, {3A}, {3B}, {3C}, {3D} and 4},
	language = {en},
	year = {2019},
	pages = {4922},
}

@inproceedings{hidayetoglu_memxct_2019,
	address = {Denver Colorado},
	title = {{MemXCT}: memory-centric {X}-ray {CT} reconstruction with massive parallelization},
	isbn = {978-1-4503-6229-0},
	shorttitle = {{MemXCT}},
	url = {https://dl.acm.org/doi/10.1145/3295500.3356220},
	doi = {10.1145/3295500.3356220},
	abstract = {X-ray computed tomography (XCT) is used regularly at synchrotron light sources to study the internal morphology of materials at high resolution. However, experimental constraints, such as radiation sensitivity, can result in noisy or undersampled measurements. Further, depending on the resolution, sample size and data acquisition rates, the resulting noisy dataset can be terabyte-scale. Advanced iterative reconstruction techniques can produce high-quality images from noisy measurements, but their computational requirements have made their use exception rather than the rule. We propose here a novel memory-centric approach that avoids redundant computations at the expense of additional memory complexity. We develop a system, MemXCT, that uses an optimized SpMV implementation with two-level pseudo-Hilbert ordering and multi-stage input buffering. We evaluate MemXCT on various supercomputer architectures incolving KNL and GPU. MemXCT can reconstruct a large (11K×11K) mouse brain tomogram in {\textasciitilde}10 seconds using 4096 KNL nodes (256K cores), the largest iterative reconstruction achieved in near-real time.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {International} {Conference} for {High} {Performance} {Computing}, {Networking}, {Storage} and {Analysis}},
	publisher = {ACM},
	author = {Hidayetoğlu, Mert and Biçer, Tekin and de Gonzalo, Simon Garcia and Ren, Bin and Gürsoy, Doğa and Kettimuthu, Rajkumar and Foster, Ian T. and Hwu, Wen-mei W.},
	month = nov,
	year = {2019},
	pages = {1--56},
}

@inproceedings{bocco_smurf_2019,
	address = {Singapore Singapore},
	title = {{SMURF}: {Scalar} {Multiple}-precision {Unum} {Risc}-{V} {Floating}-point {Accelerator} for {Scientific} {Computing}},
	isbn = {978-1-4503-7139-1},
	shorttitle = {{SMURF}},
	url = {https://dl.acm.org/doi/10.1145/3316279.3316280},
	doi = {10.1145/3316279.3316280},
	abstract = {This paper proposes an innovative Floating Point (FP) architecture for Variable Precision (VP) computation suitable for high precision FP computing, based on a refined version of the UNUM type I format. This architecture supports VP FP intervals where each interval endpoint can have up to 512 bits of mantissa. The proposed hardware architecture is pipelined and has an internal word-size of 64 bits. Computations on longer mantissas are performed iteratively on the existing hardware. The prototype is integrated in a RISC-V environment, it is exposed to the user through an instruction set extension. The paper we provide an example of software usage. The system has been prototyped on a FPGA (FieldProgrammable Gate Array) platform and also synthesized for a 28nm FDSOI process technology. The respective working frequency of FPGA and ASIC implementations are 50MHz and 600MHz. The estimated chip area is 1.5������������2 and the estimated power consumption is 95mW. The flops performance of this architecture remains within the range of a regular fixed-precision IEEE FPU while enabling arbitrary precision computation at reasonable cost.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Conference} for {Next} {Generation} {Arithmetic} 2019},
	publisher = {ACM},
	author = {Bocco, Andrea and Durand, Yves and De Dinechin, Florent},
	month = mar,
	year = {2019},
	pages = {1--8},
}

@article{jouppi_domain-specific_2020,
	title = {A domain-specific supercomputer for training deep neural networks},
	volume = {63},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3360307},
	doi = {10.1145/3360307},
	language = {en},
	number = {7},
	urldate = {2020-12-25},
	journal = {Communications of the ACM},
	author = {Jouppi, Norman P. and Yoon, Doe Hyun and Kurian, George and Li, Sheng and Patil, Nishant and Laudon, James and Young, Cliff and Patterson, David},
	month = jun,
	year = {2020},
	pages = {67--78},
}

@inproceedings{mansi_sim_2020,
	address = {Lausanne Switzerland},
	title = {∅sim: {Preparing} {System} {Software} for a {World} with {Terabyte}-scale {Memories}},
	isbn = {978-1-4503-7102-5},
	shorttitle = {∅sim},
	url = {https://dl.acm.org/doi/10.1145/3373376.3378451},
	doi = {10.1145/3373376.3378451},
	abstract = {Recent advances in memory technologies mean that commodity machines may soon have terabytes of memory; however, such machines remain expensive and uncommon today. Hence, few programmers and researchers can debug and prototype fixes for scalability problems or explore new system behavior caused by terabyte-scale memories. To enable rapid, early prototyping and exploration of system software for such machines, we built and open-sourced the 0sim simulator. 0sim uses virtualization to simulate the execution of huge workloads on modest machines. Our key observation is that many workloads follow the same control flow regardless of their input. We call such workloads dataoblivious. 0sim harnesses data-obliviousness to make huge simulations feasible and fast via memory compression.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Mansi, Mark and Swift, Michael M.},
	month = mar,
	year = {2020},
	pages = {267--282},
}

@inproceedings{achermann_mitosis_2020,
	address = {Lausanne Switzerland},
	title = {Mitosis: {Transparently} {Self}-{Replicating} {Page}-{Tables} for {Large}-{Memory} {Machines}},
	isbn = {978-1-4503-7102-5},
	shorttitle = {Mitosis},
	url = {https://dl.acm.org/doi/10.1145/3373376.3378468},
	doi = {10.1145/3373376.3378468},
	abstract = {Multi-socket machines with 1-100 TBs of physical memory are becoming prevalent. Applications running on such multisocket machines suffer non-uniform bandwidth and latency when accessing physical memory. Decades of research have focused on data allocation and placement policies in NUMA settings, but there have been no studies on the question of how to place page-tables amongst sockets. We make the case for explicit page-table allocation policies and show that pagetable placement is becoming crucial to overall performance. We propose Mitosis to mitigate NUMA effects on pagetable walks by transparently replicating and migrating pagetables across sockets without application changes. This reduces the frequency of accesses to remote NUMA nodes when performing page-table walks. Mitosis uses two components: (i) a mechanism to efficiently enable and (ii) policies to effectively control – page-table replication and migration. We implement Mitosis in Linux and evaluate its benefits on real hardware. Mitosis improves performance for large-scale multi-socket workloads by up to 1.34x by replicating pagetables across sockets. Moreover, it improves performance by up to 3.24x in cases when the OS migrates a process across sockets by enabling cross-socket page-table migration.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Achermann, Reto and Panwar, Ashish and Bhattacharjee, Abhishek and Roscoe, Timothy and Gandhi, Jayneel},
	month = mar,
	year = {2020},
	pages = {283--300},
}

@inproceedings{luo_prague_2020,
	address = {Lausanne Switzerland},
	title = {Prague: {High}-{Performance} {Heterogeneity}-{Aware} {Asynchronous} {Decentralized} {Training}},
	isbn = {978-1-4503-7102-5},
	shorttitle = {Prague},
	url = {https://dl.acm.org/doi/10.1145/3373376.3378499},
	doi = {10.1145/3373376.3378499},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Luo, Qinyi and He, Jiaao and Zhuo, Youwei and Qian, Xuehai},
	month = mar,
	year = {2020},
	pages = {401--416},
}

@inproceedings{bindschaedler_hailstorm_2020,
	address = {Lausanne Switzerland},
	title = {Hailstorm: {Disaggregated} {Compute} and {Storage} for {Distributed} {LSM}-based {Databases}},
	isbn = {978-1-4503-7102-5},
	shorttitle = {Hailstorm},
	url = {https://dl.acm.org/doi/10.1145/3373376.3378504},
	doi = {10.1145/3373376.3378504},
	abstract = {Distributed LSM-based databases face throughput and latency issues due to load imbalance across instances and interference from background tasks such as flushing, compaction, and data migration. Hailstorm addresses these problems by deploying the database storage engines over a distributed filesystem that disaggregates storage from processing, enabling storage pooling and compaction offloading. Hailstorm pools storage devices within a rack, allowing each storage engine to fully utilize the aggregate rack storage capacity and bandwidth. Storage pooling successfully handles load imbalance without the need for resharding. Hailstorm offloads compaction tasks to remote nodes, distributing their impact, and improving overall system throughput and response time. We show that Hailstorm achieves load balance in many MongoDB deployments with skewed workloads, improving the average throughput by 60\%, while decreasing tail latency by as much as 5×. In workloads with range queries, Hailstorm provides up to 22× throughput improvements. Hailstorm also enables cost savings of 47-56\% in OLTP workloads.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Bindschaedler, Laurent and Goel, Ashvin and Zwaenepoel, Willy},
	month = mar,
	year = {2020},
	pages = {301--316},
}

@inproceedings{min_cryocache_2020,
	address = {Lausanne Switzerland},
	title = {{CryoCache}: {A} {Fast}, {Large}, and {Cost}-{Effective} {Cache} {Architecture} for {Cryogenic} {Computing}},
	isbn = {978-1-4503-7102-5},
	shorttitle = {{CryoCache}},
	url = {https://dl.acm.org/doi/10.1145/3373376.3378513},
	doi = {10.1145/3373376.3378513},
	abstract = {Cryogenic computing, which is to run a computer at extremely low temperatures (e.g., 77K), is a highly promising solution to dramatically improve the computer’s performance and power efficiency thanks to the significantly reduced leakage power and wire resistance. However, computer architects are facing fundamental challenges in developing and deploying cryogenic-optimal architectural units due to the lack of understanding about its cost-effectiveness and feasibility (e.g., device and cooling costs vs. speedup, energy and area saving) and thus how to architect such cryogenic-optimal units.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Min, Dongmoon and Byun, Ilkwon and Lee, Gyu-Hyeon and Na, Seongmin and Kim, Jangwoo},
	month = mar,
	year = {2020},
	pages = {449--464},
}

@inproceedings{tzimpragos_computational_2020,
	address = {Lausanne Switzerland},
	title = {A {Computational} {Temporal} {Logic} for {Superconducting} {Accelerators}},
	isbn = {978-1-4503-7102-5},
	url = {https://dl.acm.org/doi/10.1145/3373376.3378517},
	doi = {10.1145/3373376.3378517},
	abstract = {Superconducting logic offers the potential to perform computation at tremendous speeds and energy savings. However, a “semantic gap” lies between the level-driven logic that traditional hardware designs accept as a foundation and the pulse-driven logic that is naturally supported by the most compelling superconducting technologies. A pulse, unlike a level signal, will fire through a channel for only an instant. Arranging the network of superconducting components so that input pulses always arrive simultaneously to “logic gates” to maintain the illusion of Boolean-only evaluation is a significant engineering hurdle. In this paper, we explore computing in a new and more native tongue for superconducting logic: time of arrival. Building on recent work in delay-based computations we show that superconducting logic can naturally compute directly over temporal relationships between pulse arrivals, that the computational relationships between those pulse arrivals can be formalized through a functional extension to a temporal predicate logic used in the verification community, and that the resulting architectures can operate asynchronously and describe real and useful computations. We verify our hypothesis through a combination of detailed analog circuit models, a formal analysis of our abstractions, and an evaluation in the context of several superconducting accelerators.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Tzimpragos, Georgios and Vasudevan, Dilip and Tsiskaridze, Nestan and Michelogiannakis, George and Madhavan, Advait and Volk, Jennifer and Shalf, John and Sherwood, Timothy},
	month = mar,
	year = {2020},
	pages = {435--448},
}

@inproceedings{schuiki_llhd_2020,
	address = {London UK},
	title = {{LLHD}: a multi-level intermediate representation for hardware description languages},
	isbn = {978-1-4503-7613-6},
	shorttitle = {{LLHD}},
	url = {https://dl.acm.org/doi/10.1145/3385412.3386024},
	doi = {10.1145/3385412.3386024},
	abstract = {Modern Hardware Description Languages (HDLs) such as SystemVerilog or VHDL are, due to their sheer complexity, insufficient to transport designs through modern circuit design flows. Instead, each design automation tool lowers HDLs to its own Intermediate Representation (IR). These tools are monolithic and mostly proprietary, disagree in their implementation of HDLs, and while many redundant IRs exists, no IR today can be used through the entire circuit design flow. To solve this problem, we propose the LLHD multilevel IR. LLHD is designed as simple, unambiguous reference description of a digital circuit, yet fully captures existing HDLs. We show this with our reference compiler on designs as complex as full CPU cores. LLHD comes with lowering passes to a hardware-near structural IR, which readily integrates with existing tools. LLHD establishes the basis for innovation in HDLs and tools without redundant compilers or disjoint IRs. For instance, we implement an LLHD simulator that runs up to 2.4× faster than commercial simulators but produces equivalent, cycle-accurate results. An initial vertically-integrated research prototype is capable of representing all levels of the IR, implements lowering from the behavioural to the structural IR, and covers a sufficient subset of SystemVerilog to support a full CPU design.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 41st {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Schuiki, Fabian and Kurth, Andreas and Grosser, Tobias and Benini, Luca},
	month = jun,
	year = {2020},
	pages = {258--271},
}

@inproceedings{hodzic_ipv4ipv6_2012,
	address = {Sarajevo, Bosnia and Herzegovina},
	title = {{IPv4}/{IPv6} transition using {DNS64}/{NAT64}: {Deployment} issues},
	isbn = {978-1-4673-4876-8 978-1-4673-4875-1 978-1-4673-4874-4},
	shorttitle = {{IPv4}/{IPv6} transition using {DNS64}/{NAT64}},
	url = {http://ieeexplore.ieee.org/document/6412066/},
	doi = {10.1109/BIHTEL.2012.6412066},
	abstract = {IPv4 address space is almost exhausted. Usage of IPv6 address by client end hosts is limited due to small percentage of domain names that have IPv6 address. This paper presents practical testing in ISP that gives its users IPv6 addresses and provides them transparent access to both IPv4 and IPv6 Internet locations. DNS64/NAT64 translation mechanism is used for this purpose. Tests measure resource requirements on ISP side and effects on client experience. Results show that additional DNS64 processing causes no visible impact on DNS server CPU load. There is requirement for NAT64 device at ISP on path between IPv6 users and IPv4 Internet. Test results show that memory requirements for this device are small and achievable with standard hardware devices used by ISPs. Measured increase in RTT from IPv6 clients to IPv4 Internet is less than 2\%. Conclusion is that DNS64/NAT64 translation system is viable solution for ISP.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2012 {IX} {International} {Symposium} on {Telecommunications} ({BIHTEL})},
	publisher = {IEEE},
	author = {Hodzic, Enis and Mrdovic, Sasa},
	month = oct,
	year = {2012},
	pages = {1--6},
}

@article{liu_sf-sketch_2020,
	title = {{SF}-{Sketch}: {A} {Two}-{Stage} {Sketch} for {Data} {Streams}},
	volume = {31},
	issn = {1045-9219, 1558-2183, 2161-9883},
	shorttitle = {{SF}-{Sketch}},
	url = {https://ieeexplore.ieee.org/document/9068427/},
	doi = {10.1109/TPDS.2020.2987609},
	abstract = {Sketches are probabilistic data structures designed for recording frequencies of items in a multi-set. They are widely used in various ﬁelds, especially for gathering Internet statistics from distributed data streams in network measurements. In a distributed streaming application with high data rates, a sketch in each monitoring node “ﬁlls up” very quickly and then its content is transferred to a remote collector responsible for answering queries. Thus, the size of the contents transferred must be kept as small as possible while meeting the desired accuracy requirement. To obtain signiﬁcantly higher accuracy while keeping the same update and query speed as the best prior sketches, in this article, we propose a new sketch – the Slim-Fat (SF) sketch. The key idea behind the SF-sketch is to maintain two separate sketches: a larger sketch, the Fat-subsketch, and a smaller sketch, the Slim-subsketch. The Fat-subsketch is used for updating and periodically producing the Slim-subsketch, which is then transferred to the remote collector for answering queries quickly and accurately. We also present the error bound as well as an accurate model of the correct rate of the SF-sketch, and verify their correctness through experiments. We implemented and extensively evaluated the SF-sketch along with several prior sketches. Our results show that when the size of our Slim-subsketch and of the widely used Count-Min (CM) sketch are kept the same, our SF-sketch outperforms the CM-sketch by up to 33.1 times in terms of accuracy (when the ratio of the sizes of the Fat-subsketch and the Slim-subsketch is 16:1). We have made all source codes publicly available at Github [“Source code of SF sketches,” [Online]. Available: https://github.com/paper2017/SF-sketch].},
	language = {en},
	number = {10},
	urldate = {2020-12-25},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Liu, Lingtong and Shen, Yulong and Yan, Yibo and Yang, Tong and Shahzad, Muhammad and Cui, Bin and Xie, Gaogang},
	month = oct,
	year = {2020},
	pages = {2263--2276},
}

@article{bhattacharjee_architectural_2017,
	title = {Architectural and {Operating} {System} {Support} for {Virtual} {Memory}},
	volume = {12},
	issn = {1935-3235, 1935-3243},
	url = {http://www.morganclaypool.com/doi/10.2200/S00795ED1V01Y201708CAC042},
	doi = {10.2200/S00795ED1V01Y201708CAC042},
	language = {en},
	number = {5},
	urldate = {2020-12-25},
	journal = {Synthesis Lectures on Computer Architecture},
	author = {Bhattacharjee, Abhishek and Lustig, Daniel},
	month = sep,
	year = {2017},
	pages = {1--175},
}

@article{gupta_astriflash_nodate,
	title = {{AstriFlash} {An} {Online} {Flash}-{Based} {Memory} {Hierarchy}},
	abstract = {Modern datacenters typically host datasets in DRAM to offer large-scale online services with tight tail latency requirements. Unfortunately, DRAM is expensive and increasingly difﬁcult to scale, forcing datacenter operators to consider denser storage technologies. While modern ﬂash-based storage exhibits raw access latency in the µs scale – well within the tail latency requirements of many online services – traditional OS abstractions used to separately manage memory and storage incur high overheads and preclude integration of ﬂash in systems for online services. We introduce AstriFlash, a hardware/software co-design to integrate ﬂash into the online memory hierarchy with a hybrid DRAM cache. Our evaluation with cycle-accurate full-system simulation shows that AstriFlash achieves 95\% of DRAM-only system’s throughput while maintaining 99-percentile tail latency with only 8\% degradation, and reducing the overall memory cost by 20x.},
	language = {en},
	author = {Gupta, Siddharth and Oh, Yunho and Yan, Lei and Sutherland, Mark and Bhattacharjee, Abhishek and Falsaﬁ, Babak and Hsu, Peter},
	pages = {14},
}

@inproceedings{boroumand_conda_2019,
	address = {Phoenix Arizona},
	title = {{CoNDA}: efficient cache coherence support for near-data accelerators},
	isbn = {978-1-4503-6669-4},
	shorttitle = {{CoNDA}},
	url = {https://dl.acm.org/doi/10.1145/3307650.3322266},
	doi = {10.1145/3307650.3322266},
	abstract = {Specialized on-chip accelerators are widely used to improve the energy efficiency of computing systems. Recent advances in memory technology have enabled near-data accelerators (NDAs), which reside off-chip close to main memory and can yield further benefits than on-chip accelerators. However, enforcing coherence with the rest of the system, which is already a major challenge for accelerators, becomes more difficult for NDAs. This is because (1) the cost of communication between NDAs and CPUs is high, and (2) NDA applications generate a lot of off-chip data movement. As a result, as we show in this work, existing coherence mechanisms eliminate most of the benefits of NDAs. We extensively analyze these mechanisms, and observe that (1) the majority of off-chip coherence traffic is unnecessary, and (2) much of the off-chip traffic can be eliminated if a coherence mechanism has insight into the memory accesses performed by the NDA.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 46th {International} {Symposium} on {Computer} {Architecture}},
	publisher = {ACM},
	author = {Boroumand, Amirali and Ghose, Saugata and Patel, Minesh and Hassan, Hasan and Lucia, Brandon and Ausavarungnirun, Rachata and Hsieh, Kevin and Hajinazar, Nastaran and Malladi, Krishna T. and Zheng, Hongzhong and Mutlu, Onur},
	month = jun,
	year = {2019},
	pages = {629--642},
}

@article{guo_analysis_nodate,
	title = {Analysis and {Optimization} of the {Implicit} {Broadcasts} in {FPGA} {HLS} to {Improve} {Maximum} {Frequency}},
	abstract = {Designs generated by high-level synthesis (HLS) tools typically achieve a lower frequency compared to manual RTL designs. In this work, we study the timing issues in a diverse set of realistic and complex FPGA HLS designs. (1) We observe that in almost all cases the frequency degradation is caused by the broadcast structures generated by the HLS compiler. (2) We classify three major types of broadcasts in HLS-generated designs, including high-fanout data signals, pipeline flow control signals and synchronization signals for concurrent modules. (3) We reveal a number of limitations of the current HLS tools that result in those broadcast-related timing issues. (4) We propose a set of effective yet easy-to-implement approaches, including broadcast-aware scheduling, synchronization pruning, and skid-buffer-based flow control. Our experimental results show that our methods can improve the maximum frequency of a set of nine representative HLS benchmarks by 53\% on average. In some cases, the frequency gain is more than 100 MHz.},
	language = {en},
	author = {Guo, Licheng and Lau, Jason and Chi, Yuze and Wang, Jie and Yu, Cody Hao and Chen, Zhe and Zhang, Zhiru and Cong, Jason},
	pages = {6},
}

@article{das_energy-efficient_2019,
	title = {An {Energy}-{Efficient} {Integrated} {Programmable} {Array} {Accelerator} and {Compilation} {Flow} for {Near}-{Sensor} {Ultralow} {Power} {Processing}},
	volume = {38},
	issn = {0278-0070, 1937-4151},
	url = {https://ieeexplore.ieee.org/document/8355958/},
	doi = {10.1109/TCAD.2018.2834397},
	abstract = {In this paper we give a fresh look to Coarse Grained Reconﬁgurable Arrays (CGRAs) as ultra-low power accelerators for near-sensor processing. We present a general-purpose Integrated Programmable-Array accelerator (IPA) exploiting a novel architecture, execution model, and compilation ﬂow for application mapping that can handle kernels containing complex control ﬂow, without the signiﬁcant energy overhead incurred by state of the art predication approaches. To optimize the performance and energy efﬁciency, we explore the IPA architecture with special focus on shared memory access, with the help of the ﬂexible compilation ﬂow presented in this paper. We achieve a maximum energy gain of 2×, and performance gain of 1.33× and 1.8× compared with state of the art partial and full predication techniques, respectively. The proposed accelerator achieves an average energy efﬁciency of 1617 MOPS/mW operating at 100MHz, 0.6V in 28nm UTBB FD-SOI technology, over a wide range of near-sensor processing kernels, leading to an improvement up to 18×, with an average of 9.23× (as well as a speed-up up to 20.3×, with an average of 9.7×) compared to a core specialized for ultra-low power near-sensor processing.},
	language = {en},
	number = {6},
	urldate = {2020-12-25},
	journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {Das, Satyajit and Martin, Kevin J. M. and Rossi, Davide and Coussy, Philippe and Benini, Luca},
	month = jun,
	year = {2019},
	pages = {1095--1108},
}

@article{noauthor_arm_nodate,
	title = {Arm {Architecture} {Reference} {Manual} {Armv8}, for {Armv8}-{A} architecture profile},
	language = {en},
	pages = {8248},
}

@article{genc_gemmini_2019,
	title = {Gemmini: {An} {Agile} {Systolic} {Array} {Generator} {Enabling} {Systematic} {Evaluations} of {Deep}-{Learning} {Architectures}},
	shorttitle = {Gemmini},
	url = {http://arxiv.org/abs/1911.09925},
	abstract = {Advances in deep learning and neural networks have resulted in rapid development of hardware accelerators that support them. A large majority of ASIC accelerators, however, target a single hardware design point to accelerate the main computational kernels of deep neural networks such as convolutions or matrix multiplication. On the other hand, the spectrum of use-cases for neural network accelerators, ranging from edge devices to cloud, presents a prime opportunity for agile hardware design and generator methodologies. We present Gemmini1 - an open source and agile systolic array generator enabling systematic evaluations of deep-learning architectures. Gemmini generates a custom ASIC accelerator for matrix multiplication based on a systolic array architecture, complete with additional functions for neural network inference. Gemmini runs with the RISC-V ISA, and is integrated with the Rocket Chip System-on-Chip generator ecosystem, including Rocket in-order cores and BOOM out-of-order cores. Through an elaborate design space exploration case study, this work demonstrates the selection processes of various parameters for the use-case of inference on edge devices. Selected design points achieve two to three orders of magnitude speedup in deep neural network inference compared to the baseline execution on a host processor. Gemmini-generated accelerators were used in the fabrication of test systems-on-chip in TSMC 16nm and Intel 22FFL process technologies.},
	language = {en},
	urldate = {2020-12-25},
	journal = {arXiv:1911.09925 [cs]},
	author = {Genc, Hasan and Haj-Ali, Ameer and Iyer, Vighnesh and Amid, Alon and Mao, Howard and Wright, John and Schmidt, Colin and Zhao, Jerry and Ou, Albert and Banister, Max and Shao, Yakun Sophia and Nikolic, Borivoje and Stoica, Ion and Asanovic, Krste},
	month = dec,
	year = {2019},
	note = {arXiv: 1911.09925},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Hardware Architecture, Computer Science - Machine Learning, Computer Science - Performance},
}

@article{rau_iterative_nodate,
	title = {Iterative {Modulo} {Scheduling}},
	language = {en},
	author = {Rau, B Ramakrishna},
	pages = {68},
}

@article{noauthor_arm_2012,
	title = {{ARM} {System} {Memory} {Management} {Unit} {Architecture} {Specification} {SMMU} architecture version 2.0},
	language = {en},
	year = {2012},
	pages = {372},
}

@inproceedings{ying_t4_2020,
	address = {Valencia, Spain},
	title = {T4: {Compiling} {Sequential} {Code} for {Effective} {Speculative} {Parallelization} in {Hardware}},
	isbn = {978-1-72814-661-4},
	shorttitle = {T4},
	url = {https://ieeexplore.ieee.org/document/9138940/},
	doi = {10.1109/ISCA45697.2020.00024},
	abstract = {Multicores are now ubiquitous, but programmers still write sequential code. Speculative parallelization is an enticing approach to parallelize code while retaining the ease of sequential programming, making parallelism pervasive. However, prior speculative parallelizing compilers and architectures achieved limited speedups due to high costs of recovering from misspeculation and hardware scalability bottlenecks.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2020 {ACM}/{IEEE} 47th {Annual} {International} {Symposium} on {Computer} {Architecture} ({ISCA})},
	publisher = {IEEE},
	author = {Ying, Victor A. and Jeffrey, Mark C. and Sanchez, Daniel},
	month = may,
	year = {2020},
	pages = {159--172},
}

@inproceedings{karakostas_redundant_2015,
	address = {Portland Oregon},
	title = {Redundant memory mappings for fast access to large memories},
	isbn = {978-1-4503-3402-0},
	url = {https://dl.acm.org/doi/10.1145/2749469.2749471},
	doi = {10.1145/2749469.2749471},
	abstract = {Page-based virtual memory improves programmer productivity, security, and memory utilization, but incurs performance overheads due to costly page table walks after TLB misses. This overhead can reach 50\% for modern workloads that access increasingly vast memory with stagnating TLB sizes. To reduce the overhead of virtual memory, this paper proposes Redundant Memory Mappings (RMM), which leverage ranges of pages and provides an efﬁcient, alternative representation of many virtual-to-physical mappings. We deﬁne a range be a subset of process’s pages that are virtually and physically contiguous. RMM translates each range with a single range table entry, enabling a modest number of entries to translate most of the process’s address space. RMM operates in parallel with standard paging and uses a software range table and hardware range TLB with arbitrarily large reach. We modify the operating system to automatically detect ranges and to increase their likelihood with eager page allocation. RMM is thus transparent to applications. We prototype RMM software in Linux and emulate the hardware. RMM performs substantially better than paging alone and huge pages, and improves a wider variety of workloads than direct segments (one range per program), reducing the overhead of virtual memory to less than 1\% on average.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 42nd {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {ACM},
	author = {Karakostas, Vasileios and Gandhi, Jayneel and Ayar, Furkan and Cristal, Adrián and Hill, Mark D. and McKinley, Kathryn S. and Nemirovsky, Mario and Swift, Michael M. and Ünsal, Osman},
	month = jun,
	year = {2015},
	pages = {66--78},
}

@inproceedings{jeffrey_scalable_2015,
	address = {Waikiki Hawaii},
	title = {A scalable architecture for ordered parallelism},
	isbn = {978-1-4503-4034-2},
	url = {https://dl.acm.org/doi/10.1145/2830772.2830777},
	doi = {10.1145/2830772.2830777},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 48th {International} {Symposium} on {Microarchitecture}},
	publisher = {ACM},
	author = {Jeffrey, Mark C. and Subramanian, Suvinay and Yan, Cong and Emer, Joel and Sanchez, Daniel},
	month = dec,
	year = {2015},
	pages = {228--241},
}

@article{raiciu_how_nodate,
	title = {How {Hard} {Can} {It} {Be}? {Designing} and {Implementing} a {Deployable} {Multipath} {TCP}},
	abstract = {Networks have become multipath: mobile devices have multiple radio interfaces, datacenters have redundant paths and multihoming is the norm for big server farms. Meanwhile, TCP is still only single-path. Is it possible to extend TCP to enable it to support multiple paths for current applications on today’s Internet? The answer is positive. We carefully review the constraints—partly due to various types of middleboxes—that inﬂuenced the design of Multipath TCP and show how we handled them to achieve its deployability goals. We report our experience in implementing Multipath TCP in the Linux kernel and we evaluate its performance. Our measurements focus on the algorithms needed to efﬁciently use paths with different characteristics, notably send and receive buffer tuning and segment reordering. We also compare the performance of our implementation with regular TCP on web servers. Finally, we discuss the lessons learned from designing MPTCP.},
	language = {en},
	author = {Raiciu, Costin and Paasch, Christoph and Barre, Sebastien and Ford, Alan and Honda, Michio and Duchene, Fabien and Bonaventure, Olivier and Handley, Mark},
	pages = {14},
}

@inproceedings{murray_naiad_2013,
	address = {Farminton, Pennsylvania},
	title = {Naiad: a timely dataflow system},
	isbn = {978-1-4503-2388-8},
	shorttitle = {Naiad},
	url = {http://dl.acm.org/citation.cfm?doid=2517349.2522738},
	doi = {10.1145/2517349.2522738},
	abstract = {Naiad is a distributed system for executing data parallel, cyclic dataﬂow programs. It offers the high throughput of batch processors, the low latency of stream processors, and the ability to perform iterative and incremental computations. Although existing systems offer some of these features, applications that require all three have relied on multiple platforms, at the expense of efﬁciency, maintainability, and simplicity. Naiad resolves the complexities of combining these features in one framework. A new computational model, timely dataﬂow, underlies Naiad and captures opportunities for parallelism across a wide class of algorithms. This model enriches dataﬂow computation with timestamps that represent logical points in the computation and provide the basis for an efﬁcient, lightweight coordination mechanism.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Twenty}-{Fourth} {ACM} {Symposium} on {Operating} {Systems} {Principles} - {SOSP} '13},
	publisher = {ACM Press},
	author = {Murray, Derek G. and McSherry, Frank and Isaacs, Rebecca and Isard, Michael and Barham, Paul and Abadi, Martín},
	year = {2013},
	pages = {439--455},
}

@article{xu_dijkstra_nodate,
	title = {Dijkstra: {The} {Structure} of the "{THE}" {Multiprogramming} {System}},
	language = {en},
	author = {Xu, Pengcheng},
	pages = {2},
}

@article{xu_exokernel_nodate,
	title = {Exokernel: {An} {Operating} {System} {Architecture} for {Application}-{Level} {Resource} {Management}},
	language = {en},
	author = {Xu, Pengcheng},
	pages = {2},
}

@article{xu_multics_nodate,
	title = {The {Multics} {Virtual} {Memory}: {Concepts} and {Design}},
	language = {en},
	author = {Xu, Pengcheng},
	pages = {1},
}

@article{shan_legoos_nodate,
	title = {{LegoOS}: {A} {Disseminated}, {Distributed} {OS} for {Hardware} {Resource} {Disaggregation}},
	abstract = {The monolithic server model where a server is the unit of deployment, operation, and failure is meeting its limits in the face of several recent hardware and application trends. To improve resource utilization, elasticity, heterogeneity, and failure handling in datacenters, we believe that datacenters should break monolithic servers into disaggregated, network-attached hardware components. Despite the promising beneﬁts of hardware resource disaggregation, no existing OSes or software systems can properly manage it.},
	language = {en},
	author = {Shan, Yizhou and Huang, Yutong and Chen, Yilun and Zhang, Yiying},
	pages = {20},
}

@article{li_fpga-zcu_nodate,
	title = {{FPGA}-{ZCU} {Quick} {Start} {Tutorial}},
	language = {en},
	author = {Li, Tuo and Parameswaran, Sri},
	pages = {7},
}

@article{cheng_scc_nodate,
	title = {{SCC} {Reproducibility} {Challenge} at {SC19}: {Modeling} {Mars} with {Normal} {Modes} on {Intel} {Cascade} {Lake} - {Peking} {University}},
	abstract = {Shi et al. [1] proposed a highly parallel polynomial ﬁltering eigensolver for the computation of planetary normal modes. As a challenge at the Student Cluster Competition in The International Conference for High Performance Computing, Networking, Storage and Analysis (SC19), we reproduce the computational efﬁciency of the polynomial ﬁltering eigensolver on our Intel Xeon machine. We present the weak scalability, scaling of runtime with model size (in a ﬁxed interval) and the strong scalability results in this report.},
	language = {en},
	author = {Cheng, Yihua and Fan, Zejia and Mai, Jing and Wu, Yifan and Xu, Pengcheng and Yan, Yuxuan and Fu, Zhenxin and Liang, Yun},
	pages = {4},
}

@article{waterman_volume_nodate-1,
	title = {Volume {I}: {Unprivileged} {ISA}},
	language = {en},
	author = {Waterman, Andrew and Asanovic, Krste and Division, CS},
	pages = {238},
}

@article{cheng_critique_nodate,
	title = {Critique of “{Computing} {Planetary} {Interior} {Normal} {Modes} with a {Highly} {Parallel} {Polynomial} {Filtering} {Eigensolver}” by {SCC} {Team} from {Peking} {University}},
	abstract = {Shi et al. [1] proposed a highly parallel polynomial ﬁltering eigensolver for the computation of planetary normal modes. As a challenge at the Student Cluster Competition in The International Conference for High Performance Computing, Networking, Storage and Analysis (SC19), we reproduce the computational efﬁciency of the polynomial ﬁltering eigensolver on our Intel Xeon machine. We present the weak scalability, scaling of runtime with model size (in a ﬁxed interval) and the strong scalability results in this report.},
	language = {en},
	author = {Cheng, Yihua and Fan, Zejia and Mai, Jing and Wu, Yifan and Xu, Pengcheng and Yan, Yuxuan and Fu, Zhenxin and Liang, Yun},
	pages = {4},
}

@article{cong_efcient_nodate,
	title = {An {Efﬁcient} and {Versatile} {Scheduling} {Algorithm} {Based} {On} {SDC} {Formulation}},
	abstract = {Scheduling plays a central role in the behavioral synthesis process, which automatically compiles high-level speciﬁcations into optimized hardware implementations. However, most of the existing behavior-level scheduling heuristics either have a limited efﬁciency in a speciﬁc class of applications or lack general support of various design constraints.},
	language = {en},
	author = {Cong, Jason and Zhang, Zhiru},
	pages = {6},
}

@article{ye_handshake-based_2018,
	title = {Handshake-based {HLS} in {CIRCT}},
	language = {en},
	author = {Ye, Hanchen},
	year = {2018},
	pages = {58},
}

@article{cox_xv6_nodate,
	title = {xv6: a simple, {Unix}-like teaching operating system},
	author = {Cox, Russ and Kaashoek, Frans and Morris, Robert},
	pages = {104},
}

@article{tiziano_de_matteis_fblas_nodate,
	title = {{FBLAS}: {Streaming} {Linear} {Algebra} {Kernels} on {FPGA}},
	author = {Tiziano De Matteis and Johannes de Fine Licht and Hoefler, Torsten},
}

@article{johannes_de_fine_licht_hlslib_nodate,
	title = {hlslib: {Software} {Engineering} for {Hardware} {Design}},
	abstract = {High-level synthesis (HLS) tools have brought FPGA
development into the mainstream, by allowing programmers
to design architectures using familiar languages such as C,
C++, and OpenCL. While the move to these languages has
brought significant benefits, many aspects of traditional software
engineering are still unsupported, or not exploited by developers
in practice. Furthermore, designing reconfigurable architectures
requires support for hardware constructs, such as FIFOs and
shift registers, that are not native to CPU-oriented languages.
To address this gap, we have developed hlslib, a collection
of software tools, plug-in hardware modules, and code samples,
designed to enhance the productivity of HLS developers. The goal
of hlslib is two-fold: first, create a community-driven arena
of bleeding edge development, which can move quicker, and
provides more powerful abstractions than what is provided by
vendors; and second, collect a wide range of example codes, both
minimal proofs of concept, and larger, real-world applications,
that can be reused directly or inspire other work. hlslib is
offered as an open source library, containing CMake files, C++
headers, convenience scripts, and examples codes, and is receptive
to any contribution that can benefit HLS developers, through
general functionality or examples.},
	author = {Johannes de Fine Licht and Hoefler, Torsten},
}

@article{noauthor_7nm_nodate,
	title = {A 7nm {4GHz} {Arm}®-core-based {CoWoS}® {Chiplet} {Design} for {High} {Performance} {Computing}},
	abstract = {A dual-chiplet Chip-on-Wafer-on-Substrate (CoWoS®) was
implemented in 7nm 15M process. Each SoC chiplet has four
Arm® Cortex®-A72 processors operating at 4GHz. The on-die
interconnect mesh bus operates above 4GHz at 2mm distance.
The inter-chiplet connection features a scalable, 0.56pJ/bit power
efficiency, 1.6Tb/s/mm2 bandwidth density, and 0.3V Lowvoltage-
In-Package-INterCONnect (LIPINCONTM) interface
achieving 8Gb/s/pin and 320GB/s bandwidth. Silicon test-chip
measurements validate the processor, on-die interconnects and
inter-chiplet interface performance. The built-in eye-scan feature
shows the inter-chiplet connection achieves 244mV eye-height
and 69\% UI eye-width.},
}

@article{de_sensi_-depth_2020,
	title = {An {In}-{Depth} {Analysis} of the {Slingshot} {Interconnect}},
	url = {http://arxiv.org/abs/2008.08886},
	abstract = {The interconnect is one of the most critical components in large scale computing systems, and its impact on the performance of applications is going to increase with the system size. In this paper, we will describe SLINGSHOT, an interconnection network for large scale computing systems. SLINGSHOT is based on high-radix switches, which allow building exascale and hyperscale datacenters networks with at most three switch-to-switch hops. Moreover, SLINGSHOT provides efﬁcient adaptive routing and congestion control algorithms, and highly tunable trafﬁc classes. SLINGSHOT uses an optimized Ethernet protocol, which allows it to be interoperable with standard Ethernet devices while providing high performance to HPC applications. We analyze the extent to which SLINGSHOT provides these features, evaluating it on microbenchmarks and on several applications from the datacenter and AI worlds, as well as on HPC applications. We ﬁnd that applications running on SLINGSHOT are less affected by congestion compared to previous generation networks.},
	language = {en},
	urldate = {2020-12-25},
	journal = {arXiv:2008.08886 [cs]},
	author = {De Sensi, Daniele and Di Girolamo, Salvatore and McMahon, Kim H. and Roweth, Duncan and Hoefler, Torsten},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.08886},
	keywords = {C.2.1, C.2.2, C.2.4, C.5.1, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Networking and Internet Architecture, Computer Science - Performance},
}

@article{besta_high-performance_2020,
	title = {High-{Performance} {Routing} with {Multipathing} and {Path} {Diversity} in {Ethernet} and {HPC} {Networks}},
	url = {http://arxiv.org/abs/2007.03776},
	abstract = {The recent line of research into topology design focuses on lowering network diameter. Many low-diameter topologies such as Slim Fly or Jellyﬁsh that substantially reduce cost, power consumption, and latency have been proposed. A key challenge in realizing the beneﬁts of these topologies is routing. On one hand, these networks provide shorter path lengths than established topologies such as Clos or torus, leading to performance improvements. On the other hand, the number of shortest paths between each pair of endpoints is much smaller than in Clos, but there is a large number of non-minimal paths between router pairs. This hampers or even makes it impossible to use established multipath routing schemes such as ECMP. In this work, to facilitate high-performance routing in modern networks, we analyze existing routing protocols and architectures, focusing on how well they exploit the diversity of minimal and non-minimal paths. We ﬁrst develop a taxonomy of different forms of support for multipathing and overall path diversity. Then, we analyze how existing routing schemes support this diversity. Among others, we consider multipathing with both shortest and non-shortest paths, support for disjoint paths, or enabling adaptivity. To address the ongoing convergence of HPC and “Big Data” domains, we consider routing protocols developed for both traditional HPC systems and supercomputers, and for data centers and general clusters. Thus, we cover architectures and protocols based on Ethernet, InﬁniBand, and other HPC networks such as Myrinet. Our review will foster developing future high-performance multipathing routing protocols in supercomputers and data centers.},
	language = {en},
	urldate = {2020-12-25},
	journal = {arXiv:2007.03776 [cs]},
	author = {Besta, Maciej and Domke, Jens and Schneider, Marcel and Konieczny, Marek and Di Girolamo, Salvatore and Schneider, Timo and Singla, Ankit and Hoefler, Torsten},
	month = oct,
	year = {2020},
	note = {arXiv: 2007.03776},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Networking and Internet Architecture, Computer Science - Performance},
}

@article{zaruba_snitch_2020,
	title = {Snitch: {A} tiny {Pseudo} {Dual}-{Issue} {Processor} for {Area} and {Energy} {Efficient} {Execution} of {Floating}-{Point} {Intensive} {Workloads}},
	issn = {0018-9340, 1557-9956, 2326-3814},
	shorttitle = {Snitch},
	url = {http://arxiv.org/abs/2002.10143},
	doi = {10.1109/TC.2020.3027900},
	abstract = {Data-parallel applications, such as data analytics, machine learning, and scientific computing, are placing an ever-growing demand on floating-point operations per second on emerging systems. With increasing integration density, the quest for energy efficiency becomes the number one design concern. While dedicated accelerators provide high energy efficiency, they are over-specialized and hard to adjust to algorithmic changes. We propose an architectural concept that tackles the issues of achieving extreme energy efficiency while still maintaining high flexibility as a general-purpose compute engine. The key idea is to pair a tiny 10kGE control core, called Snitch, with a double-precision FPU to adjust the compute to control ratio. While traditionally minimizing non-FPU area and achieving high floating-point utilization has been a trade-off, with Snitch, we achieve them both, by enhancing the ISA with two minimally intrusive extensions: stream semantic registers (SSR) and a floating-point repetition instruction (FREP). SSRs allow the core to implicitly encode load/store instructions as register reads/writes, eliding many explicit memory instructions. The FREP extension decouples the floating-point and integer pipeline by sequencing instructions from a micro-loop buffer. These ISA extensions significantly reduce the pressure on the core and free it up for other tasks, making Snitch and FPU effectively dual-issue at a minimal incremental cost of 3.2\%. The two low overhead ISA extensions make Snitch more flexible than a contemporary vector processor lane, achieving a \$2{\textbackslash}times\$ energy-efficiency improvement. We have evaluated the proposed core and ISA extensions on an octa-core cluster in 22nm technology. We achieve more than \$5{\textbackslash}times\$ multi-core speed-up and a \$3.5{\textbackslash}times\$ gain in energy efficiency on several parallel microkernels.},
	language = {en},
	urldate = {2020-12-25},
	journal = {IEEE Transactions on Computers},
	author = {Zaruba, Florian and Schuiki, Fabian and Hoefler, Torsten and Benini, Luca},
	year = {2020},
	note = {arXiv: 2002.10143},
	keywords = {Computer Science - Hardware Architecture},
	pages = {1--1},
}

@article{licht_flexible_2020,
	title = {Flexible {Communication} {Avoiding} {Matrix} {Multiplication} on {FPGA} with {High}-{Level} {Synthesis}},
	url = {http://arxiv.org/abs/1912.06526},
	doi = {10.1145/3373087.3375296},
	abstract = {Data movement is the dominating factor affecting performance and energy in modern computing systems. Consequently, many algorithms have been developed to minimize the number of I/O operations for common computing patterns. Matrix multiplication is no exception, and lower bounds have been proven and implemented both for shared and distributed memory systems. Reconfigurable hardware platforms are a lucrative target for I/O minimizing algorithms, as they offer full control of memory accesses to the programmer. While bounds developed in the context of fixed architectures still apply to these platforms, the spatially distributed nature of their computational and memory resources requires a decentralized approach to optimize algorithms for maximum hardware utilization. We present a model to optimize matrix multiplication for FPGA platforms, simultaneously targeting maximum performance and minimum off-chip data movement, within constraints set by the hardware. We map the model to a concrete architecture using a high-level synthesis tool, maintaining a high level of abstraction, allowing us to support arbitrary data types, and enables maintainability and portability across FPGA devices. Kernels generated from our architecture are shown to offer competitive performance in practice, scaling with both compute and memory resources. We offer our design as an open source project1 to encourage the open development of linear algebra and I/O minimizing algorithms on reconfigurable hardware platforms.},
	language = {en},
	urldate = {2020-12-25},
	journal = {Proceedings of the 2020 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
	author = {Licht, Johannes de Fine and Kwasniewski, Grzegorz and Hoefler, Torsten},
	month = feb,
	year = {2020},
	note = {arXiv: 1912.06526},
	keywords = {Computer Science - Computational Complexity, Computer Science - Distributed, Parallel, and Cluster Computing},
	pages = {244--254},
}

@article{hoefler_spin_2017,
	title = {{sPIN}: {High}-performance streaming {Processing} in the {Network}},
	shorttitle = {{sPIN}},
	url = {http://arxiv.org/abs/1709.05483},
	abstract = {Optimizing communication performance is imperative for largescale computing because communication overheads limit the strong scalability of parallel applications. Today’s network cards contain rather powerful processors optimized for data movement. However, these devices are limited to fixed functions, such as remote direct memory access. We develop sPIN, a portable programming model to offload simple packet processing functions to the network card. To demonstrate the potential of the model, we design a cycle-accurate simulation environment by combining the network simulator LogGOPSim and the CPU simulator gem5. We implement offloaded message matching, datatype processing, and collective communications and demonstrate transparent full-application speedups. Furthermore, we show how sPIN can be used to accelerate redundant in-memory filesystems and several other use cases. Our work investigates a portable packet-processing network acceleration model similar to compute acceleration with CUDA or OpenCL. We show how such network acceleration enables an eco-system that can significantly speed up applications and system services.},
	language = {en},
	urldate = {2020-12-25},
	journal = {arXiv:1709.05483 [cs]},
	author = {Hoefler, Torsten and Di Girolamo, Salvatore and Taranov, Konstantin and Grant, Ryan E. and Brightwell, Ron},
	month = oct,
	year = {2017},
	note = {arXiv: 1709.05483},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
}

@article{taranov_srdma_nodate,
	title = {{sRDMA} — {Efﬁcient} {NIC}-based {Authentication} and {Encryption} for {Remote} {Direct} {Memory} {Access}},
	abstract = {State-of-the-art remote direct memory access (RDMA) technologies have shown to be vulnerable against attacks by innetwork adversaries, as they provide only a weak form of protection by including access tokens in each message. A network eavesdropper can easily obtain sensitive information and modify bypassing packets, affecting not only secrecy but also integrity. Tampering with packets can have drastic consequences. For example, when memory pages with code are changed remotely, altering packet contents enables remote code injection. We propose sRDMA, a protocol that provides efﬁcient authentication and encryption for RDMA to prevent information leakage and message tampering. sRDMA uses symmetric cryptography and employs network interface cards to perform cryptographic operations. Additionally, we provide an implementation for sRDMA using programmable network adapters.},
	language = {en},
	author = {Taranov, Konstantin and Rothenberger, Benjamin and Perrig, Adrian and Hoeﬂer, Torsten},
	pages = {15},
}

@article{schuiki_stream_2020,
	title = {Stream {Semantic} {Registers}: {A} {Lightweight} {RISC}-{V} {ISA} {Extension} {Achieving} {Full} {Compute} {Utilization} in {Single}-{Issue} {Cores}},
	issn = {0018-9340, 1557-9956, 2326-3814},
	shorttitle = {Stream {Semantic} {Registers}},
	url = {https://ieeexplore.ieee.org/document/9068465/},
	doi = {10.1109/TC.2020.2987314},
	abstract = {Single-issue processor cores are very energy efﬁcient but suffer from the von Neumann bottleneck, in that they must explicitly fetch and issue the loads/storse necessary to feed their ALU/FPU. Each instruction spent on moving data is a cycle not spent on computation, limiting ALU/FPU utilization to 33\% on reductions. We propose "Stream Semantic Registers" to boost utilization and increase energy efﬁciency. SSR is a lightweight, non-invasive RISC-V ISA extension which implicitly encodes memory accesses as register reads/writes, eliminating a large number of loads/stores. We implement the proposed extension in the RTL of an existing multi-core cluster and synthesize the design for a modern 22nm technology. Our extension provides a signiﬁcant, 2x to 5x, architectural speedup across different kernels at a small 11\% increase in core area. Sequential code runs 3x faster on a single core, and 3x fewer cores are needed in a cluster to achieve the same performance. The utilization increase to almost 100\% in leads to a 2x energy efﬁciency improvement in a multi-core cluster. The extension reduces instruction fetches by up to 3.5x and instruction cache power consumption by up to 5.6x. Compilers can automatically map loop nests to SSRs, making the changes transparent to the programmer.},
	language = {en},
	urldate = {2020-12-25},
	journal = {IEEE Transactions on Computers},
	author = {Schuiki, Fabian and Zaruba, Florian and Hoefler, Torsten and Benini, Luca},
	year = {2020},
	pages = {1--1},
}

@inproceedings{lin_shentu_2018,
	address = {Dallas, TX, USA},
	title = {{ShenTu}: {Processing} {Multi}-{Trillion} {Edge} {Graphs} on {Millions} of {Cores} in {Seconds}},
	isbn = {978-1-5386-8384-2},
	shorttitle = {{ShenTu}},
	url = {https://ieeexplore.ieee.org/document/8665798/},
	doi = {10.1109/SC.2018.00059},
	abstract = {Graphs are an important abstraction used in many scientiﬁc ﬁelds. With the magnitude of graph-structured data constantly increasing, effective data analytics requires efﬁcient and scalable graph processing systems. Although HPC systems have long been used for scientiﬁc computing, people have only recently started to assess their potential for graph processing, a workload with inherent load imbalance, lack of locality, and access irregularity. We propose ShenTu8, the ﬁrst generalpurpose graph processing framework that can efﬁciently utilize an entire Petascale system to process multi-trillion edge graphs in seconds. ShenTu embodies four key innovations: hardware specialization, supernode routing, on-chip sorting, and degree-aware messaging, which together enable its unprecedented performance and scalability. It can traverse a record-size 70-trillion-edge graph in seconds. Furthermore, ShenTu enables the processing of a spam detection problem on a 12-trillion edge Internet graph, making it possible to identify trustworthy and spam webpages directly at the ﬁne-grained page level.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {{SC18}: {International} {Conference} for {High} {Performance} {Computing}, {Networking}, {Storage} and {Analysis}},
	publisher = {IEEE},
	author = {Lin, Heng and Zhu, Xiaowei and Yu, Bowen and Tang, Xiongchao and Xue, Wei and Chen, Wenguang and Zhang, Lufei and Hoefler, Torsten and Ma, Xiaosong and Liu, Xin and Zheng, Weimin and Xu, Jingfang},
	month = nov,
	year = {2018},
	pages = {706--716},
}

@inproceedings{de_matteis_streaming_2019,
	address = {Denver Colorado},
	title = {Streaming message interface: high-performance distributed memory programming on reconfigurable hardware},
	isbn = {978-1-4503-6229-0},
	shorttitle = {Streaming message interface},
	url = {https://dl.acm.org/doi/10.1145/3295500.3356201},
	doi = {10.1145/3295500.3356201},
	abstract = {Distributed memory programming is the established paradigm used in high-performance computing (HPC) systems, requiring explicit communication between nodes and devices. When FPGAs are deployed in distributed settings, communication is typically handled either by going through the host machine, sacrificing performance, or by streaming across fixed device-to-device connections, sacrificing flexibility. We present Streaming Message Interface (SMI), a communication model and API that unifies explicit message passing with a hardware-oriented programming model, facilitating minimal-overhead, flexible, and productive inter-FPGA communication. Instead of bulk transmission, messages are streamed across the network during computation, allowing communication to be seamlessly integrated into pipelined designs. We present a high-level synthesis implementation of SMI targeting a dedicated FPGA interconnect, exposing runtime-configurable routing with support for arbitrary network topologies, and implement a set of distributed memory benchmarks. Using SMI, programmers can implement distributed, scalable HPC programs on reconfigurable hardware, without deviating from best practices for hardware design.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {International} {Conference} for {High} {Performance} {Computing}, {Networking}, {Storage} and {Analysis}},
	publisher = {ACM},
	author = {De Matteis, Tiziano and de Fine Licht, Johannes and Beránek, Jakub and Hoefler, Torsten},
	month = nov,
	year = {2019},
	pages = {1--33},
}

@article{planeta_migros_2020,
	title = {{MigrOS}: {Transparent} {Operating} {Systems} {Live} {Migration} {Support} for {Containerised} {RDMA}-applications},
	shorttitle = {{MigrOS}},
	url = {http://arxiv.org/abs/2009.06988},
	abstract = {Major data centre providers are introducing RDMAbased networks for their tenants, as well as for operating their underlying infrastructure. In comparison to traditional socket-based network stacks, RDMA-based networks oﬀer higher throughput, lower latency, and reduced CPU overhead. However, RDMA networks make transparent checkpoint and migration operations much more diﬃcult. The diﬃculties arise because RDMA network architectures remove the OS from the critical path of communication. As a result, the OS loses control over active RDMA network connections, required for live migration of RDMA-applications. This paper presents TardiS, an OS-level architecture for transparent live migration of RDMA-applications. TardiS offers changes at the OS software level and small changes to the RDMA communication protocol. As a proof of concept, we integrate the proposed changes into SoftRoCE, an open-source kernel-level implementation of an RDMA communication protocol. We designed these changes to introduce no runtime overhead, apart from the actual migration costs. TardiS allows seamless live migration of applications in data centre settings. It also allows HPC clusters to explore new scheduling strategies, which currently do not consider migration as an option to reallocate the resources.},
	language = {en},
	urldate = {2020-12-25},
	journal = {arXiv:2009.06988 [cs]},
	author = {Planeta, Maksym and Bierbaum, Jan and Antony, Leo Sahaya Daphne and Hoefler, Torsten and Härtig, Hermann},
	month = oct,
	year = {2020},
	note = {arXiv: 2009.06988},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Networking and Internet Architecture, Computer Science - Operating Systems},
}

@inproceedings{bjerregaard_scheduling_2005,
	address = {New York City, NY, USA},
	title = {A {Scheduling} {Discipline} for {Latency} and {Bandwidth} {Guarantees} in {Asynchronous} {Network}-on-{Chip}},
	isbn = {978-0-7695-2305-7},
	url = {http://ieeexplore.ieee.org/document/1402044/},
	doi = {10.1109/ASYNC.2005.7},
	abstract = {Guaranteed services (GS) are important in that they provide predictability in the complex dynamics of shared communication structures. This paper discusses the implementation of GS in asynchronous Network-on-Chip. We present a novel scheduling discipline called Asynchronous Latency Guarantee (ALG) scheduling, which provides latency and bandwidth guarantees in accessing a shared media, e.g. a physical link shared between a number of virtual channels. ALG overcomes the drawbacks of existing scheduling disciplines, in particular the coupling between latency and bandwidth guarantees. A 0.12 µm CMOS standard cell implementation of an ALG link has been simulated. The operation speed of the design was 702 MDI/s.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {11th {IEEE} {International} {Symposium} on {Asynchronous} {Circuits} and {Systems}},
	publisher = {IEEE},
	author = {Bjerregaard, T. and Sparso, J.},
	year = {2005},
	pages = {34--43},
}

@inproceedings{carloni_invited_2016,
	address = {Austin Texas},
	title = {Invited - {The} case for embedded scalable platforms},
	isbn = {978-1-4503-4236-0},
	url = {https://dl.acm.org/doi/10.1145/2897937.2905018},
	doi = {10.1145/2897937.2905018},
	abstract = {Heterogeneous system-on-chip (SoC) architectures are emerging as a fundamental computing platform across a variety of domains, from mobile to cloud computing. Heterogeneity, however, increases design complexity in terms of hardware-software interactions, access to shared resources, and diminished regularity of the design. Embedded Scalable Platforms are a novel approach to SoC design and programming that addresses these design-complexity challenges by combining an architecture and a methodology. The ﬂexible socketed architecture simpliﬁes the integration of heterogeneous components by balancing regularity and specialization. The companion methodology raises the level of abstraction to system-level design, thus promoting closer collaboration among software programmers and hardware engineers. The architecture is supported by a scalable communication infrastructure. The methodology leverages compositional design-space exploration with high-level synthesis. The case for Embedded Scalable Platforms is made based on experiments on the development of various full-system prototypes and experience in teaching these concepts in a new graduate course.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 53rd {Annual} {Design} {Automation} {Conference}},
	publisher = {ACM},
	author = {Carloni, Luca P.},
	month = jun,
	year = {2016},
	pages = {1--6},
}

@article{mckeown_piton_2017,
	title = {Piton: {A} {Manycore} {Processor} for {Multitenant} {Clouds}},
	volume = {37},
	issn = {0272-1732},
	shorttitle = {Piton},
	url = {http://ieeexplore.ieee.org/document/7924281/},
	doi = {10.1109/MM.2017.36},
	language = {en},
	number = {2},
	urldate = {2020-12-25},
	journal = {IEEE Micro},
	author = {McKeown, Michael and Fu, Yaosheng and Nguyen, Tri and Zhou, Yanqi and Balkind, Jonathan and Lavrov, Alexey and Shahrad, Mohammad and Payne, Samuel and Wentzlaff, David},
	month = mar,
	year = {2017},
	pages = {70--80},
}

@inproceedings{kumar_network_2002,
	address = {Pittsburgh, PA, USA},
	title = {A network on chip architecture and design methodology},
	isbn = {978-0-7695-1486-4},
	url = {http://ieeexplore.ieee.org/document/1016885/},
	doi = {10.1109/ISVLSI.2002.1016885},
	abstract = {We propose a packet switched platform for single chip systems which scales well to an arbitrary number of processor like resources. The platform, which we call Network-on-Chip (NOC), includes both the architecture and the design methodology.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings {IEEE} {Computer} {Society} {Annual} {Symposium} on {VLSI}. {New} {Paradigms} for {VLSI} {Systems} {Design}. {ISVLSI} 2002},
	publisher = {IEEE Comput. Soc},
	author = {Kumar, S. and Jantsch, A. and Soininen, J.-P. and Forsell, M. and Millberg, M. and Oberg, J. and Tiensyrja, K. and Hemani, A.},
	year = {2002},
	pages = {117--124},
}

@article{bertozzi_feature_2004,
	title = {Feature - {Xpipes} : a network-on-chip architecture for gigascale systems-on-chip},
	volume = {4},
	issn = {1531-636X},
	shorttitle = {Feature - {Xpipes}},
	url = {http://ieeexplore.ieee.org/document/1330747/},
	doi = {10.1109/MCAS.2004.1330747},
	abstract = {The growing complexity of embedded multi-processor architectures for digital media processing will soon require highly scalable communication infrastructures. Packet switched Networks-on-Chip (NoC) have been proposed to support the trend for Systems-on-Chip integration. In this paper, an advanced NoC architecture, called Xpipes, targeting high performance and reliable communication for on-chip multi-processors is introduced. It consists of a library of soft macros (switches, network interfaces and links) that are design-time composable and tunable so that domainspecific heterogeneous architectures can be instantiated and synthesized. Links can be pipelined with a flexible number of stages to decouple link throughput from its length and to get arbitrary topologies. Moreover, a tool called XpipesCompiler, which automatically instantiates a customized NoC from the library of soft network components, is used in this paper to test the Xpipes-based synthesis flow for domain-specific communication architectures.},
	language = {en},
	number = {2},
	urldate = {2020-12-25},
	journal = {IEEE Circuits and Systems Magazine},
	author = {Bertozzi, D. and Benini, L.},
	year = {2004},
	pages = {18--31},
}

@article{bolotin_qnoc_2004,
	title = {{QNoC}: {QoS} architecture and design process for network on chip},
	volume = {50},
	issn = {13837621},
	shorttitle = {{QNoC}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1383762103001139},
	doi = {10.1016/j.sysarc.2003.07.004},
	abstract = {We deﬁne Quality of Service (QoS) and cost model for communications in Systems on Chip (SoC), and derive related Network on Chip (NoC) architecture and design process. SoC inter-module communication traﬃc is classiﬁed into four classes of service: signaling (for inter-module control signals); real-time (representing delay-constrained bit streams); RD/WR (modeling short data access) and block-transfer (handling large data bursts). Communication traﬃc of the target SoC is analyzed (by means of analytic calculations and simulations), and QoS requirements (delay and throughput) for each service class are derived. A customized Quality-of-Service NoC (QNoC) architecture is derived by modifying a generic network architecture. The customization process minimizes the network cost (in area and power) while maintaining the required QoS.},
	language = {en},
	number = {2-3},
	urldate = {2020-12-25},
	journal = {Journal of Systems Architecture},
	author = {Bolotin, Evgeny and Cidon, Israel and Ginosar, Ran and Kolodny, Avinoam},
	month = feb,
	year = {2004},
	pages = {105--128},
}

@article{bjerregaard_survey_2006,
	title = {A survey of research and practices of {Network}-on-chip},
	volume = {38},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/1132952.1132953},
	doi = {10.1145/1132952.1132953},
	language = {en},
	number = {1},
	urldate = {2020-12-25},
	journal = {ACM Computing Surveys},
	author = {Bjerregaard, Tobias and Mahadevan, Shankar},
	month = jun,
	year = {2006},
	pages = {1},
}

@article{goossens_aethereal_2005,
	title = {Æthereal {Network} on {Chip}:{Concepts}, {Architectures}, and {Implementations}},
	volume = {22},
	issn = {0740-7475},
	shorttitle = {Æthereal {Network} on {Chip}},
	url = {http://ieeexplore.ieee.org/document/1511973/},
	doi = {10.1109/MDT.2005.99},
	language = {en},
	number = {5},
	urldate = {2020-12-25},
	journal = {IEEE Design and Test of Computers},
	author = {Goossens, K. and Dielissen, J. and Radulescu, A.},
	month = may,
	year = {2005},
	pages = {414--421},
}

@article{hemani_network_nodate,
	title = {Network on a {Chip}: {An} architecture for billion transistor era},
	abstract = {Looking into the future, when the billion transitor ASICs will become reality, this paper presents Network on a chip (NOC) concept and its associated methodology as solution to the design productivity problem. NOC is a network of computational, storage and I/O resources, interconnected by a network of switches. Resources communcate with each other using addressed data packets routed to their destination by the switch fabric. Arguments are presented to justify that in the billion transistor era, the area and performance penalty would be minimum. A concrete topology for the NOC, a honeycomb structure, is proposed and discussed. A methodology to support NOC is presented. This methodology outlines steps from requirements down to implementation. As an illustration of the concepts, a plausible mapping of an entire basestation on hypothetical NOC is discussed.},
	language = {en},
	author = {Hemani, Ahmed and Jantsch, Axel and Kumar, Shashi and Postula, Adam and Öberg, Johnny and Lindqvist, Dan},
	pages = {8},
}

@inproceedings{vangal_80-tile_2007,
	address = {San Francisco, CA, USA},
	title = {An 80-{Tile} 1.{28TFLOPS} {Network}-on-{Chip} in 65nm {CMOS}},
	isbn = {978-1-4244-0852-8 978-1-4244-0853-5},
	url = {http://ieeexplore.ieee.org/document/4242283/},
	doi = {10.1109/ISSCC.2007.373606},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2007 {IEEE} {International} {Solid}-{State} {Circuits} {Conference}. {Digest} of {Technical} {Papers}},
	publisher = {IEEE},
	author = {Vangal, Sriram and Howard, Jason and Ruhl, Gregory and Dighe, Saurabh and Wilson, Howard and Tschanz, James and Finan, David and Iyer, Priya and Singh, Arvind and Jacob, Tiju and Jain, Shailendra and Venkataraman, Sriram and Hoskote, Yatin and Borkar, Nitin},
	month = feb,
	year = {2007},
	note = {ISSN: 0193-6530},
	pages = {98--589},
}

@article{pande_performance_2005,
	title = {Performance {Evaluation} and {Design} {Trade}-{Offs} for {Network}-on-{Chip} {Interconnect} {Architectures}},
	volume = {54},
	issn = {0018-9340},
	url = {http://ieeexplore.ieee.org/document/1453503/},
	doi = {10.1109/TC.2005.134},
	abstract = {Multiprocessor system-on-chip (MP-SoC) platforms are emerging as an important trend for SoC design. Power and wire design constraints are forcing the adoption of new design methodologies for system-on-chip (SoC), namely, those that incorporate modularity and explicit parallelism. To enable these MP-SoC platforms, researchers have recently pursued scaleable communicationcentric interconnect fabrics, such as networks-on-chip (NoC), which possess many features that are particularly attractive for these. These communication-centric interconnect fabrics are characterized by different trade-offs with regard to latency, throughput, energy dissipation, and silicon area requirements. In this paper, we develop a consistent and meaningful evaluation methodology to compare the performance and characteristics of a variety of NoC architectures. We also explore design trade-offs that characterize the NoC approach and obtain comparative results for a number of common NoC topologies. To the best of our knowledge, this is the first effort in characterizing different NoC architectures with respect to their performance and design trade-offs. To further illustrate our evaluation methodology, we map a typical multiprocessing platform to different NoC interconnect architectures and show how the system performance is affected by these design trade-offs.},
	language = {en},
	number = {8},
	urldate = {2020-12-25},
	journal = {IEEE Transactions on Computers},
	author = {Pande, P.P. and Grecu, C. and Jones, M. and Ivanov, A. and Saleh, R.},
	month = aug,
	year = {2005},
	pages = {1025--1040},
}

@article{li_dyxy_nodate,
	title = {{DyXY} - {A} {Proximity} {Congestion}-{Aware} {Deadlock}-{Free} {Dynamic} {Routing} {Method} for {Network} on {Chip}},
	abstract = {A novel routing algorithm, namely dynamic XY (DyXY) routing, is proposed for NoCs to provide adaptive routing and ensure deadlock-free and livelock-free routing at the same time. A new router architecture is developed to support the routing algorithm. Analytical models based on queuing theory are developed for DyXY routing for a twodimensional mesh NoC architecture, and analytical results match very well with the simulation results. It is observed that DyXY routing can achieve better performance compared with static XY routing and odd-even routing.},
	language = {en},
	author = {Li, Ming and Zeng, Qing-An and Jone, Wen-Ben},
	pages = {4},
}

@inproceedings{zhang_reconfigurable_2008,
	address = {Anaheim, California},
	title = {A reconfigurable routing algorithm for a fault-tolerant {2D}-{Mesh} {Network}-on-{Chip}},
	isbn = {978-1-60558-115-6},
	url = {http://portal.acm.org/citation.cfm?doid=1391469.1391584},
	doi = {10.1145/1391469.1391584},
	abstract = {In this paper we present a reconﬁgurable routing algorithm for a 2D-Mesh Network-on-Chip (NoC) dedicated to faulttolerant, Massively Parallel Multi-Processors Systems on Chip (MP2-SoC). The routing algorithm can be dynamically reconﬁgured, to adapt to the modiﬁcation of the micro-network topology caused by a faulty router. This algorithm has been implemented in a reconﬁgurable version of the DSPIN micro-network, and evaluated from the point of view of performance (penalty on the network saturation threshold), and cost (extra silicon area occupied by the reconﬁgurable version of the router).},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 45th annual conference on {Design} automation - {DAC} '08},
	publisher = {ACM Press},
	author = {Zhang, Zhen and Greiner, Alain and Taktak, Sami},
	year = {2008},
	pages = {441},
}

@inproceedings{yin_modular_2018,
	address = {Los Angeles, CA},
	title = {Modular {Routing} {Design} for {Chiplet}-{Based} {Systems}},
	isbn = {978-1-5386-5984-7},
	url = {https://ieeexplore.ieee.org/document/8416868/},
	doi = {10.1109/ISCA.2018.00066},
	abstract = {System-on-Chip (SoC) complexity and the increasing costs of silicon motivate the breaking of an SoC into smaller “chiplets.” A chiplet-based SoC design process has the promise to enable fast SoC construction by using advanced packaging technologies to tightly integrate multiple disparate chips (e.g., CPU, GPU, memory, FPGA). However, when assembling chiplets into a single SoC, correctness validation becomes a signiﬁcant challenge. In particular, the network-on-chip (NoC) used within the individual chiplets and across chiplets to tie them together can easily have deadlocks, especially if each chip is designed in isolation.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2018 {ACM}/{IEEE} 45th {Annual} {International} {Symposium} on {Computer} {Architecture} ({ISCA})},
	publisher = {IEEE},
	author = {Yin, Jieming and Lin, Zhifeng and Kayiran, Onur and Poremba, Matthew and Shoaib Bin Altaf, Muhammad and Enright Jerger, Natalie and Loh, Gabriel H.},
	month = jun,
	year = {2018},
	pages = {726--738},
}

@inproceedings{mounce_chiplet_2016,
	address = {Big Sky, MT, USA},
	title = {Chiplet based approach for heterogeneous processing and packaging architectures},
	isbn = {978-1-4673-7676-1},
	url = {http://ieeexplore.ieee.org/document/7500830/},
	doi = {10.1109/AERO.2016.7500830},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2016 {IEEE} {Aerospace} {Conference}},
	publisher = {IEEE},
	author = {Mounce, Gabriel and Lyke, Jim and Horan, Stephen and Powell, Wes and Doyle, Rich and Some, Rafi},
	month = mar,
	year = {2016},
	pages = {1--12},
}

@inproceedings{thonnart_popstar_2020,
	address = {Grenoble, France},
	title = {{POPSTAR}: a {Robust} {Modular} {Optical} {NoC} {Architecture} for {Chiplet}-based {3D} {Integrated} {Systems}},
	isbn = {978-3-9819263-4-7},
	shorttitle = {{POPSTAR}},
	url = {https://ieeexplore.ieee.org/document/9116214/},
	doi = {10.23919/DATE48585.2020.9116214},
	abstract = {Silicon photonics technology is now gaining maturity with increasing levels of design complexity from devices to large photonic integrated circuits. Close integration of control electronics with 3D assembly of photonics and CMOS open the way to high-performance computing architectures partitioned in chiplets connected by optical NoC on silicon photonic interposers. In this paper, we give an overview of our works on optical links and NoC for manycore systems, from low-level control of photonic devices to high-level system optimization of the optical communications. We detail the POPSTAR optical NoC topology and architecture (Processors On Photonic Silicon interposer Terascale ARchitecture) with electro-optical interface chiplets, the corresponding nested spiral topology for single-writer multiplereader links and the associated control electronics, in charge of high-speed drivers, thermal stabilization and handling of the protocol stack, from data integrity to flow-control, routing and arbitration of the optical communications. The strengths and opportunities for this architecture will be discussed, with a shift in system \& implementation constraints with respect to previous optical NoC proposals, and new challenges to be addressed.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2020 {Design}, {Automation} \& {Test} in {Europe} {Conference} \& {Exhibition} ({DATE})},
	publisher = {IEEE},
	author = {Thonnart, Yvain and Bernabe, Stephane and Charbonnier, Jean and Bernard, Christian and Coriat, David and Fuguet, Cesar and Tissier, Pierre and Charbonnier, Benoit and Malhouitre, Stephane and Saint-Patrice, Damien and Assous, Myriam and Narayan, Aditya and Coskun, Ayse and Dutoit, D. and Vivet, P.},
	month = mar,
	year = {2020},
	pages = {1456--1461},
}

@inproceedings{naffziger_22_2020,
	address = {San Francisco, CA, USA},
	title = {2.2 {AMD} {Chiplet} {Architecture} for {High}-{Performance} {Server} and {Desktop} {Products}},
	isbn = {978-1-72813-205-1},
	url = {https://ieeexplore.ieee.org/document/9063103/},
	doi = {10.1109/ISSCC19947.2020.9063103},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2020 {IEEE} {International} {Solid}- {State} {Circuits} {Conference} - ({ISSCC})},
	publisher = {IEEE},
	author = {Naffziger, Samuel and Lepak, Kevin and Paraschou, Milam and Subramony, Mahesh},
	month = feb,
	year = {2020},
	pages = {44--45},
}

@article{pal_design_2020,
	title = {Design {Space} {Exploration} for {Chiplet}-{Assembly}-{Based} {Processors}},
	volume = {28},
	issn = {1063-8210, 1557-9999},
	url = {https://ieeexplore.ieee.org/document/8998304/},
	doi = {10.1109/TVLSI.2020.2968904},
	abstract = {Recent advancements in 2.5-D integration technologies have made chiplet assembly a viable system design approach. Chiplet assembly is emerging as a new paradigm for heterogeneous design at lower cost, design effort, and turnaround time and enables low-cost customization of hardware. However, the success of this approach depends on identifying a minimum chiplet set which delivers these beneﬁts. We develop the ﬁrst microarchitectural design space exploration framework for chiplet assembly-based processors which enables us to identify the minimum set of chiplets to design and manufacture. Since chiplet assembly makes heterogeneous technology and costeffective application-dependent customization possible, we show the beneﬁts of using multiple systems built from multiple chiplets to service diverse workloads (up to 35\% improvement in energydelay product over a single best system) and advantages of chiplet assembly approaches over system-on-chip (SoC) methodology in terms of total cost (up to 72\% improvement in cost) while satisfying the energy and performance constraints of individual applications.},
	language = {en},
	number = {4},
	urldate = {2020-12-25},
	journal = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
	author = {Pal, Saptadeep and Petrisko, Daniel and Kumar, Rakesh and Gupta, Puneet},
	month = apr,
	year = {2020},
	pages = {1062--1073},
}

@inproceedings{kadomoto_wixi_2019,
	address = {Abu Dhabi, United Arab Emirates},
	title = {{WiXI}: {An} {Inter}-{Chip} {Wireless} {Bus} {Interface} for {Shape}-{Changeable} {Chiplet}-{Based} {Computers}},
	isbn = {978-1-5386-6648-7},
	shorttitle = {{WiXI}},
	url = {https://ieeexplore.ieee.org/document/8988618/},
	doi = {10.1109/ICCD46524.2019.00021},
	abstract = {Herein, we propose a wireless bus interface that can connect multiple chips to form a ﬂexible system. In the proposed bus interface, on-chip coils are formed along the outer periphery of each chip, and high-speed wireless communication between multiple chips is enabled via horizontal inductive coupling between coils. Using the proposed interface, embedded computer systems can be realized by simply combining small chips with different functions as needed and arranging them in an adjacent manner. The proposed bus interface enables variation in the relative angle between adjacent chips during operation, can be implemented in complicated shapes, and facilitates chip replacement post fabrication to achieve ﬂexible and robust computer systems; such systems can be applied in micro-robots and wearable interfaces. In this paper, we present a theoretical analysis of electromagnetic coupling between coils, electromagnetic ﬁeld simulation results, and circuit simulation results of transmitter and receiver circuits. Through the simulation conducted using 45 nm CMOS technology, we realized high-speed communication of 14.3 Gb/s with a power efﬁciency of 0.55 pJ/b using the proposed bus interface. We also veriﬁed the data collision detection ability of the proposed bus interface using a collision detection circuit and packet transfer based on a SerDes circuit.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2019 {IEEE} 37th {International} {Conference} on {Computer} {Design} ({ICCD})},
	publisher = {IEEE},
	author = {Kadomoto, Junichiro and Irie, Hidetsugu and Sakai, Shuichi},
	month = nov,
	year = {2019},
	pages = {100--108},
}

@inproceedings{haj-ali_neurovectorizer_2020,
	address = {San Diego CA USA},
	title = {{NeuroVectorizer}: end-to-end vectorization with deep reinforcement learning},
	isbn = {978-1-4503-7047-9},
	shorttitle = {{NeuroVectorizer}},
	url = {https://dl.acm.org/doi/10.1145/3368826.3377928},
	doi = {10.1145/3368826.3377928},
	abstract = {One of the key challenges arising when compilers vectorize loops for today’s SIMD-compatible architectures is to decide if vectorization or interleaving is beneficial. Then, the compiler has to determine the number of instructions to pack together and the interleaving level (stride). Compilers are designed today to use fixed-cost models that are based on heuristics to make vectorization decisions on loops. However, these models are unable to capture the data dependency, the computation graph, or the organization of instructions. Alternatively, software engineers often hand-write the vectorization factors of every loop. This, however, places a huge burden on them, since it requires prior experience and significantly increases the development time. In this work, we explore a novel approach for handling loop vectorization and propose an end-to-end solution using deep reinforcement learning (RL). We conjecture that deep RL can capture different instructions, dependencies, and data structures to enable learning a sophisticated model that can better predict the actual performance cost and determine the optimal vectorization factors. We develop an end-to-end framework, from code to vectorization, that integrates deep RL in the LLVM compiler. Our proposed framework takes benchmark codes as input and extracts the loop codes. These loop codes are then fed to a loop embedding generator that learns an embedding for these loops. Finally, the learned embeddings are used as input to a Deep RL agent, which ∗Part of this work was done while Ameer Haj-Ali was in a summer internship at Intel Labs.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 18th {ACM}/{IEEE} {International} {Symposium} on {Code} {Generation} and {Optimization}},
	publisher = {ACM},
	author = {Haj-Ali, Ameer and Ahmed, Nesreen K. and Willke, Ted and Shao, Yakun Sophia and Asanovic, Krste and Stoica, Ion},
	month = feb,
	year = {2020},
	pages = {242--255},
}

@inproceedings{karandikar_fireperf_2020,
	address = {Lausanne Switzerland},
	title = {{FirePerf}: {FPGA}-{Accelerated} {Full}-{System} {Hardware}/{Software} {Performance} {Profiling} and {Co}-{Design}},
	isbn = {978-1-4503-7102-5},
	shorttitle = {{FirePerf}},
	url = {https://dl.acm.org/doi/10.1145/3373376.3378455},
	doi = {10.1145/3373376.3378455},
	abstract = {Achieving high-performance when developing specialized hardware/software systems requires understanding and improving not only core compute kernels, but also intricate and elusive system-level bottlenecks. Profiling these bottlenecks requires both high-fidelity introspection and the ability to run sufficiently many cycles to execute complex software stacks, a challenging combination. In this work, we enable agile full-system performance optimization for hardware/ software systems with FirePerf, a set of novel out-of-band system-level performance profiling capabilities integrated into the open-source FireSim FPGA-accelerated hardware simulation platform. Using out-of-band call stack reconstruction and automatic performance counter insertion, FirePerf enables introspecting into hardware and software at appropriate abstraction levels to rapidly identify opportunities for software optimization and hardware specialization, without disrupting end-to-end system behavior like traditional profiling tools. We demonstrate the capabilities of FirePerf with a case study that optimizes the hardware/software stack of an open-source RISC-V SoC with an Ethernet NIC to achieve 8× end-to-end improvement in achievable bandwidth for networking applications running on Linux. We also deploy a RISC-V Linux kernel optimization discovered with FirePerf on commercial RISC-V silicon, resulting in up to 1.72× improvement in network performance.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Karandikar, Sagar and Ou, Albert and Amid, Alon and Mao, Howard and Katz, Randy and Nikolić, Borivoje and Asanović, Krste},
	month = mar,
	year = {2020},
	pages = {715--731},
}

@inproceedings{karandikar_firesim_2018,
	address = {Los Angeles, CA},
	title = {{FireSim}: {FPGA}-{Accelerated} {Cycle}-{Exact} {Scale}-{Out} {System} {Simulation} in the {Public} {Cloud}},
	isbn = {978-1-5386-5984-7},
	shorttitle = {{FireSim}},
	url = {https://ieeexplore.ieee.org/document/8416816/},
	doi = {10.1109/ISCA.2018.00014},
	abstract = {We present FireSim, an open-source simulation platform that enables cycle-exact microarchitectural simulation of large scale-out clusters by combining FPGA-accelerated simulation of silicon-proven RTL designs with a scalable, distributed network simulation. Unlike prior FPGA-accelerated simulation tools, FireSim runs on Amazon EC2 F1, a public cloud FPGA platform, which greatly improves usability, provides elasticity, and lowers the cost of large-scale FPGAbased experiments. We describe the design and implementation of FireSim and show how it can provide sufﬁcient performance to run modern applications at scale, to enable true hardware-software co-design. As an example, we demonstrate automatically generating and deploying a target cluster of 1,024 3.2 GHz quad-core server nodes, each with 16 GB of DRAM, interconnected by a 200 Gbit/s network with 2 microsecond latency, which simulates at a 3.4 MHz processor clock rate (less than 1,000x slowdown over real-time). In aggregate, this FireSim instantiation simulates 4,096 cores and 16 TB of memory, runs ˜14 billion instructions per second, and harnesses 12.8 million dollars worth of FPGAs—at a total cost of only ˜\$100 per simulation hour to the user. We present several examples to show how FireSim can be used to explore various research directions in warehouse-scale machine design, including modeling networks with high-bandwidth and lowlatency, integrating arbitrary RTL designs for a variety of commodity and specialized datacenter nodes, and modeling a variety of datacenter organizations, as well as reusing the scaleout FireSim infrastructure to enable fast, massively parallel cycle-exact single-node microarchitectural experimentation.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2018 {ACM}/{IEEE} 45th {Annual} {International} {Symposium} on {Computer} {Architecture} ({ISCA})},
	publisher = {IEEE},
	author = {Karandikar, Sagar and Mao, Howard and Kim, Donggyu and Biancolin, David and Amid, Alon and Lee, Dayeol and Pemberton, Nathan and Amaro, Emmanuel and Schmidt, Colin and Chopra, Aditya and Huang, Qijing and Kovacs, Kyle and Nikolic, Borivoje and Katz, Randy and Bachrach, Jonathan and Asanovic, Krste},
	month = jun,
	year = {2018},
	pages = {29--42},
}

@inproceedings{magyar_golden_2019,
	address = {Westminster, CO, USA},
	title = {Golden {Gate}: {Bridging} {The} {Resource}-{Efficiency} {Gap} {Between} {ASICs} and {FPGA} {Prototypes}},
	isbn = {978-1-72812-350-9},
	shorttitle = {Golden {Gate}},
	url = {https://ieeexplore.ieee.org/document/8942087/},
	doi = {10.1109/ICCAD45719.2019.8942087},
	abstract = {We present Golden Gate, an FPGA-based simulation tool that decouples the timing of an FPGA host platform from that of the target RTL design. In contrast to previous work in static time-multiplexing of FPGA resources, Golden Gate employs the Latency-Insensitive Bounded Dataflow Network (LI-BDN) formalism to decompose the simulator into subcomponents, each of which may be independently and automatically optimized. This structure allows Golden Gate to support a broad class of optimizations that improve resource utilization by implementing FPGA-hostile structures over multiple cycles, while the LI-BDN formalism ensures that the simulator still produces bit- and cycle-exact results. To verify that these optimizations are implemented correctly, we also present lime, a model-checking tool that provides a push-button flow for checking whether optimized subcomponents adhere to an associated correctness specification, while also guaranteeing forward progress. Finally, we use Golden Gate to generate a cycle-exact simulator of a multi-core SoC, where we reduce LUT utilization by up to 26\% by coercing multi-ported, combinationally read memories into simulation models backed by time-multiplexed block RAMs, enabling us to simulate 50\% more cores on a single FPGA.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2019 {IEEE}/{ACM} {International} {Conference} on {Computer}-{Aided} {Design} ({ICCAD})},
	publisher = {IEEE},
	author = {Magyar, Albert and Biancolin, David and Koenig, John and Seshia, Sanjit and Bachrach, Jonathan and Asanovic, Krste},
	month = nov,
	year = {2019},
	pages = {1--8},
}

@article{pemberton_serverless_nodate,
	title = {The {Serverless} {Data} {Center}: {Hardware} {Disaggregation} {Meets} {Serverless} {Computing}},
	abstract = {Serverless computing and hardware disaggregation are recent movements that have progressed largely independently, even though they share a common goal: to shape the future of cloud computing. Serverless computing is a software layer that simpliﬁes cloud programming, even without changes to the underlying hardware, whereas hardware disaggregation challenges the established approach to data center architecture, breaking up traditional server units into their individual components and rewiring them in alternative ways. While a superﬁcial similarity is apparent, the two movements are synergistic in fundamental technical ways. Cross-pollination of ideas promises advances on both sides, and co-design could be essential and rewarding in the long run.},
	language = {en},
	author = {Pemberton, Nathan and Schleier-Smith, Johann},
	pages = {6},
}

@inproceedings{biancolin_fased_2019,
	address = {Seaside CA USA},
	title = {{FASED}: {FPGA}-{Accelerated} {Simulation} and {Evaluation} of {DRAM}},
	isbn = {978-1-4503-6137-8},
	shorttitle = {{FASED}},
	url = {https://dl.acm.org/doi/10.1145/3289602.3293894},
	doi = {10.1145/3289602.3293894},
	abstract = {Recent work in FPGA-accelerated simulation of ASICs has shown that much of a simulator can be automatically generated from ASIC RTL. Alas, these works rely on simple models of the outer cache hierarchy and DRAM, as mapping ASIC RTL for these components into an FPGA fabric is too complex and resource intensive. To improve FPGA simulation model accuracy, we present fased, a parameterized generator of composable, high-fidelity, FPGA-hosted last-level-cache and DRAM models. fased instances are highly performant, yet they maintain timing faithfulness independently of the behavior of the host-FPGA memory system. For a given scheduling policy, a single fased instance can model nearly the entire space of realizable single-channel DDR3 memory organizations, without resynthesizing the simulator RTL. We demonstrate fased by integrating it into a flow that automatically transforms RTL for multicore RISC-V processors into full-system simulators that execute at up to 150 target MHz on cloud-hosted FPGAs.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 2019 {ACM}/{SIGDA} {International} {Symposium} on {Field}-{Programmable} {Gate} {Arrays}},
	publisher = {ACM},
	author = {Biancolin, David and Karandikar, Sagar and Kim, Donggyu and Koenig, Jack and Waterman, Andrew and Bachrach, Jonathan and Asanovic, Krste},
	month = feb,
	year = {2019},
	pages = {330--339},
}

@article{conti_iot_2017,
	title = {An {IoT} {Endpoint} {System}-on-{Chip} for {Secure} and {Energy}-{Efficient} {Near}-{Sensor} {Analytics}},
	volume = {64},
	issn = {1549-8328, 1558-0806},
	url = {http://arxiv.org/abs/1612.05974},
	doi = {10.1109/TCSI.2017.2698019},
	abstract = {Near-sensor data analytics is a promising direction for IoT endpoints, as it minimizes energy spent on communication and reduces network load - but it also poses security concerns, as valuable data is stored or sent over the network at various stages of the analytics pipeline. Using encryption to protect sensitive data at the boundary of the on-chip analytics engine is a way to address data security issues. To cope with the combined workload of analytics and encryption in a tight power envelope, we propose Fulmine, a System-on-Chip based on a tightly-coupled multi-core cluster augmented with specialized blocks for compute-intensive data processing and encryption functions, supporting software programmability for regular computing tasks. The Fulmine SoC, fabricated in 65 nm technology, consumes less than 20 mW on average at 0.8 V achieving an efﬁciency of up to 70 pJ/B in encryption, 50 pJ/px in convolution, or up to 25 MIPS/mW in software. As a strong argument for real-life ﬂexible application of our platform, we show experimental results for three secure analytics use cases: secure autonomous aerial surveillance with a state-of-the-art deep CNN consuming 3.16 pJ per equivalent RISC op; local CNN-based face detection with secured remote recognition in 5.74 pJ/op; and seizure detection with encrypted data collection from EEG within 12.7 pJ/op.},
	language = {en},
	number = {9},
	urldate = {2020-12-25},
	journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
	author = {Conti, Francesco and Schilling, Robert and Schiavone, Pasquale Davide and Pullini, Antonio and Rossi, Davide and Gürkaynak, Frank Kagan and Muehlberghuber, Michael and Gautschi, Michael and Loi, Igor and Haugou, Germain and Mangard, Stefan and Benini, Luca},
	month = sep,
	year = {2017},
	note = {arXiv: 1612.05974},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Hardware Architecture, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	pages = {2481--2494},
}

@inproceedings{lee_keystone_2020,
	address = {Heraklion Greece},
	title = {Keystone: an open framework for architecting trusted execution environments},
	isbn = {978-1-4503-6882-7},
	shorttitle = {Keystone},
	url = {https://dl.acm.org/doi/10.1145/3342195.3387532},
	doi = {10.1145/3342195.3387532},
	abstract = {Trusted execution environments (TEEs) see rising use in devices from embedded sensors to cloud servers and encompass a range of cost, power constraints, and security threat model choices. On the other hand, each of the current vendor-specific TEEs makes a fixed set of trade-offs with little room for customization. We present Keystone—the first open-source framework for building customized TEEs. Keystone uses simple abstractions provided by the hardware such as memory isolation and a programmable layer underneath untrusted components (e.g., OS). We build reusable TEE core primitives from these abstractions while allowing platform-specific modifications and flexible feature choices. We showcase how Keystone-based TEEs run on unmodified RISC-V hardware and demonstrate the strengths of our design in terms of security, TCB size, execution of a range of benchmarks, applications, kernels, and deployment models.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {Fifteenth} {European} {Conference} on {Computer} {Systems}},
	publisher = {ACM},
	author = {Lee, Dayeol and Kohlbrenner, David and Shinde, Shweta and Asanović, Krste and Song, Dawn},
	month = apr,
	year = {2020},
	pages = {1--16},
}

@article{lee_off-chip_nodate,
	title = {An {Off}-{Chip} {Attack} on {Hardware} {Enclaves} via the {Memory} {Bus}},
	abstract = {This paper shows how an attacker can break the conﬁdentiality of a hardware enclave with MEMBUSTER, an off-chip attack based on snooping the memory bus. An attacker with physical access can observe an unencrypted address bus and extract ﬁne-grained memory access patterns of the victim. MEMBUSTER is qualitatively different from prior on-chip attacks to enclaves and is more difﬁcult to thwart. We highlight several challenges for MEMBUSTER. First, DRAM requests are only visible on the memory bus at lastlevel cache misses. Second, the attack needs to incur minimal interference or overhead to the victim to prevent the detection of the attack. Lastly, the attacker needs to reverse-engineer the translation between virtual, physical, and DRAM addresses to perform a robust attack. We introduce three techniques, critical page whitelisting, cache squeezing, and oracle-based fuzzy matching algorithm to increase cache misses for memory accesses that are useful for the attack, with no detectable interference to the victim, and to convert memory accesses to sensitive data. We demonstrate MEMBUSTER on an Intel SGX CPU to leak conﬁdential data from two applications: Hunspell and Memcached. We show that a single uninterrupted run of the victim can leak most of the sensitive data with high accuracy.},
	language = {en},
	author = {Lee, Dayeol and Jung, Dongha and Fang, Ian T and Tsai, Chia-Che and Popa, Raluca Ada},
	pages = {18},
}

@article{maas_hardware_nodate,
	title = {A {Hardware} {Accelerator} for {Tracing} {Garbage} {Collection}},
	abstract = {A large number of workloads are written in garbage-collected languages. These applications spend up to 1035\% of their CPU cycles on GC, and these numbers increase further for pause-free concurrent collectors. As this amounts to a signiﬁcant fraction of resources in scenarios ranging from data centers to mobile devices, reducing the cost of GC would improve the efﬁciency of a wide range of workloads.},
	language = {en},
	author = {Maas, Martin and Asanovic, Krste and Kubiatowicz, John},
	pages = {14},
}

@article{wang_hammer_nodate,
	title = {Hammer: {Enabling} {Reusable} {Physical} {Design}},
	abstract = {A lack of reusable physical design methodologies in ASIC design contributes to high design effort and costs. We posit that traditional ﬂows suffer from a lack of separation between logical design, physical design, technology, and tool concerns, preventing effective re-use. We introduce Hammer, a physical design generator which remedies these problems via separation of concerns. In addition, Hammer addresses the needs of users to achieve practical re-usability using the principles of incremental adoption, system evolution, and abstraction with modularity. We elucidate how the design of Hammer separates concerns to enable usability, and walk through examples of how the principles of Hammer facilitate and contribute to open-source re-use and sharing in the domain of physical design.},
	language = {en},
	author = {Wang, Edward and Izraelevitz, Adam and Schmidt, Colin and Nikolic, Borivoje and Alon, Elad and Bachrach, Jonathan},
	pages = {6},
}

@article{tastan_approximate_2020,
	title = {Approximate {CPU} {Design} for {IoT} {End}-{Devices} with {Learning} {Capabilities}},
	volume = {9},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/9/1/125},
	doi = {10.3390/electronics9010125},
	abstract = {With the rise of Internet of Things (IoT), low-cost resource-constrained devices have to be more capable than traditional embedded systems, which operate on stringent power budgets. In order to add new capabilities such as learning, the power consumption planning has to be revised. Approximate computing is a promising paradigm for reducing power consumption at the expense of inaccuracy introduced to the computations. In this paper, we set forth approximate computing features of a processor that will exist in the next generation low-cost resource-constrained learning IoT devices. Based on these features, we design an approximate IoT processor which beneﬁts from RISC-V ISA. Targeting machine learning applications such as classiﬁcation and clustering, we have demonstrated that our processor reinforced with approximate operations can save power up to 23\% for ASIC implementation while at least 90\% top-1 accuracy is achieved on the trained models and test data set.},
	language = {en},
	number = {1},
	urldate = {2020-12-25},
	journal = {Electronics},
	author = {Taştan, İbrahim and Karaca, Mahmut and Yurdakul, Arda},
	month = jan,
	year = {2020},
	pages = {125},
}

@article{davidson_celerity_2018,
	title = {The {Celerity} {Open}-{Source} 511-{Core} {RISC}-{V} {Tiered} {Accelerator} {Fabric}: {Fast} {Architectures} and {Design} {Methodologies} for {Fast} {Chips}},
	volume = {38},
	issn = {0272-1732},
	shorttitle = {The {Celerity} {Open}-{Source} 511-{Core} {RISC}-{V} {Tiered} {Accelerator} {Fabric}},
	url = {https://ieeexplore.ieee.org/document/8344478/},
	doi = {10.1109/MM.2018.022071133},
	language = {en},
	number = {2},
	urldate = {2020-12-25},
	journal = {IEEE Micro},
	author = {Davidson, Scott and Xie, Shaolin and Torng, Christopher and Al-Hawai, Khalid and Rovinski, Austin and Ajayi, Tutu and Vega, Luis and Zhao, Chun and Zhao, Ritchie and Dai, Steve and Amarnath, Aporva and Veluri, Bandhav and Gao, Paul and Rao, Anuj and Liu, Gai and Gupta, Rajesh K. and Zhang, Zhiru and Dreslinski, Ronald and Batten, Christopher and Taylor, Michael Bedford},
	month = mar,
	year = {2018},
	pages = {30--41},
}

@inproceedings{wu_tick_2017,
	address = {Snowbird Utah USA},
	title = {The \textit{{Tick}} {Programmable} {Low}-{Latency} {SDR} {System}},
	isbn = {978-1-4503-4916-1},
	url = {https://dl.acm.org/doi/10.1145/3117811.3117834},
	doi = {10.1145/3117811.3117834},
	abstract = {Tick is a new SDR system that provides programmability and ensures low latency at both PHY and MAC. It supports modular design and element-based programming, similar to the Click router framework [23]. It uses an accelerator-rich architecture, where an embedded processor executes control flows and handles various MAC events. User-defined accelerators offload those tasks, which are either computation-intensive or communication-heavy, or require fine-grained timing control, from the processor, and accelerate them in hardware. Tick applies a number of hardware and software co-design techniques to ensure low latency, including multi-clockdomain pipelining, field-based processing pipeline, separation of data and control flows, etc. We have implemented Tick and validated its effectiveness through extensive evaluations as well as two prototypes of 802.11ac SISO/MIMO and 802.11a/g full-duplex.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 23rd {Annual} {International} {Conference} on {Mobile} {Computing} and {Networking}},
	publisher = {ACM},
	author = {Wu, Haoyang and Wang, Tao and Yuan, Zengwen and Peng, Chunyi and Li, Zhiwei and Tan, Zhaowei and Ding, Boyan and Li, Xiaoguang and Li, Yuanjie and Liu, Jun and Lu, Songwu},
	month = oct,
	year = {2017},
	pages = {101--113},
}

@article{taylor_celerity_nodate,
	title = {Celerity: {An} {Open} {Source} 511-core {RISC}-{V} {Tiered} {Accelerator} {Fabric}},
	language = {en},
	author = {Taylor, Michael},
	pages = {50},
}

@article{ajayi_celerity_nodate,
	title = {Celerity: {An} {Open} {Source} {RISC}-{V} {Tiered} {Accelerator} {Fabric}},
	language = {en},
	author = {Ajayi, Tutu and Al-Hawaj, Khalid and Amarnath, Aporva and Dai, Steve and Davidson, Scott and Gao, Paul and Liu, Gai and Lotfi, Atieh and Puscar, Julian and Rao, Anuj and Rovinski, Austin and Salem, Loai and Sun, Ningxiao and Torng, Christopher and Vega, Luis and Veluri, Bandhav and Wang, Xiaoyang and Xie, Shaolin and Zhao, Chun and Zhao, Ritchie},
	pages = {62},
}

@article{kim_evaluation_nodate,
	title = {Evaluation of {RISC}-{V} {RTL} with {FPGA}-{Accelerated} {Simulation}},
	abstract = {This paper presents a fast and accurate simulation methodology for performance, power, and energy evaluation in the hardware/software co-design flow. Cycle-level microarchitectural software simulation is the bottleneck of the hardware/software co-design cycle due to its slow speed and the difficulty of simulator validation. While sampling methodologies can ameliorate some of these challenges, we show that it is often insufficient for rigorous design evaluations. To circumvent the limitations of software simulation and sampling, we employ MIDAS, which automatically generates FPGA-accelerated simulators from RTL. These simulators are not only up to three orders-of-magnitude faster than existing microarchitectural software simulators, but also truly cycle-accurate, as the same RTL is used to build the silicon implementation. MIDAS builds on the work of Strober, namely by increasing simulator execution rate (up to tenfold) and by including an abstract L2 cache model to simulate more realistic systems without the corresponding RTL implementations. We simulated the productized, in-order processor, Rocket, and the industry-competitive, out-of-order processor, BOOM. To our knowledge, this is the first paper to present performance, power, and energy evaluations from RTL simulations running the whole SPEC2006int benchmark suite with its reference inputs.},
	language = {en},
	author = {Kim, Donggyu and Celio, Christopher and Biancolin, David and Bachrach, Jonathan and Asanovic, Krste},
	pages = {7},
}

@article{celio_open-source_nodate,
	title = {an open-source out-of-order {RISC}-{V} core},
	abstract = {This paper presents BOOM version 2, an updated version of the Berkeley Out-of-Order Machine first presented in [3]. The design exploration was performed through synthesis, place and route using the foundry-provided standard-cell library and the memory compiler in the TSMC 28 nm HPM process (high performance mobile).},
	language = {en},
	author = {Celio, Christopher and Chiu, Pi-Feng and Nikolic, Borivoje and Patterson, David and Asanovic, Krste},
	pages = {8},
}

@inproceedings{gray_grvi_2016,
	address = {Washington, DC, USA},
	title = {{GRVI} {Phalanx}: {A} {Massively} {Parallel} {RISC}-{V} {FPGA} {Accelerator} {Accelerator}},
	isbn = {978-1-5090-2356-1},
	shorttitle = {{GRVI} {Phalanx}},
	url = {http://ieeexplore.ieee.org/document/7544735/},
	doi = {10.1109/FCCM.2016.12},
	abstract = {GRVI is an FPGA-efficient RISC-V RV32I soft processor. Phalanx is a parallel processor and accelerator array framework. Groups of processors and accelerators form shared memory clusters. Clusters are interconnected with each other and with extreme bandwidth I/O and memory devices by a Hoplite NOC with 300-bit links. An example Kintex UltraScale 040 system has 400 RISC-V cores, peak throughput of 100,000 MIPS, peak shared memory bandwidth of 600 GB/s, NOC bisection bandwidth of 700 Gb/s, and uses 12-17 W.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2016 {IEEE} 24th {Annual} {International} {Symposium} on {Field}-{Programmable} {Custom} {Computing} {Machines} ({FCCM})},
	publisher = {IEEE},
	author = {Gray, Jan},
	month = may,
	year = {2016},
	pages = {17--20},
}

@article{gautschi_near-threshold_2017,
	title = {Near-{Threshold} {RISC}-{V} {Core} {With} {DSP} {Extensions} for {Scalable} {IoT} {Endpoint} {Devices}},
	volume = {25},
	issn = {1063-8210, 1557-9999},
	url = {https://ieeexplore.ieee.org/document/7864441/},
	doi = {10.1109/TVLSI.2017.2654506},
	abstract = {Endpoint devices for Internet-of-Things not only need to work under extremely tight power envelope of a few milliwatts, but also need to be ﬂexible in their computing capabilities, from a few kOPS to GOPS. Near-threshold (NT) operation can achieve higher energy efﬁciency, and the performance scalability can be gained through parallelism. In this paper, we describe the design of an open-source RISC-V processor core speciﬁcally designed for NT operation in tightly coupled multicore clusters. We introduce instruction extensions and microarchitectural optimizations to increase the computational density and to minimize the pressure toward the shared-memory hierarchy. For typical data-intensive sensor processing workloads, the proposed core is, on average, 3.5× faster and 3.2× more energy efﬁcient, thanks to a smart L0 buffer to reduce cache access contentions and support for compressed instructions. Single Instruction Multiple Data extensions, such as dot products, and a built-in L0 storage further reduce the shared-memory accesses by 8× reducing contentions by 3.2×. With four NT-optimized cores, the cluster is operational from 0.6 to 1.2 V, achieving a peak efﬁciency of 67 MOPS/mW in a low-cost 65-nm bulk CMOS technology. In a low-power 28-nm FD-SOI process, a peak efﬁciency of 193 MOPS/mW (40 MHz and 1 mW) can be achieved.},
	language = {en},
	number = {10},
	urldate = {2020-12-25},
	journal = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
	author = {Gautschi, Michael and Schiavone, Pasquale Davide and Traber, Andreas and Loi, Igor and Pullini, Antonio and Rossi, Davide and Flamand, Eric and Gurkaynak, Frank K. and Benini, Luca},
	month = oct,
	year = {2017},
	pages = {2700--2713},
}

@inproceedings{lee_45nm_2014,
	address = {Venice Lido, Italy},
	title = {A 45nm 1.{3GHz} 16.7 double-precision {GFLOPS}/{W} {RISC}-{V} processor with vector accelerators},
	isbn = {978-1-4799-5696-8 978-1-4799-5694-4},
	url = {https://ieeexplore.ieee.org/document/6942056},
	doi = {10.1109/ESSCIRC.2014.6942056},
	abstract = {A 64-bit dual-core RISC-V processor with vector accelerators has been fabricated in a 45 nm SOI process. This is the ﬁrst dual-core processor to implement the open-source RISC-V ISA designed at the University of California, Berkeley. In a standard 40 nm process, the RISC-V scalar core scores 10\% higher in DMIPS/MHz than the Cortex-A5, ARM’s comparable single-issue in-order scalar core, and is 49\% more area-efﬁcient. To demonstrate the extensibility of the RISC-V ISA, we integrate a custom vector accelerator alongside each single-issue in-order scalar core. The vector accelerator is 1.8× more energy-efﬁcient than the IBM Blue Gene/Q processor, and 2.6× more than the IBM Cell processor, both fabricated in the same process. The dual-core RISC-V processor achieves maximum clock frequency of 1.3 GHz at 1.2 V and peak energy efﬁciency of 16.7 doubleprecision GFLOPS/W at 0.65 V with an area of 3 mm2.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {{ESSCIRC} 2014 - 40th {European} {Solid} {State} {Circuits} {Conference} ({ESSCIRC})},
	publisher = {IEEE},
	author = {Lee, Yunsup and Waterman, Andrew and Avizienis, Rimas and Cook, Henry and Sun, Chen and Stojanovic, Vladimir and Asanovic, Krste},
	month = sep,
	year = {2014},
	pages = {199--202},
}

@inproceedings{parashar_timeloop_2019,
	address = {Madison, WI, USA},
	title = {Timeloop: {A} {Systematic} {Approach} to {DNN} {Accelerator} {Evaluation}},
	isbn = {978-1-72810-746-2},
	shorttitle = {Timeloop},
	url = {https://ieeexplore.ieee.org/document/8695666/},
	doi = {10.1109/ISPASS.2019.00042},
	abstract = {This paper presents Timeloop, an infrastructure for evaluating and exploring the architecture design space of deep neural network (DNN) accelerators. Timeloop uses a concise and uniﬁed representation of the key architecture and implementation attributes of DNN accelerators to describe a broad space of hardware topologies. It can then emulate those topologies to generate an accurate projection of performance and energy efﬁciency for a DNN workload through a mapper that ﬁnds the best way to schedule operations and stage data on the speciﬁed architecture. This enables fair comparisons across different architectures and makes DNN accelerator design more systematic. This paper describes Timeloop’s underlying models and algorithms in detail and shows results from case studies enabled by Timeloop, which provide interesting insights into the current state of DNN architecture design. In particular, they reveal that dataﬂow and memory hierarchy co-design plays a critical role in optimizing energy efﬁciency. Also, there is currently still not a single architecture that achieves the best performance and energy efﬁciency across a diverse set of workloads due to ﬂexibility and efﬁciency trade-offs. These results provide inspiration into possible directions for DNN accelerator research.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2019 {IEEE} {International} {Symposium} on {Performance} {Analysis} of {Systems} and {Software} ({ISPASS})},
	publisher = {IEEE},
	author = {Parashar, Angshuman and Raina, Priyanka and Shao, Yakun Sophia and Chen, Yu-Hsin and Ying, Victor A. and Mukkara, Anurag and Venkatesan, Rangharajan and Khailany, Brucek and Keckler, Stephen W. and Emer, Joel},
	month = mar,
	year = {2019},
	pages = {304--315},
}

@inproceedings{liu_rapid_2019,
	address = {Las Vegas NV USA},
	title = {Rapid {Generation} of {High}-{Quality} {RISC}-{V} {Processors} from {Functional} {Instruction} {Set} {Specifications}},
	isbn = {978-1-4503-6725-7},
	url = {https://dl.acm.org/doi/10.1145/3316781.3317890},
	doi = {10.1145/3316781.3317890},
	abstract = {The increasing popularity of compute acceleration for emerging domains such as artificial intelligence and computer vision has led to the growing need for domain-specific accelerators, often implemented as specialized processors that execute a set of domainoptimized instructions. The ability to rapidly explore (1) various possibilities of the customized instruction set, and (2) its corresponding micro-architectural features is critical to achieve the best quality-of-results (QoRs). However, this ability is frequently hindered by the manual design process at the register transfer level (RTL). Such an RTL-based methodology is often expensive and slow to react when the design specifications change at the instruction-set level and/or micro-architectural level.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 56th {Annual} {Design} {Automation} {Conference} 2019},
	publisher = {ACM},
	author = {Liu, Gai and Primmer, Joseph and Zhang, Zhiru},
	month = jun,
	year = {2019},
	pages = {1--6},
}

@article{waterman_risc-v_nodate,
	title = {The {RISC}-{V} {Instruction} {Set} {Manual} {Volume} {I}: {User}-{Level} {ISA}},
	language = {en},
	author = {Waterman, Andrew and Asanovic, Krste and Division, CS},
	pages = {145},
}

@misc{noauthor_rsvp-te_nodate,
	title = {{RSVP}-{TE} daemon for {DiffServ} over {MPLS} under {Linux}},
}

@misc{noauthor_xilinx_nodate,
	title = {Xilinx 7 {Series} {FPGA} {Libraries} {Guide} for {Schematic} {Designs} ({UG799})},
}

@misc{noauthor_xilinx_2012,
	title = {Xilinx 7 {Series} {FPGA} {Libraries} {Guide} for {HDL} {Designs} ({UG768})},
	year = {2012},
}

@article{noauthor_xilinx_2018,
	title = {Xilinx {Software} {Command}-{Line} {Tools} ({XSCT}): {Reference} {Guide} ({UG1208})},
	language = {en},
	year = {2018},
	pages = {113},
}

@article{noauthor_vivado_2020,
	title = {Vivado {Design} {Suite} {User} {Guide}: {Creating} and {Packaging} {Custom} {IP} ({UG1118})},
	language = {en},
	year = {2020},
	pages = {113},
}

@article{noauthor_zynq_2019,
	title = {Zynq {UltraScale}+ {Device} {Technical} {Reference} {Manual}},
	abstract = {Loading Bitstreams, Figure 12-17, and Secure Boot Image Format. Added Device DNA Identifiers, Initialization Vector Register, Secure Non-Volatile Storage, and Enhanced SPK Revocation. Added note to Table 12-13. Chapter 13: Revised SPI Interrupt Sensitivity. Chapter 14: Revised TTC Counter Features, TTC Block Diagram, Table 14-11, and Table 14-12. Chapter 15: Revised. Chapter 16: Revised TBU Instances. Chapter 17: Table 17-1, Table 17-2 table note added, and added a note after the third item in ECC Poisoning Multi-Purpose Register (DDR4 Only). Chapter 20: Revised. Chapter 21: Revised. Chapter 22: Revised Configure Clocks Chapter 23: Revised Table 23-2, Figure 23-1, FIFOs, and Clocks, Resets. Chapter 24: Revised Clocks and Resets, Table 24-3, Table 24-4, Table 24-21, Table 24-22, Table 24-23, and Table 24-32. Chapter 26: Revised Reference Clock, Interface Controller, DLL Clock Mode, Transmit CMD/DAT Delay, Receive Clock Tap Delay, Table 26-7, Table 26-12, Table 26-15, Table 26-16, and Table 26-23. Chapter 27: Figure 27-2 updated. Chapter 28: Default Logic Levels revised. Chapter 31: Device Programming revised. Chapter 33: Figure 33-1 and Figure 33-18 updated. Chapter 34: Configure the PHY revised. Chapter 37: Revised Figure 37-1, Figure 37-2, Figure 37-4, and Figure 37-5. Chapter 38: Revised Table 38-3 and FPD Reset Sequence.},
	language = {en},
	year = {2019},
	pages = {1177},
}

@article{noauthor_zynq_2020,
	title = {Zynq {UltraScale}+ {Device} {Packaging} and {Pinouts} {Product} {Specification} {User} {Guide}},
	language = {en},
	year = {2020},
	pages = {265},
}

@article{noauthor_ultrascale_2018,
	title = {{UltraScale} {Architecture} {Libraries} {Guide} ({UG974})},
	language = {en},
	year = {2018},
	pages = {661},
}

@article{noauthor_ultrascale_2020,
	title = {{UltraScale} {Architecture} {Configuration} {User} {Guide}},
	language = {en},
	year = {2020},
	pages = {224},
}

@article{noauthor_7_2018,
	title = {7 {Series} {FPGAs} {SelectIO} {Resources} {User} {Guide} ({UG471})},
	language = {en},
	year = {2018},
	pages = {188},
}

@article{noauthor_7_2018-1,
	title = {7 {Series} {FPGAs} {Configuration} {User} {Guide} ({UG470})},
	language = {en},
	year = {2018},
	pages = {180},
}

@article{parberryy_how_nodate,
	title = {How to {Present} a {Paper} in {Theoretical} {Computer} {Science}: {A} {Speaker}'s {Guide} for {Students}},
	language = {en},
	author = {Parberryy, Ian},
	pages = {12},
}

@article{xu_openpiton_nodate,
	title = {{OpenPiton}: {An} {Open} {Source} {Manycore} {Research} {Framework}},
	language = {en},
	author = {Xu, Pengcheng},
	pages = {21},
}

@inproceedings{mckeown_power_2018,
	address = {Vienna},
	title = {Power and {Energy} {Characterization} of an {Open} {Source} 25-{Core} {Manycore} {Processor}},
	isbn = {978-1-5386-3659-6},
	url = {http://ieeexplore.ieee.org/document/8327053/},
	doi = {10.1109/HPCA.2018.00070},
	abstract = {The end of Dennard’s scaling and the looming power wall have made power and energy primary design goals for modern processors. Further, new applications such as cloud computing and Internet of Things (IoT) continue to necessitate increased performance and energy efﬁciency. Manycore processors show potential in addressing some of these issues. However, there is little detailed power and energy data on manycore processors. In this work, we carefully study detailed power and energy characteristics of Piton, a 25-core modern open source academic processor, including voltage versus frequency scaling, energy per instruction (EPI), memory system energy, network-on-chip (NoC) energy, thermal characteristics, and application performance and power consumption. This is the ﬁrst detailed power and energy characterization of an open source manycore design implemented in silicon. The open source nature of the processor provides increased value, enabling detailed characterization veriﬁed against simulation and the ability to correlate results with the design and register transfer level (RTL) model. Additionally, this enables other researchers to utilize this work to build new power models, devise new research directions, and perform accurate power and energy research using the open source processor. The characterization data reveals a number of interesting insights, including that operand values have a large impact on EPI, recomputing data can be more energy efﬁcient than loading it from memory, on-chip data transmission (NoC) energy is low, and insights on energy efﬁcient multithreaded core design. All data collected and the hardware infrastructure used is open source and available for download at http://www.openpiton.org.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2018 {IEEE} {International} {Symposium} on {High} {Performance} {Computer} {Architecture} ({HPCA})},
	publisher = {IEEE},
	author = {McKeown, Michael and Lavrov, Alexey and Shahrad, Mohammad and Jackson, Paul J. and Fu, Yaosheng and Balkind, Jonathan and Nguyen, Tri M. and Lim, Katie and Zhou, Yanqi and Wentzlaff, David},
	month = feb,
	year = {2018},
	pages = {762--775},
}

@article{noauthor_ultrascale_2020-1,
	title = {{UltraScale} {Architecture}-{Based} {FPGAs} {Memory} {IP} v1.4 {LogiCORE} {IP} {Product} {Guide}},
	year = {2020},
	pages = {817},
}

@article{gu_certikos_nodate,
	title = {{CertiKOS}: {An} {Extensible} {Architecture} for {Building} {Certiﬁed} {Concurrent} {OS} {Kernels}},
	abstract = {Complete formal veriﬁcation of a non-trivial concurrent OS kernel is widely considered a grand challenge. We present a novel compositional approach for building certiﬁed concurrent OS kernels. Concurrency allows interleaved execution of kernel/user modules across different layers of abstraction. Each such layer can have a different set of observable events. We insist on formally specifying these layers and their observable events, and then verifying each kernel module at its proper abstraction level. To support certiﬁed linking with other CPUs or threads, we prove a strong contextual reﬁnement property for every kernel function, which states that the implementation of each such function will behave like its speciﬁcation under any kernel/user context with any valid interleaving. We have successfully developed a practical concurrent OS kernel and veriﬁed its (contextual) functional correctness in Coq. Our certiﬁed kernel is written in 6500 lines of C and x86 assembly and runs on stock x86 multicore machines. To our knowledge, this is the ﬁrst proof of functional correctness of a complete, general-purpose concurrent OS kernel with ﬁne-grained locking.},
	language = {en},
	author = {Gu, Ronghui and Shao, Zhong and Chen, Hao and Kim, Jieung and Sjoberg, Vilhelm},
	pages = {19},
}

@article{xu_how_nodate,
	title = {How {Hard} {Can} {It} {Be}? {Designing} and {Implementing} a {Deployable} {Multipath} {TCP} - {Review} from a {Student} in {Computer} {Networks}},
	language = {en},
	author = {Xu, Pengcheng},
	pages = {1},
}

@article{rangan_thread_nodate,
	title = {Thread {Motion}: {Fine}-{Grained} {Power} {Management} for {Multi}-{Core} {Systems}},
	abstract = {Dynamic voltage and frequency scaling (DVFS) is a commonly-used powermanagement scheme that dynamically adjusts power and performance to the time-varying needs of running programs. Unfortunately, conventional DVFS, relying on off-chip regulators, faces limitations in terms of temporal granularity and high costs when considered for future multi-core systems. To overcome these challenges, this paper presents thread motion (TM), a ﬁne-grained power-management scheme for chip multiprocessors (CMPs). Instead of incurring the high cost of changing the voltage and frequency of different cores, TM enables rapid movement of threads to adapt the timevarying computing needs of running applications to a mixture of cores with ﬁxed but different power/performance levels. Results show that for the same power budget, two voltage/frequency levels are sufﬁcient to provide performance gains commensurate to idealized scenarios using per-core voltage control. Thread motion extends workload-based power management into the nanosecond realm and, for a given power budget, provides up to 20\% better performance than coarse-grained DVFS.},
	language = {en},
	author = {Rangan, Krishna K and Wei, Gu-Yeon and Brooks, David},
	pages = {12},
}

@article{guo_cde_nodate,
	title = {{CDE}: {Using} {System} {Call} {Interposition} to {Automatically} {Create} {Portable} {Software} {Packages}},
	abstract = {It can be painfully hard to take software that runs on one person’s machine and get it to run on another machine. Online forums and mailing lists are ﬁlled with discussions of users’ troubles with compiling, installing, and conﬁguring software and their myriad of dependencies. To eliminate this dependency problem, we created a system called CDE that uses system call interposition to monitor the execution of x86-Linux programs and package up the Code, Data, and Environment required to run them on other x86-Linux machines. Creating a CDE package is completely automatic, and running programs within a package requires no installation, conﬁguration, or root permissions. Hundreds of people in both academia and industry have used CDE to distribute software, demo prototypes, make their scientiﬁc experiments reproducible, run software natively on older Linux distributions, and deploy experiments to compute clusters.},
	language = {en},
	author = {Guo, Philip J and Engler, Dawson},
	pages = {6},
}

@article{noauthor_sifive_nodate,
	title = {{SiFive} {FU540}-{C000} {Manual}: v1p0},
	language = {en},
	pages = {144},
}

@inproceedings{josipovic_invited_2020,
	address = {Seaside CA USA},
	title = {Invited {Tutorial}: {Dynamatic}: {From} {C}/{C}++ to {Dynamically} {Scheduled} {Circuits}},
	isbn = {978-1-4503-7099-8},
	shorttitle = {Invited {Tutorial}},
	url = {https://dl.acm.org/doi/10.1145/3373087.3375391},
	doi = {10.1145/3373087.3375391},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 2020 {ACM}/{SIGDA} {International} {Symposium} on {Field}-{Programmable} {Gate} {Arrays}},
	publisher = {ACM},
	author = {Josipović, Lana and Guerrieri, Andrea and Ienne, Paolo},
	month = feb,
	year = {2020},
	pages = {1--10},
}

@inproceedings{cheng_combining_2020,
	address = {Seaside CA USA},
	title = {Combining {Dynamic} \& {Static} {Scheduling} in {High}-level {Synthesis}},
	isbn = {978-1-4503-7099-8},
	url = {https://dl.acm.org/doi/10.1145/3373087.3375297},
	doi = {10.1145/3373087.3375297},
	abstract = {A central task in high-level synthesis is scheduling: the allocation of operations to clock cycles. The classic approach to scheduling is static, in which each operation is mapped to a clock cycle at compile-time, but recent years have seen the emergence of dynamic scheduling, in which an operation’s clock cycle is only determined at run-time. Both approaches have their merits: static scheduling can lead to simpler circuitry and more resource sharing, while dynamic scheduling can lead to faster hardware when the computation has non-trivial control flow. In this work, we seek a scheduling approach that combines the best of both worlds. Our idea is to identify the parts of the input program where dynamic scheduling does not bring any performance advantage and to use static scheduling on those parts. These statically-scheduled parts are then treated as black boxes when creating a dataflow circuit for the remainder of the program which can benefit from the flexibility of dynamic scheduling.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 2020 {ACM}/{SIGDA} {International} {Symposium} on {Field}-{Programmable} {Gate} {Arrays}},
	publisher = {ACM},
	author = {Cheng, Jianyi and Josipovic, Lana and Constantinides, George A. and Ienne, Paolo and Wickerson, John},
	month = feb,
	year = {2020},
	pages = {288--298},
}

@article{xu_depkit_nodate,
	title = {{DepKit}: {A} {Typed} {Language} for {Advanced} {Package} {Management}},
	abstract = {Package management is one of the most important functionalities of an operating system: it allows the administrator to easily manage the software installed on a system. However, lying at the core is the dependency resolution problem, which is never an easy task: it has been hard to find a balance point between flexibility provided to the users and complexity of the dependency system. In this work we present DepKit, a typed language design and implementation to solve the an advanced form of package management, which offers great flexibility for both software vendors and system administrators. The implementation based on Z3 SMT solver shows that the language is capable of solving real-world problems.},
	language = {en},
	author = {Xu, Pengcheng and Guan, Zhichao},
	pages = {5},
}

@article{cook_diplomatic_2017,
	title = {Diplomatic {Design} {Patterns}: {A} {TileLink} {Case} {Study}},
	abstract = {Modern systems-on-chip (SoCs) incorporate a large and growing number of specialized hardware units that must be integrated into a unified address space via a shared bus topology. This process is labor-intensive and error-prone because the interface requirements of all connected blocks must be mutually satisfied. The design productivity gains derived from the modularity of RISC-V are bottlenecked by the need to integrate the cross product of processor variants, bus ordering behaviors, and slave device capabilities. This growing complexity has stimulated development of new tools and methodologies to enable the completion of complex and parameterized SoC designs. We present two tools used to create correctby-construction interconnects in the Rocket Chip generator: Diplomacy is a parameter negotiation framework for generating parameterized protocol implementations. Beyond confirming the mutual compatibility of the system endpoints, Diplomacy enables them to specialize themselves based on knowledge of the other endpoints included in a particular system. TileLink is a highlyparameterized chip-scale shared-memory interconnect standard. The implementation of TileLink in the Rocket chip generator exploits Diplomacy to specialize the interconnect to different levels of protocol conformance.},
	language = {en},
	author = {Cook, Henry and Terpstra, Wesley and Lee, Yunsup},
	year = {2017},
	pages = {7},
}

@article{xu_build_nodate,
	title = {Build {Your} {Own} {Networking} {Stack}},
	language = {en},
	author = {Xu, Pengcheng},
	pages = {29},
}

@article{ionescu_battle_nodate,
	title = {Battle of {SKM} and {IUM}},
	language = {en},
	author = {Ionescu, Alex and Srl, Cloudbase Solutions},
	pages = {65},
}

@article{xu_automatic_nodate,
	title = {Automatic {Code} {Generation} for {Rocket} {Chip} {RoCC} {Accelerators} {Fourth} {Workshop} on {Computer} {Architecture} {Research} with {RISC}-{V} ({CARRV} 2020)},
	language = {en},
	author = {Xu, Pengcheng},
	pages = {26},
}

@article{noauthor_amba_2003,
	title = {{AMBA} 3 {APB} {Protocol} {Specification}},
	language = {en},
	year = {2003},
	pages = {34},
}

@inproceedings{minutoli_soda_2020,
	address = {Virtual Event USA},
	title = {{SODA}: a new synthesis infrastructure for agile hardware design of machine learning accelerators},
	isbn = {978-1-4503-8026-3},
	shorttitle = {{SODA}},
	url = {https://dl.acm.org/doi/10.1145/3400302.3415781},
	doi = {10.1145/3400302.3415781},
	abstract = {Next-generation systems, such as edge devices, will have to provide efficient processing of machine learning (ML) algorithms, along with several metrics, including energy, performance, area, and latency. However, the quickly evolving field of ML makes it extremely difficult to generate accelerators able to support a wide variety of algorithms. Simultaneously, designing accelerators in hardware description languages (HDLs) by hand is laborious and time-consuming, and does not allow quick exploration of the design space. This paper discusses the SODA synthesizer, an automated open-source high-level ML framework-to-Verilog compiler targeting ML Application-Specific Integrated Circuits (ASICs) chiplets based on the LLVM infrastructure. The SODA synthesizers will allow implementing optimal designs by combining templated and fully tunable IPs and macros, and fully custom components generated through high-level synthesis. All these components will be provided through an extendable resource library, characterized by commercial and open-source logic design flows. Through a closedloop design space exploration engine, developers will quickly explore their hardware designs along different dimensions.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Computer}-{Aided} {Design}},
	publisher = {ACM},
	author = {Minutoli, Marco and Castellana, Vito Giovanni and Tan, Cheng and Manzano, Joseph and Amatya, Vinay and Tumeo, Antonino and Brooks, David and Wei, Gu-Yeon},
	month = nov,
	year = {2020},
	pages = {1--7},
}

@article{siracusa_tensor_2020,
	title = {Tensor {Optimization} for {High}-{Level} {Synthesis} {Design} {Flows}},
	volume = {39},
	issn = {0278-0070, 1937-4151},
	url = {https://ieeexplore.ieee.org/document/9211479/},
	doi = {10.1109/TCAD.2020.3012318},
	abstract = {Improving data locality of tensor data structures is a crucial optimization for maximizing the performance of machine learning and intensive linear algebra applications. While CPUs and GPUs improve data locality by means of automated caching mechanisms, FPGAs let the developer specify data structure allocation. Although this feature enables a high degree of customizability, the increasing complexity and memory footprint of modern applications prevent considering any manual approach to ﬁnd an optimal allocation. For this reason, we propose a compiler optimization to automatically improve the tensor allocation of high-level software descriptions. The optimization is controlled by a ﬂexible cost model that can be tuned by means of simple yet expressive callback functions. In this way, the user can tailor the optimization strategy with respect to the optimization goal. We tested our methodology integrating our optimization in the Bambu open-source HLS framework. In this setting, we achieved a 14\% speedup on the digit recognition version proposed by the Rosetta benchmark. Moreover, we tested our optimization on the CHStone benchmark suite, achieving an average of 6\% speedup. Finally, we applied our methodology on two industrial examples from the aerospace domain obtaining a 15\% speedup. As a ﬁnal step, we tested the versatility of our methodology inserting our optimization in the Clang software optimization ﬂow achieving a 12\% speedup on the Rosetta benchmark when running on CPU.},
	language = {en},
	number = {11},
	urldate = {2020-12-25},
	journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {Siracusa, Marco and Ferrandi, Fabrizio},
	month = nov,
	year = {2020},
	pages = {4217--4228},
}

@article{balkind_openpiton_2020,
	title = {{OpenPiton} at 5: {A} {Nexus} for {Open} and {Agile} {Hardware} {Design}},
	volume = {40},
	issn = {0272-1732, 1937-4143},
	shorttitle = {{OpenPiton} at 5},
	url = {https://ieeexplore.ieee.org/document/9099948/},
	doi = {10.1109/MM.2020.2997706},
	abstract = {For ﬁve years, OpenPiton has provided hardware designs, build and veriﬁcation scripts, and other infrastructure to enable efﬁcient, detailed research into manycores and systems-on-chip. It enables open-source hardware development through its open design and support of a plethora of open simulators and CAD tools. OpenPiton was ﬁrst designed to perform cutting-edge computer architecture research at Princeton University and opening it up to the public has led to thousands of downloads and numerous academic publications spanning many subﬁelds within computing. In this article, we share some of the lessons learned during the development of OpenPiton, provide examples of how OpenPiton has been used to efﬁciently test novel research ideas, and discuss how OpenPiton has evolved due to its open development and feedback from the open-source community.},
	language = {en},
	number = {4},
	urldate = {2020-12-25},
	journal = {IEEE Micro},
	author = {Balkind, Jonathan and Chang, Ting-Jung and Jackson, Paul J. and Tziantzioulis, Georgios and Li, Ang and Gao, Fei and Lavrov, Alexey and Chirkov, Grigory and Tu, Jinzheng and Shahrad, Mohammad and Wentzlaff, David},
	month = jul,
	year = {2020},
	pages = {22--31},
}

@inproceedings{ravi_open_2016,
	address = {Chennai},
	title = {Open source {HLS} tools: {A} stepping stone for modern electronic {CAD}},
	isbn = {978-1-5090-0612-0},
	shorttitle = {Open source {HLS} tools},
	url = {http://ieeexplore.ieee.org/document/7919615/},
	doi = {10.1109/ICCIC.2016.7919615},
	abstract = {This paper presents a comprehensive survey on commonly used High-Level synthesis (HLS) tools that are available as open source. The HLS tools considered in this paper include Bambu, GAUT, Icarus Verilog, LegUp, and MyHDL. This paper also presents the process steps involved in each tool in detail and the major issues and challenges that are to be addressed in these tools in order to make the tools to become the most suitable choice for modern electronic system design.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2016 {IEEE} {International} {Conference} on {Computational} {Intelligence} and {Computing} {Research} ({ICCIC})},
	publisher = {IEEE},
	author = {Ravi, S. and Joseph, M.},
	month = dec,
	year = {2016},
	pages = {1--8},
}

@inproceedings{cota_analysis_2015,
	address = {San Francisco California},
	title = {An {Analysis} of {Accelerator} {Coupling} in {Heterogeneous} {Architectures}},
	isbn = {978-1-4503-3520-1},
	url = {https://dl.acm.org/doi/10.1145/2744769.2744794},
	doi = {10.1145/2744769.2744794},
	abstract = {Existing research on accelerators has emphasized the performance and energy eﬃciency improvements they can provide, devoting little attention to practical issues such as accelerator invocation and interaction with other on-chip components (e.g. cores, caches). In this paper we present a quantitative study that considers these aspects by implementing seven high-throughput accelerators following three design models: tight coupling behind a CPU, loose out-of-core coupling with Direct Memory Access (DMA) to the LLC, and loose out-of-core coupling with DMA to DRAM. A salient conclusion of our study is that working sets of non-trivial size are best served by loosely-coupled accelerators that integrate private memory blocks tailored to their needs.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 52nd {Annual} {Design} {Automation} {Conference}},
	publisher = {ACM},
	author = {Cota, Emilio G. and Mantovani, Paolo and Di Guglielmo, Giuseppe and Carloni, Luca P.},
	month = jun,
	year = {2015},
	pages = {1--6},
}

@inproceedings{bhardwaj_comprehensive_2020,
	address = {Boston Massachusetts},
	title = {A comprehensive methodology to determine optimal coherence interfaces for many-accelerator {SoCs}},
	isbn = {978-1-4503-7053-0},
	url = {https://dl.acm.org/doi/10.1145/3370748.3406564},
	doi = {10.1145/3370748.3406564},
	abstract = {Modern systems-on-chip (SoCs) include not only general-purpose CPUs but also specialized hardware accelerators. Typically, there are three coherence model choices to integrate an accelerator with the memory hierarchy: no coherence, coherent with the last-level cache (LLC), and private cache based full coherence. However, there has been very limited research on finding which coherence models are optimal for the accelerators of a complex many-accelerator SoC. This paper focuses on determining a cost-aware coherence interface for an SoC and its target application: find the best coherence models for the accelerators that optimize their power and performance, considering both workload characteristics and system-level contention. A novel comprehensive methodology is proposed that uses Bayesian optimization to efficiently find the cost-aware coherence interfaces for SoCs that are modeled using the gem5-Aladdin architectural simulator. For a complete analysis, gem5-Aladdin is extended to support LLC coherence in addition to already-supported no coherence and full coherence. For a heterogeneous SoC targeting applications with varying amount of accelerator-level parallelism, the proposed framework rapidly finds cost-aware coherence interfaces that show significant performance and power benefits over the other commonly-used coherence interfaces.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the {ACM}/{IEEE} {International} {Symposium} on {Low} {Power} {Electronics} and {Design}},
	publisher = {ACM},
	author = {Bhardwaj, Kshitij and Havasi, Marton and Yao, Yuan and Brooks, David M. and Hernández-Lobato, José Miguel and Wei, Gu-Yeon},
	month = aug,
	year = {2020},
	pages = {145--150},
}

@inproceedings{josipovic_dynamically_2018,
	address = {Monterey CALIFORNIA USA},
	title = {Dynamically {Scheduled} {High}-level {Synthesis}},
	isbn = {978-1-4503-5614-5},
	url = {https://dl.acm.org/doi/10.1145/3174243.3174264},
	doi = {10.1145/3174243.3174264},
	abstract = {High-level synthesis (HLS) tools almost universally generate statically scheduled datapaths. Static scheduling implies that circuits out of HLS tools have a hard time exploiting parallelism in code with potential memory dependencies, with control-dependent dependencies in inner loops, or where performance is limited by long latency control decisions. The situation is essentially the same as in computer architecture between Very-Long Instruction Word (VLIW) processors and dynamically scheduled superscalar processors; the former display the best performance per cost in highly regular embedded applications, but general purpose, irregular, and controldominated computing tasks require the runtime flexibility of dynamic scheduling. In this work, we show that high-level synthesis of dynamically scheduled circuits is perfectly feasible by describing the implementation of a prototype synthesizer which generates a particular form of latency-insensitive synchronous circuits. Compared to a commercial HLS tool, the result is a different trade-off between performance and circuit complexity, much as superscalar processors represent a different trade-off compared to VLIW processors: in demanding applications, the performance is very significantly improved at an affordable cost. We here demonstrate only the first steps towards more performant high-level synthesis tools adapted to emerging FPGA applications and the demands of computing in broader application domains.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 2018 {ACM}/{SIGDA} {International} {Symposium} on {Field}-{Programmable} {Gate} {Arrays}},
	publisher = {ACM},
	author = {Josipović, Lana and Ghosal, Radhika and Ienne, Paolo},
	month = feb,
	year = {2018},
	pages = {127--136},
}

@article{canis_legup_2013,
	title = {{LegUp}: {An} open-source high-level synthesis tool for {FPGA}-based processor/accelerator systems},
	volume = {13},
	issn = {1539-9087, 1558-3465},
	shorttitle = {{LegUp}},
	url = {https://dl.acm.org/doi/10.1145/2514740},
	doi = {10.1145/2514740},
	language = {en},
	number = {2},
	urldate = {2020-12-25},
	journal = {ACM Transactions on Embedded Computing Systems},
	author = {Canis, Andrew and Choi, Jongsok and Aldham, Mark and Zhang, Victor and Kammoona, Ahmed and Czajkowski, Tomasz and Brown, Stephen D. and Anderson, Jason H.},
	month = sep,
	year = {2013},
	pages = {1--27},
}

@inproceedings{cong_efficient_2006,
	address = {San Francisco, CA, USA},
	title = {An efficient and versatile scheduling algorithm based on {SDC} formulation},
	isbn = {978-1-59593-381-2},
	url = {http://portal.acm.org/citation.cfm?doid=1146909.1147025},
	doi = {10.1145/1146909.1147025},
	abstract = {Scheduling plays a central role in the behavioral synthesis process, which automatically compiles high-level specifications into optimized hardware implementations. However, most of the existing behavior-level scheduling heuristics either have a limited efficiency in a specific class of applications or lack general support of various design constraints, In this paper we describe a new scheduler that converts a rich set of scheduling constraints into a system of difference constraints (SDC) and performs a variety of powerful optimizations under a unified mathematical programming framework. In particular, we show that our SDC-based scheduling algorithm can efficiently support resource constraints, frequency constraints, latency constraints, and relative timing constraints, and effectively optimize longest path latency, expected overall latency, and the slack distribution. Experiments demonstrate that our proposed technique provides efficient solutions for a broader range of applications with higher quality of results (in terms of system performance) when compared to the state-of-the-art scheduling heuristics.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 43rd annual conference on {Design} automation  - {DAC} '06},
	publisher = {ACM Press},
	author = {Cong, Jason and Zhang, Zhiru},
	year = {2006},
	pages = {433},
}

@inproceedings{hempstead_ultra_2005,
	address = {Madison, WI, USA},
	title = {An {Ultra} {Low} {Power} {System} {Architecture} for {Sensor} {Network} {Applications}},
	isbn = {978-0-7695-2270-8},
	url = {http://ieeexplore.ieee.org/document/1431558/},
	doi = {10.1109/ISCA.2005.12},
	abstract = {Recent years have seen a burgeoning interest in embedded wireless sensor networks with applications ranging from habitat monitoring to medical applications. Wireless sensor networks have several important attributes that require special attention to device design. These include the need for inexpensive, long-lasting, highly reliable devices coupled with very low performance requirements. Ultimately, the “holy grail” of this design space is a truly untethered device that operates off of energy scavenged from the ambient environment. In this paper, we describe an application-driven approach to the architectural design and implementation of a wireless sensor device that recognizes the event-driven nature of many sensor-network workloads. We have developed a full-system simulator for our sensor node design to verify and explore our architecture. Our simulation results suggest one to two orders of magnitude reduction in power dissipation over existing commoditybased systems for an important class of sensor network applications. We are currently in the implementation stage of design, and plan to tape out the ﬁrst version of our system within the next year.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {32nd {International} {Symposium} on {Computer} {Architecture} ({ISCA}'05)},
	publisher = {IEEE},
	author = {Hempstead, M. and Tripathi, N. and Mauro, P. and {Gu-Yeon Wei} and Brooks, D.},
	year = {2005},
	pages = {208--219},
}

@inproceedings{yang_graphabcd_2020,
	address = {Valencia, Spain},
	title = {{GraphABCD}: {Scaling} {Out} {Graph} {Analytics} with {Asynchronous} {Block} {Coordinate} {Descent}},
	isbn = {978-1-72814-661-4},
	shorttitle = {{GraphABCD}},
	url = {https://ieeexplore.ieee.org/document/9138946/},
	doi = {10.1109/ISCA45697.2020.00043},
	abstract = {It is of vital importance to efﬁciently process large graphs for many data-intensive applications. As a result, a large collection of graph analytic frameworks has been proposed to improve the per-iteration performance on a single kind of computation resource. However, heavy coordination and synchronization overhead make it hard to scale out graph analytic frameworks from single platform to heterogeneous platforms. Furthermore, increasing the convergence rate, i.e. reducing the number of iterations, which is equally vital for improving the overall performance of iterative graph algorithms, receives much less attention.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {2020 {ACM}/{IEEE} 47th {Annual} {International} {Symposium} on {Computer} {Architecture} ({ISCA})},
	publisher = {IEEE},
	author = {Yang, Yifan and Li, Zhaoshi and Deng, Yangdong and Liu, Zhiwei and Yin, Shouyi and Wei, Shaojun and Liu, Leibo},
	month = may,
	year = {2020},
	pages = {419--432},
}

@article{mcfarland_high-level_1990,
	title = {The high-level synthesis of digital systems},
	volume = {78},
	issn = {00189219},
	url = {http://ieeexplore.ieee.org/document/52214/},
	doi = {10.1109/5.52214},
	language = {en},
	number = {2},
	urldate = {2020-12-25},
	journal = {Proceedings of the IEEE},
	author = {McFarland, M.C. and Parker, A.C. and Camposano, R.},
	month = feb,
	year = {1990},
	pages = {301--318},
}

@article{reagen_cheetah_2020,
	title = {Cheetah: {Optimizing} and {Accelerating} {Homomorphic} {Encryption} for {Private} {Inference}},
	shorttitle = {Cheetah},
	url = {http://arxiv.org/abs/2006.00505},
	abstract = {As the application of deep learning continues to grow, so does the amount of data used to make predictions. While traditionally, big-data deep learning was constrained by computing performance and off-chip memory bandwidth, a new constraint has emerged: privacy. One solution is homomorphic encryption (HE). Applying HE to the client-cloud model allows cloud services to perform inference directly on the client’s encrypted data. While HE can meet privacy constraints, it introduces enormous computational challenges and remains impractically slow in current systems.},
	language = {en},
	urldate = {2020-12-25},
	journal = {arXiv:2006.00505 [cs]},
	author = {Reagen, Brandon and Choi, Wooseok and Ko, Yeongil and Lee, Vincent and Wei, Gu-Yeon and Lee, Hsien-Hsin S. and Brooks, David},
	month = oct,
	year = {2020},
	note = {arXiv: 2006.00505},
	keywords = {Computer Science - Cryptography and Security},
}

@article{lim_juxtapiton_2018,
	title = {{JuxtaPiton}: {Enabling} {Heterogeneous}-{ISA} {Research} with {RISC}-{V} and {SPARC} {FPGA} {Soft}-cores},
	shorttitle = {{JuxtaPiton}},
	url = {http://arxiv.org/abs/1811.08091},
	abstract = {Energy efficiency has become an increasingly important concern in computer architecture due to the end of Dennard scaling. Heterogeneity has been explored as a way to achieve better energy efficiency and heterogeneous microarchitecture chips have become common in the mobile setting.},
	language = {en},
	urldate = {2020-12-25},
	journal = {arXiv:1811.08091 [cs]},
	author = {Lim, Katie and Balkind, Jonathan and Wentzlaff, David},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.08091},
	keywords = {Computer Science - Hardware Architecture},
}

@article{moreau_hardware-software_2019,
	title = {A {Hardware}-{Software} {Blueprint} for {Flexible} {Deep} {Learning} {Specialization}},
	url = {http://arxiv.org/abs/1807.04188},
	abstract = {Specialized Deep Learning (DL) acceleration stacks, designed for a speciﬁc set of frameworks, model architectures, operators, and data types, offer the allure of high performance while sacriﬁcing ﬂexibility. Changes in algorithms, models, operators, or numerical systems threaten the viability of specialized hardware accelerators. We propose VTA, a programmable deep learning architecture template designed to be extensible in the face of evolving workloads. VTA achieves this ﬂexibility via a parametrizable architecture, two-level ISA, and a JIT compiler. The two-level ISA is based on (1) a task-ISA that explicitly orchestrates concurrent compute and memory tasks and (2) a microcode-ISA which implements a wide variety of operators with single-cycle tensor-tensor operations. Next, we propose a runtime system equipped with a JIT compiler for ﬂexible code-generation and heterogeneous execution that enables effective use of the VTA architecture. VTA is integrated and open-sourced into Apache TVM, a state-ofthe-art deep learning compilation stack that provides ﬂexibility for diverse models and divergent hardware backends. We propose a ﬂow that performs design space exploration to generate a customized hardware architecture and software operator library that can be leveraged by mainstream learning frameworks. We demonstrate our approach by deploying optimized deep learning models used for object classiﬁcation and style transfer on edge-class FPGAs.},
	language = {en},
	urldate = {2020-12-25},
	journal = {arXiv:1807.04188 [cs, stat]},
	author = {Moreau, Thierry and Chen, Tianqi and Vega, Luis and Roesch, Jared and Yan, Eddie and Zheng, Lianmin and Fromm, Josh and Jiang, Ziheng and Ceze, Luis and Guestrin, Carlos and Krishnamurthy, Arvind},
	month = apr,
	year = {2019},
	note = {arXiv: 1807.04188},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{tripp_trident_2007,
	title = {Trident: {From} {High}-{Level} {Language} to {Hardware} {Circuitry}},
	volume = {40},
	issn = {0018-9162},
	shorttitle = {Trident},
	url = {http://ieeexplore.ieee.org/document/4133993/},
	doi = {10.1109/MC.2007.107},
	language = {en},
	number = {3},
	urldate = {2020-12-25},
	journal = {Computer},
	author = {Tripp, Justin L. and Gokhale, Maya B. and Peterson, Kristopher D.},
	month = mar,
	year = {2007},
	pages = {28--37},
}

@inproceedings{yan_translation_2019,
	address = {Phoenix Arizona},
	title = {Translation ranger: operating system support for contiguity-aware {TLBs}},
	isbn = {978-1-4503-6669-4},
	shorttitle = {Translation ranger},
	url = {https://dl.acm.org/doi/10.1145/3307650.3322223},
	doi = {10.1145/3307650.3322223},
	abstract = {Virtual memory (VM) eases programming effort but can suffer from high address translation overheads. Architects have traditionally coped by increasing Translation Lookaside Buffer (TLB) capacity; this approach, however, requires considerable hardware resources. One promising alternative is to rely on software-generated translation contiguity to compress page translation encodings within the TLB. To enable this, operating systems (OSes) have to assign spatially-adjacent groups of physical frames to contiguous groups of virtual pages, as doing so allows compression or coalescing of these contiguous translations in hardware. Unfortunately, modern OSes do not currently guarantee translation contiguity in many real-world scenarios; as systems remain online for long periods of time, their memory can and does become fragmented.},
	language = {en},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 46th {International} {Symposium} on {Computer} {Architecture}},
	publisher = {ACM},
	author = {Yan, Zi and Lustig, Daniel and Nellans, David and Bhattacharjee, Abhishek},
	month = jun,
	year = {2019},
	pages = {698--710},
}

@article{gaddipati_ps_2019,
	title = {{PS} and {PL}-{Based} {1G}/{10G} {Ethernet} {Solution}},
	abstract = {This application note focuses on Ethernet-based designs that use Zynq® UltraScale+™ devices. It describes the use of the gigabit Ethernet controller (GEM) available in the processing system (PS) through the extended multiplexed I/O (EMIO) and multiplexed I/O (MIO) interfaces. It also describes the use of 1000BASE-X, SGMII, and 10GBASE-R physical interfaces using high-speed transceivers in programmable logic (PL). The use of Ethernet jumbo frames in both PS and PL-based Ethernet systems is explained in this application note. Throughput numbers for PS Ethernet, PL Ethernet (1G and 10G), and PS-PL Ethernet are also included. The designs explained in this application note demonstrate Ethernet solutions with kernel-mode Linux device drivers.},
	language = {en},
	author = {Gaddipati, Naveen Kumar and Mahajan, Akhilesh and Jain, Rhythm and Shaik, Mohammed Rafi and Shaik, Juneed and Pathala, Suryabhavani},
	year = {2019},
	pages = {17},
}

@article{defossez_serial_2012,
	title = {Serial {LVDS} {High}-{Speed} {ADC} {Interface}},
	language = {en},
	author = {Defossez, Marc},
	year = {2012},
	pages = {21},
}
